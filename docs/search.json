[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "FIP 606 | por Caio M.",
    "section": "",
    "text": "Olá,\n\nSeja bem-vindo ao meu caderno de aulas da disciplina FIP 606 - Análise e Visualização de Dados em Fitopatologia.\nEu me chamo Caio M. Pereira e sou doutorando do programa de pós-graduação em Fitopatologia da Universidade Federal de Viçosa (UFV).\nEste website foi criado com base em Quarto, com o objetivo de armazenar e compartilhar as informações e scripts gerados ao longo das aulas da disciplina FIP 606 - Análise e Visualização de Dados em Fitopatologia, ministrada pelo Prof. Emerson Del Ponte e cursada no primeiro semestre de 2024.\n\nFique à vontade para explorar todo o conteúdo.\nEspero que as minhas informações, scripts e códigos lhe sejam úteis.\nBom proveito!\n\n\n\n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "Aula 9.2.html",
    "href": "Aula 9.2.html",
    "title": "Aula 09 - Estatística inferencial - Regressão linear",
    "section": "",
    "text": "estande &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=401662555\")\n\nestande &lt;- estande %&gt;% \n  mutate(bloco = as.factor(bloco))\n\n\n\n\nestande %&gt;% \n  ggplot(aes(trat, nplants))+\n  geom_jitter(width = 0.2, alpha = 0.2, color = \"darkred\")+\n  stat_summary(fun.data = \"mean_cl_boot\")+\n  geom_smooth(method = \"lm\", se = FALSE)+\n  facet_wrap(~exp)\n\n\n\n\n\n\n\n\n\nestande %&gt;% \n  ggplot(aes(trat, nplants))+\n  geom_jitter(width = 0.2, alpha = 0.2, color = \"darkred\")+\n  stat_summary(fun.data = \"mean_cl_boot\")+\n  geom_smooth(method = \"lm\", se = FALSE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nexp1 &lt;- estande %&gt;% \n  filter(exp == 1)\n\nexp1 %&gt;% \n  ggplot(aes(trat, nplants))+\n  geom_point()+\n  ylim (0,100)+\n  geom_smooth(method = \"lm\", se = FALSE)\n\n\n\n\n\n\n\n\n\nlm1 &lt;- lm (nplants ~ trat,\n           data = exp1)\nsummary(lm1)\n\n\nCall:\nlm(formula = nplants ~ trat, data = exp1)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-25.500  -6.532   1.758   8.573  27.226 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  52.5000     4.2044  12.487 1.84e-11 ***\ntrat         -0.2419     0.1859  -1.301    0.207    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 15 on 22 degrees of freedom\nMultiple R-squared:  0.07148,   Adjusted R-squared:  0.02928 \nF-statistic: 1.694 on 1 and 22 DF,  p-value: 0.2066\n\n\n\n\n\n\nexp2 &lt;- estande %&gt;% \n  filter(exp == 2)\n\nexp2 %&gt;% \n  ggplot(aes(trat, nplants))+\n  geom_point()+\n  ylim (0,100)+\n  geom_smooth (se = FALSE)+\n  geom_smooth(method = \"lm\", se = FALSE, color = \"red\")\n\n\n\n\n\n\n\n\nUma alternativa para linearizar a curva seria aplicar função logarítmica no tratameto.\n\nlm2 &lt;- lm (nplants ~ trat,\n           data = exp2)\nsummary(lm2)\n\n\nCall:\nlm(formula = nplants ~ trat, data = exp2)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-25.7816  -7.7150   0.5653   8.1929  19.2184 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  60.9857     3.6304  16.798 4.93e-14 ***\ntrat         -0.7007     0.1605  -4.365 0.000247 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 12.95 on 22 degrees of freedom\nMultiple R-squared:  0.4641,    Adjusted R-squared:  0.4398 \nF-statistic: 19.05 on 1 and 22 DF,  p-value: 0.0002473\n\n\n\n\n\n\nexp3 &lt;- estande %&gt;% \n  filter(exp == 3)\n\nexp1 %&gt;% \n  ggplot(aes(trat, nplants))+\n  geom_point()+\n  ylim (0,100)+\n  geom_smooth(method = \"lm\", se = FALSE)\n\n\n\n\n\n\n\n\n\nlm3 &lt;- lm (nplants ~ trat,\n           data = exp3)\nsummary(lm3)\n\n\nCall:\nlm(formula = nplants ~ trat, data = exp3)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-26.5887  -3.9597   0.7177   5.5806  19.8952 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  95.7500     2.9529  32.425  &lt; 2e-16 ***\ntrat         -0.7634     0.1306  -5.847 6.97e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 10.53 on 22 degrees of freedom\nMultiple R-squared:  0.6085,    Adjusted R-squared:  0.5907 \nF-statistic: 34.19 on 1 and 22 DF,  p-value: 6.968e-06\n\n\n\n\n\n\n\nglm1 &lt;- glm(nplants ~ trat,\n            family = \"gaussian\",\n            data = exp1)\n\nsummary(glm1)\n\n\nCall:\nglm(formula = nplants ~ trat, family = \"gaussian\", data = exp1)\n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  52.5000     4.2044  12.487 1.84e-11 ***\ntrat         -0.2419     0.1859  -1.301    0.207    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for gaussian family taken to be 224.9751)\n\n    Null deviance: 5330.5  on 23  degrees of freedom\nResidual deviance: 4949.5  on 22  degrees of freedom\nAIC: 202\n\nNumber of Fisher Scoring iterations: 2\n\nAIC(glm1)\n\n[1] 202.0045\n\n\n\nglm2a &lt;- glm(nplants ~ trat,\n            family = \"gaussian\",\n            data = exp2)\n\nsummary(glm2a)\n\n\nCall:\nglm(formula = nplants ~ trat, family = \"gaussian\", data = exp2)\n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  60.9857     3.6304  16.798 4.93e-14 ***\ntrat         -0.7007     0.1605  -4.365 0.000247 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for gaussian family taken to be 167.7464)\n\n    Null deviance: 6886.6  on 23  degrees of freedom\nResidual deviance: 3690.4  on 22  degrees of freedom\nAIC: 194.96\n\nNumber of Fisher Scoring iterations: 2\n\nAIC(glm2a)\n\n[1] 194.9597\n\n\n\nglm2b &lt;- glm(nplants ~ trat,\n            family = poisson(link = \"log\"),\n            data = exp2)\n\nsummary(glm2b)\n\n\nCall:\nglm(formula = nplants ~ trat, family = poisson(link = \"log\"), \n    data = exp2)\n\nCoefficients:\n             Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  4.134189   0.037583 110.003  &lt; 2e-16 ***\ntrat        -0.016270   0.002059  -7.901 2.76e-15 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 139.783  on 23  degrees of freedom\nResidual deviance:  69.578  on 22  degrees of freedom\nAIC: 210.24\n\nNumber of Fisher Scoring iterations: 4\n\nAIC(glm2b)\n\n[1] 210.2353\n\n\n\nglm3 &lt;- glm(nplants ~ trat,\n            family = \"gaussian\",\n            data = exp3)\n\nsummary(glm3)\n\n\nCall:\nglm(formula = nplants ~ trat, family = \"gaussian\", data = exp3)\n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  95.7500     2.9529  32.425  &lt; 2e-16 ***\ntrat         -0.7634     0.1306  -5.847 6.97e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for gaussian family taken to be 110.9787)\n\n    Null deviance: 6235.8  on 23  degrees of freedom\nResidual deviance: 2441.5  on 22  degrees of freedom\nAIC: 185.04\n\nNumber of Fisher Scoring iterations: 2\n\nAIC(glm3)\n\n[1] 185.0449\n\n\n\nglm3b &lt;- glm(nplants ~ trat,\n            family = poisson(link = \"log\"),\n            data = exp3)\n\nsummary(glm3b)\n\n\nCall:\nglm(formula = nplants ~ trat, family = poisson(link = \"log\"), \n    data = exp3)\n\nCoefficients:\n             Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  4.571590   0.029539 154.762  &lt; 2e-16 ***\ntrat        -0.009965   0.001488  -6.697 2.13e-11 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 77.906  on 23  degrees of freedom\nResidual deviance: 29.952  on 22  degrees of freedom\nAIC: 183.93\n\nNumber of Fisher Scoring iterations: 4\n\nAIC(glm3b)\n\n[1] 183.9324\n\n\nA função AIC é útil para auxiliar na escolha do melhor modelo para cada situação. Nesse caso, utilizamos o critério de informação de Akaike (do inglês, Akaike’s Information Criterion - AIC). Os melhores modelos, ou seja, aqueles que melhor se ajustam aos dados, serão aqueles que apresentarem os menores valores para essa função.\n\n\n\n\nglm_exp &lt;- glmer(nplants ~ trat + (trat | exp),\n            family = \"gaussian\",\n            data = estande)\n\nsummary(glm_exp)\n\nLinear mixed model fit by REML ['lmerMod']\nFormula: nplants ~ trat + (trat | exp)\n   Data: estande\n\nREML criterion at convergence: 580.8\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-2.0988 -0.6091  0.1722  0.6360  1.9963 \n\nRandom effects:\n Groups   Name        Variance  Std.Dev. Corr \n exp      (Intercept) 510.68405 22.5983       \n          trat          0.05516  0.2349  -0.82\n Residual             167.91303 12.9581       \nNumber of obs: 72, groups:  exp, 3\n\nFixed effects:\n            Estimate Std. Error t value\n(Intercept)  69.7452    13.2146   5.278\ntrat         -0.5687     0.1643  -3.462\n\nCorrelation of Fixed Effects:\n     (Intr)\ntrat -0.731\noptimizer (nloptwrap) convergence code: 0 (OK)\nModel failed to converge with max|grad| = 0.00274249 (tol = 0.002, component 1)\n\nAIC(glm_exp)\n\n[1] 592.8402\n\n\n\nglm_exp_2 &lt;- glmer(nplants ~ trat + (trat | exp),\n            family = poisson(link = \"log\"),\n            data = estande)\n\nsummary(glm_exp_2)\n\nGeneralized linear mixed model fit by maximum likelihood (Laplace\n  Approximation) [glmerMod]\n Family: poisson  ( log )\nFormula: nplants ~ trat + (trat | exp)\n   Data: estande\n\n     AIC      BIC   logLik deviance df.resid \n   660.7    672.1   -325.4    650.7       67 \n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-3.6247 -0.8083  0.1042  0.9601  3.6511 \n\nRandom effects:\n Groups Name        Variance  Std.Dev. Corr \n exp    (Intercept) 6.425e-02 0.253478      \n        trat        1.602e-05 0.004003 -0.17\nNumber of obs: 72, groups:  exp, 3\n\nFixed effects:\n             Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  4.223397   0.147793  28.577  &lt; 2e-16 ***\ntrat        -0.010434   0.002538  -4.111 3.93e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n     (Intr)\ntrat -0.192\n\nAIC(glm_exp_2)\n\n[1] 660.7282",
    "crumbs": [
      "Home",
      "Aula 09",
      "Estatística inferencial - Regressão linear"
    ]
  },
  {
    "objectID": "Aula 9.2.html#análise-de-regressão-linear",
    "href": "Aula 9.2.html#análise-de-regressão-linear",
    "title": "Aula 09 - Estatística inferencial - Regressão linear",
    "section": "",
    "text": "estande &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=401662555\")\n\nestande &lt;- estande %&gt;% \n  mutate(bloco = as.factor(bloco))\n\n\n\n\nestande %&gt;% \n  ggplot(aes(trat, nplants))+\n  geom_jitter(width = 0.2, alpha = 0.2, color = \"darkred\")+\n  stat_summary(fun.data = \"mean_cl_boot\")+\n  geom_smooth(method = \"lm\", se = FALSE)+\n  facet_wrap(~exp)\n\n\n\n\n\n\n\n\n\nestande %&gt;% \n  ggplot(aes(trat, nplants))+\n  geom_jitter(width = 0.2, alpha = 0.2, color = \"darkred\")+\n  stat_summary(fun.data = \"mean_cl_boot\")+\n  geom_smooth(method = \"lm\", se = FALSE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nexp1 &lt;- estande %&gt;% \n  filter(exp == 1)\n\nexp1 %&gt;% \n  ggplot(aes(trat, nplants))+\n  geom_point()+\n  ylim (0,100)+\n  geom_smooth(method = \"lm\", se = FALSE)\n\n\n\n\n\n\n\n\n\nlm1 &lt;- lm (nplants ~ trat,\n           data = exp1)\nsummary(lm1)\n\n\nCall:\nlm(formula = nplants ~ trat, data = exp1)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-25.500  -6.532   1.758   8.573  27.226 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  52.5000     4.2044  12.487 1.84e-11 ***\ntrat         -0.2419     0.1859  -1.301    0.207    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 15 on 22 degrees of freedom\nMultiple R-squared:  0.07148,   Adjusted R-squared:  0.02928 \nF-statistic: 1.694 on 1 and 22 DF,  p-value: 0.2066\n\n\n\n\n\n\nexp2 &lt;- estande %&gt;% \n  filter(exp == 2)\n\nexp2 %&gt;% \n  ggplot(aes(trat, nplants))+\n  geom_point()+\n  ylim (0,100)+\n  geom_smooth (se = FALSE)+\n  geom_smooth(method = \"lm\", se = FALSE, color = \"red\")\n\n\n\n\n\n\n\n\nUma alternativa para linearizar a curva seria aplicar função logarítmica no tratameto.\n\nlm2 &lt;- lm (nplants ~ trat,\n           data = exp2)\nsummary(lm2)\n\n\nCall:\nlm(formula = nplants ~ trat, data = exp2)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-25.7816  -7.7150   0.5653   8.1929  19.2184 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  60.9857     3.6304  16.798 4.93e-14 ***\ntrat         -0.7007     0.1605  -4.365 0.000247 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 12.95 on 22 degrees of freedom\nMultiple R-squared:  0.4641,    Adjusted R-squared:  0.4398 \nF-statistic: 19.05 on 1 and 22 DF,  p-value: 0.0002473\n\n\n\n\n\n\nexp3 &lt;- estande %&gt;% \n  filter(exp == 3)\n\nexp1 %&gt;% \n  ggplot(aes(trat, nplants))+\n  geom_point()+\n  ylim (0,100)+\n  geom_smooth(method = \"lm\", se = FALSE)\n\n\n\n\n\n\n\n\n\nlm3 &lt;- lm (nplants ~ trat,\n           data = exp3)\nsummary(lm3)\n\n\nCall:\nlm(formula = nplants ~ trat, data = exp3)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-26.5887  -3.9597   0.7177   5.5806  19.8952 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  95.7500     2.9529  32.425  &lt; 2e-16 ***\ntrat         -0.7634     0.1306  -5.847 6.97e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 10.53 on 22 degrees of freedom\nMultiple R-squared:  0.6085,    Adjusted R-squared:  0.5907 \nF-statistic: 34.19 on 1 and 22 DF,  p-value: 6.968e-06\n\n\n\n\n\n\n\nglm1 &lt;- glm(nplants ~ trat,\n            family = \"gaussian\",\n            data = exp1)\n\nsummary(glm1)\n\n\nCall:\nglm(formula = nplants ~ trat, family = \"gaussian\", data = exp1)\n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  52.5000     4.2044  12.487 1.84e-11 ***\ntrat         -0.2419     0.1859  -1.301    0.207    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for gaussian family taken to be 224.9751)\n\n    Null deviance: 5330.5  on 23  degrees of freedom\nResidual deviance: 4949.5  on 22  degrees of freedom\nAIC: 202\n\nNumber of Fisher Scoring iterations: 2\n\nAIC(glm1)\n\n[1] 202.0045\n\n\n\nglm2a &lt;- glm(nplants ~ trat,\n            family = \"gaussian\",\n            data = exp2)\n\nsummary(glm2a)\n\n\nCall:\nglm(formula = nplants ~ trat, family = \"gaussian\", data = exp2)\n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  60.9857     3.6304  16.798 4.93e-14 ***\ntrat         -0.7007     0.1605  -4.365 0.000247 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for gaussian family taken to be 167.7464)\n\n    Null deviance: 6886.6  on 23  degrees of freedom\nResidual deviance: 3690.4  on 22  degrees of freedom\nAIC: 194.96\n\nNumber of Fisher Scoring iterations: 2\n\nAIC(glm2a)\n\n[1] 194.9597\n\n\n\nglm2b &lt;- glm(nplants ~ trat,\n            family = poisson(link = \"log\"),\n            data = exp2)\n\nsummary(glm2b)\n\n\nCall:\nglm(formula = nplants ~ trat, family = poisson(link = \"log\"), \n    data = exp2)\n\nCoefficients:\n             Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  4.134189   0.037583 110.003  &lt; 2e-16 ***\ntrat        -0.016270   0.002059  -7.901 2.76e-15 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 139.783  on 23  degrees of freedom\nResidual deviance:  69.578  on 22  degrees of freedom\nAIC: 210.24\n\nNumber of Fisher Scoring iterations: 4\n\nAIC(glm2b)\n\n[1] 210.2353\n\n\n\nglm3 &lt;- glm(nplants ~ trat,\n            family = \"gaussian\",\n            data = exp3)\n\nsummary(glm3)\n\n\nCall:\nglm(formula = nplants ~ trat, family = \"gaussian\", data = exp3)\n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  95.7500     2.9529  32.425  &lt; 2e-16 ***\ntrat         -0.7634     0.1306  -5.847 6.97e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for gaussian family taken to be 110.9787)\n\n    Null deviance: 6235.8  on 23  degrees of freedom\nResidual deviance: 2441.5  on 22  degrees of freedom\nAIC: 185.04\n\nNumber of Fisher Scoring iterations: 2\n\nAIC(glm3)\n\n[1] 185.0449\n\n\n\nglm3b &lt;- glm(nplants ~ trat,\n            family = poisson(link = \"log\"),\n            data = exp3)\n\nsummary(glm3b)\n\n\nCall:\nglm(formula = nplants ~ trat, family = poisson(link = \"log\"), \n    data = exp3)\n\nCoefficients:\n             Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  4.571590   0.029539 154.762  &lt; 2e-16 ***\ntrat        -0.009965   0.001488  -6.697 2.13e-11 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 77.906  on 23  degrees of freedom\nResidual deviance: 29.952  on 22  degrees of freedom\nAIC: 183.93\n\nNumber of Fisher Scoring iterations: 4\n\nAIC(glm3b)\n\n[1] 183.9324\n\n\nA função AIC é útil para auxiliar na escolha do melhor modelo para cada situação. Nesse caso, utilizamos o critério de informação de Akaike (do inglês, Akaike’s Information Criterion - AIC). Os melhores modelos, ou seja, aqueles que melhor se ajustam aos dados, serão aqueles que apresentarem os menores valores para essa função.\n\n\n\n\nglm_exp &lt;- glmer(nplants ~ trat + (trat | exp),\n            family = \"gaussian\",\n            data = estande)\n\nsummary(glm_exp)\n\nLinear mixed model fit by REML ['lmerMod']\nFormula: nplants ~ trat + (trat | exp)\n   Data: estande\n\nREML criterion at convergence: 580.8\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-2.0988 -0.6091  0.1722  0.6360  1.9963 \n\nRandom effects:\n Groups   Name        Variance  Std.Dev. Corr \n exp      (Intercept) 510.68405 22.5983       \n          trat          0.05516  0.2349  -0.82\n Residual             167.91303 12.9581       \nNumber of obs: 72, groups:  exp, 3\n\nFixed effects:\n            Estimate Std. Error t value\n(Intercept)  69.7452    13.2146   5.278\ntrat         -0.5687     0.1643  -3.462\n\nCorrelation of Fixed Effects:\n     (Intr)\ntrat -0.731\noptimizer (nloptwrap) convergence code: 0 (OK)\nModel failed to converge with max|grad| = 0.00274249 (tol = 0.002, component 1)\n\nAIC(glm_exp)\n\n[1] 592.8402\n\n\n\nglm_exp_2 &lt;- glmer(nplants ~ trat + (trat | exp),\n            family = poisson(link = \"log\"),\n            data = estande)\n\nsummary(glm_exp_2)\n\nGeneralized linear mixed model fit by maximum likelihood (Laplace\n  Approximation) [glmerMod]\n Family: poisson  ( log )\nFormula: nplants ~ trat + (trat | exp)\n   Data: estande\n\n     AIC      BIC   logLik deviance df.resid \n   660.7    672.1   -325.4    650.7       67 \n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-3.6247 -0.8083  0.1042  0.9601  3.6511 \n\nRandom effects:\n Groups Name        Variance  Std.Dev. Corr \n exp    (Intercept) 6.425e-02 0.253478      \n        trat        1.602e-05 0.004003 -0.17\nNumber of obs: 72, groups:  exp, 3\n\nFixed effects:\n             Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  4.223397   0.147793  28.577  &lt; 2e-16 ***\ntrat        -0.010434   0.002538  -4.111 3.93e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n     (Intr)\ntrat -0.192\n\nAIC(glm_exp_2)\n\n[1] 660.7282",
    "crumbs": [
      "Home",
      "Aula 09",
      "Estatística inferencial - Regressão linear"
    ]
  },
  {
    "objectID": "Aula 8.2.html",
    "href": "Aula 8.2.html",
    "title": "Aula 08 - Curva de progresso da doença",
    "section": "",
    "text": "Para construção de uma curva de progresso da doença usaremos como exemplo um conjunto de dados que descreve diferentes métodos de irrigação (variável independente, um fator, 2 níveis) e seu efeito sobre a severidade (variável dependente) ao longo dos dias.\n\ncurve &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=1807247585\")\n\ncurve$severity2 &lt;- (curve$severity*100)\n\nComo os dados de severidade são apresentados em valores decimais, é possível colocá-los em porcentagem fazendo multiplicação por 100.\nPara construir a curva, primeiro é preciso agrupar os dados (group_by) em função do método de irrigação e do dia. Em seguida, é calculada a média em função das mesmas variáveis (dia e irrigação) com a função summarise(sev_mean = mean(sev_X)).\n\ncurve2 &lt;- curve %&gt;% \n  group_by(Irrigation, day) %&gt;% \n  summarise(sev_mean = mean(severity))\n\ncurve2\n\n# A tibble: 20 × 3\n# Groups:   Irrigation [2]\n   Irrigation   day sev_mean\n   &lt;chr&gt;      &lt;dbl&gt;    &lt;dbl&gt;\n 1 Drip           0   0.01  \n 2 Drip           7   0.0367\n 3 Drip          14   0.107 \n 4 Drip          21   0.117 \n 5 Drip          28   0.153 \n 6 Drip          35   0.18  \n 7 Drip          42   0.323 \n 8 Drip          49   0.357 \n 9 Drip          56   0.42  \n10 Drip          63   0.43  \n11 Furrow         0   0.01  \n12 Furrow         7   0.04  \n13 Furrow        14   0.103 \n14 Furrow        21   0.103 \n15 Furrow        28   0.157 \n16 Furrow        35   0.187 \n17 Furrow        42   0.353 \n18 Furrow        49   0.383 \n19 Furrow        56   0.413 \n20 Furrow        63   0.45  \n\n\n\n\n\nPara conhecer o comportamento da severidade ao longo do tempo, será construído um gráfico de pontos (geom_point) e linhas (geom_line), diferenciando os tratamentos (“Irrigation”) pela cor:\n\ncurve2 %&gt;% \n  ggplot(aes(day, sev_mean, colour = Irrigation))+\n  geom_point()+\n  geom_line()\n\n\n\n\n\n\n\n\nOu, uma figura com dois gráficos. Um para cada nível do fator “Irrigation”:\n\ncurve2 %&gt;% \n  ggplot(aes(day, sev_mean))+\n  geom_point()+\n  geom_line()+\n  facet_wrap(~Irrigation)\n\n\n\n\n\n\n\n\n\n\n\nPara o cálculo da área abaixo da curva de progresso da doença (AACPD, ou “area under the disease progress curve”, AUDPC), será criado um novo dataframe. Para isso, será feito o agrupamento (group_by) das variáveis em função do tratamento (”Irrigation”) e das repetições (“rep”). Em seguida, será utilizada a função summarise para o cálculo da AACPD (função AUDPC, pacote epifitter).\n\ncurve3 &lt;- curve %&gt;% \n  group_by(Irrigation, rep) %&gt;% \n  summarise(aacpd = AUDPC(day, severity))\n\ncurve3\n\n# A tibble: 6 × 3\n# Groups:   Irrigation [2]\n  Irrigation   rep aacpd\n  &lt;chr&gt;      &lt;dbl&gt; &lt;dbl&gt;\n1 Drip           1  13.0\n2 Drip           2  13.9\n3 Drip           3  13.3\n4 Furrow         1  13.5\n5 Furrow         2  14.1\n6 Furrow         3  13.7\n\n\n\n\n\nAntes de realizar análise de variância é preciso estabelece um modelo, o que será com os valores de AACPD e a função (lm):\n\nm_curve &lt;- lm(aacpd ~ Irrigation+factor(rep),\n              data = curve3)\n\n\n\nCom funções do pacote Performance:\n\ncheck_normality(m_curve)\n\nOK: residuals appear as normally distributed (p = 0.380).\n\ncheck_heteroscedasticity(m_curve)\n\nOK: Error variance appears to be homoscedastic (p = 0.704).\n\n\nCom o pacote DHARMa:\n\nplot(simulateResiduals(m_curve))\n\n\n\n\n\n\n\n\nCom o teste de Shapiro-Wilk (shapiro.test) e o teste de Bartlett (bartlett.test):\n\nshapiro.test(m_curve$residuals)\n\n\n    Shapiro-Wilk normality test\n\ndata:  m_curve$residuals\nW = 0.90104, p-value = 0.3801\n\nbartlett.test (aacpd ~ Irrigation,\n               data = curve3)\n\n\n    Bartlett test of homogeneity of variances\n\ndata:  aacpd by Irrigation\nBartlett's K-squared = 0.46162, df = 1, p-value = 0.4969\n\n\nAmbas as metodologias demonstram que os dados seguem distribuição normal e possuem homocedasticidade, logo é possível proceder análise de variância.\n\n\n\n\nanova(m_curve)\n\nAnalysis of Variance Table\n\nResponse: aacpd\n            Df  Sum Sq  Mean Sq F value  Pr(&gt;F)  \nIrrigation   1 0.23602 0.236017  10.605 0.08275 .\nfactor(rep)  2 0.61291 0.306454  13.771 0.06770 .\nResiduals    2 0.04451 0.022254                  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nA ANOVA mostra que não há diferença entre as áreas.\n\nagricolae::cv.model(m_curve)\n\n[1] 1.097572\n\n\nO que poderia ser explicado pelo coeficiente de variação do experimento, que foi muito baixo (CV = 1.09 %).",
    "crumbs": [
      "Home",
      "Aula 08",
      "Curva de progresso da doença"
    ]
  },
  {
    "objectID": "Aula 8.2.html#curva-de-progresso-da-doença",
    "href": "Aula 8.2.html#curva-de-progresso-da-doença",
    "title": "Aula 08 - Curva de progresso da doença",
    "section": "",
    "text": "Para construção de uma curva de progresso da doença usaremos como exemplo um conjunto de dados que descreve diferentes métodos de irrigação (variável independente, um fator, 2 níveis) e seu efeito sobre a severidade (variável dependente) ao longo dos dias.\n\ncurve &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=1807247585\")\n\ncurve$severity2 &lt;- (curve$severity*100)\n\nComo os dados de severidade são apresentados em valores decimais, é possível colocá-los em porcentagem fazendo multiplicação por 100.\nPara construir a curva, primeiro é preciso agrupar os dados (group_by) em função do método de irrigação e do dia. Em seguida, é calculada a média em função das mesmas variáveis (dia e irrigação) com a função summarise(sev_mean = mean(sev_X)).\n\ncurve2 &lt;- curve %&gt;% \n  group_by(Irrigation, day) %&gt;% \n  summarise(sev_mean = mean(severity))\n\ncurve2\n\n# A tibble: 20 × 3\n# Groups:   Irrigation [2]\n   Irrigation   day sev_mean\n   &lt;chr&gt;      &lt;dbl&gt;    &lt;dbl&gt;\n 1 Drip           0   0.01  \n 2 Drip           7   0.0367\n 3 Drip          14   0.107 \n 4 Drip          21   0.117 \n 5 Drip          28   0.153 \n 6 Drip          35   0.18  \n 7 Drip          42   0.323 \n 8 Drip          49   0.357 \n 9 Drip          56   0.42  \n10 Drip          63   0.43  \n11 Furrow         0   0.01  \n12 Furrow         7   0.04  \n13 Furrow        14   0.103 \n14 Furrow        21   0.103 \n15 Furrow        28   0.157 \n16 Furrow        35   0.187 \n17 Furrow        42   0.353 \n18 Furrow        49   0.383 \n19 Furrow        56   0.413 \n20 Furrow        63   0.45  \n\n\n\n\n\nPara conhecer o comportamento da severidade ao longo do tempo, será construído um gráfico de pontos (geom_point) e linhas (geom_line), diferenciando os tratamentos (“Irrigation”) pela cor:\n\ncurve2 %&gt;% \n  ggplot(aes(day, sev_mean, colour = Irrigation))+\n  geom_point()+\n  geom_line()\n\n\n\n\n\n\n\n\nOu, uma figura com dois gráficos. Um para cada nível do fator “Irrigation”:\n\ncurve2 %&gt;% \n  ggplot(aes(day, sev_mean))+\n  geom_point()+\n  geom_line()+\n  facet_wrap(~Irrigation)\n\n\n\n\n\n\n\n\n\n\n\nPara o cálculo da área abaixo da curva de progresso da doença (AACPD, ou “area under the disease progress curve”, AUDPC), será criado um novo dataframe. Para isso, será feito o agrupamento (group_by) das variáveis em função do tratamento (”Irrigation”) e das repetições (“rep”). Em seguida, será utilizada a função summarise para o cálculo da AACPD (função AUDPC, pacote epifitter).\n\ncurve3 &lt;- curve %&gt;% \n  group_by(Irrigation, rep) %&gt;% \n  summarise(aacpd = AUDPC(day, severity))\n\ncurve3\n\n# A tibble: 6 × 3\n# Groups:   Irrigation [2]\n  Irrigation   rep aacpd\n  &lt;chr&gt;      &lt;dbl&gt; &lt;dbl&gt;\n1 Drip           1  13.0\n2 Drip           2  13.9\n3 Drip           3  13.3\n4 Furrow         1  13.5\n5 Furrow         2  14.1\n6 Furrow         3  13.7\n\n\n\n\n\nAntes de realizar análise de variância é preciso estabelece um modelo, o que será com os valores de AACPD e a função (lm):\n\nm_curve &lt;- lm(aacpd ~ Irrigation+factor(rep),\n              data = curve3)\n\n\n\nCom funções do pacote Performance:\n\ncheck_normality(m_curve)\n\nOK: residuals appear as normally distributed (p = 0.380).\n\ncheck_heteroscedasticity(m_curve)\n\nOK: Error variance appears to be homoscedastic (p = 0.704).\n\n\nCom o pacote DHARMa:\n\nplot(simulateResiduals(m_curve))\n\n\n\n\n\n\n\n\nCom o teste de Shapiro-Wilk (shapiro.test) e o teste de Bartlett (bartlett.test):\n\nshapiro.test(m_curve$residuals)\n\n\n    Shapiro-Wilk normality test\n\ndata:  m_curve$residuals\nW = 0.90104, p-value = 0.3801\n\nbartlett.test (aacpd ~ Irrigation,\n               data = curve3)\n\n\n    Bartlett test of homogeneity of variances\n\ndata:  aacpd by Irrigation\nBartlett's K-squared = 0.46162, df = 1, p-value = 0.4969\n\n\nAmbas as metodologias demonstram que os dados seguem distribuição normal e possuem homocedasticidade, logo é possível proceder análise de variância.\n\n\n\n\nanova(m_curve)\n\nAnalysis of Variance Table\n\nResponse: aacpd\n            Df  Sum Sq  Mean Sq F value  Pr(&gt;F)  \nIrrigation   1 0.23602 0.236017  10.605 0.08275 .\nfactor(rep)  2 0.61291 0.306454  13.771 0.06770 .\nResiduals    2 0.04451 0.022254                  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nA ANOVA mostra que não há diferença entre as áreas.\n\nagricolae::cv.model(m_curve)\n\n[1] 1.097572\n\n\nO que poderia ser explicado pelo coeficiente de variação do experimento, que foi muito baixo (CV = 1.09 %).",
    "crumbs": [
      "Home",
      "Aula 08",
      "Curva de progresso da doença"
    ]
  },
  {
    "objectID": "Aula 7.3.html",
    "href": "Aula 7.3.html",
    "title": "Aula 07 - Estatística inferencial - Experimento fatorial",
    "section": "",
    "text": "FAT &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=2023059672\")\n\nAo aplicar o comando theme_set (theme_bw()), todos os gráficos gerados a partir da inserção deste comando terão o tema designado, no caso “theme_bw”.\n\ntheme_set(theme_bw())\n\nFAT %&gt;%\n  ggplot(aes(treat, severity, color = factor(dose)))+\n  geom_jitter(width = 0.1)\n\n\n\n\n\n\n\nFAT %&gt;%\n  ggplot(aes(treat, severity, color = factor(dose)))+\n  geom_jitter()+\n  facet_wrap(~dose)\n\n\n\n\n\n\n\n\nAcima, foram apresentados dois gráficos para visualização dos dados. A primeira opção, faz uso de cores para apresentar as respostas associados aos níveis do fator dose, enquanto os níveis do fator “treat” são apresentados no eixo x.\nJá a segunda opção, faz uso da função facet_wrap, em que são construídos dois gráficos, um para cada nível do fator dose.\n\n\n\nPara construir o modelo para experimento com arranjo fatorial ainda será utilizada a função lm. No entanto, como dois ou mais fatores serão avaliados é preciso incluir as outras variáveis independentes no modelo. Dessa forma, a fórmula seria baseada em: variável resposta~varíavel indepedente_1*varíavel indepedente_2.\n\nmf &lt;- lm (severity ~ treat*dose,\n          data = FAT)\n\n\n\n\n\nanova(mf)\n\nAnalysis of Variance Table\n\nResponse: severity\n           Df   Sum Sq  Mean Sq F value    Pr(&gt;F)    \ntreat       1 0.113232 0.113232  30.358 4.754e-05 ***\ndose        1 0.073683 0.073683  19.755 0.0004077 ***\ntreat:dose  1 0.072739 0.072739  19.502 0.0004326 ***\nResiduals  16 0.059678 0.003730                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nA análise de variância nos mostra que há diferença entre as médias dos tratamentos (treat, F =4.754e-05), entre as médias das doses (dose, F = 0.0004077), e que também há diferenças significativas na interação tratamento*dose (treat:dose, F = 0.0004326).\nPortanto, como há interações entre fatores, será preciso decompor as médias e realizar comparações para os níveis das doses dentro do fator tratamento, e dos níveis do tratamentos dentro do fator dose.\n\n\n\n\nplot(simulateResiduals(mf))\n\n\n\n\n\n\n\n\nOs resultados obtidos pelo pacote DHARMa demonstram que os dados seguem distribuição normal e há homogeneidade de variância entre os grupos.\n\n\n\nPara comparação de médias, também será utilizada a função emmeans, e para análise de um fator dentro de outro é preciso indicar a ordem dos fatores, separado por uma barra ( | ).\n\n\n\nmf_medias &lt;- emmeans(mf, ~ treat | dose)\ncld(mf_medias)\n\ndose = 0.5:\n treat        emmean     SE df lower.CL upper.CL .group\n Tebuconazole 0.0210 0.0273 16 -0.03690   0.0789  1    \n Ionic liquid 0.2921 0.0273 16  0.23420   0.3500   2   \n\ndose = 2.0:\n treat        emmean     SE df lower.CL upper.CL .group\n Tebuconazole 0.0202 0.0273 16 -0.03768   0.0781  1    \n Ionic liquid 0.0501 0.0273 16 -0.00781   0.1080  1    \n\nConfidence level used: 0.95 \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\n\n\n\n\n\nmf_medias &lt;- emmeans(mf, ~ dose | treat) \ncld(mf_medias)\n\ntreat = Ionic liquid:\n dose emmean     SE df lower.CL upper.CL .group\n  2.0 0.0501 0.0273 16 -0.00781   0.1080  1    \n  0.5 0.2921 0.0273 16  0.23420   0.3500   2   \n\ntreat = Tebuconazole:\n dose emmean     SE df lower.CL upper.CL .group\n  2.0 0.0202 0.0273 16 -0.03768   0.0781  1    \n  0.5 0.0210 0.0273 16 -0.03690   0.0789  1    \n\nConfidence level used: 0.95 \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same.",
    "crumbs": [
      "Home",
      "Aula 07",
      "Estatística inferencial - Experimento fatorial"
    ]
  },
  {
    "objectID": "Aula 7.3.html#experimento-fatorial---2anova",
    "href": "Aula 7.3.html#experimento-fatorial---2anova",
    "title": "Aula 07 - Estatística inferencial - Experimento fatorial",
    "section": "",
    "text": "FAT &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=2023059672\")\n\nAo aplicar o comando theme_set (theme_bw()), todos os gráficos gerados a partir da inserção deste comando terão o tema designado, no caso “theme_bw”.\n\ntheme_set(theme_bw())\n\nFAT %&gt;%\n  ggplot(aes(treat, severity, color = factor(dose)))+\n  geom_jitter(width = 0.1)\n\n\n\n\n\n\n\nFAT %&gt;%\n  ggplot(aes(treat, severity, color = factor(dose)))+\n  geom_jitter()+\n  facet_wrap(~dose)\n\n\n\n\n\n\n\n\nAcima, foram apresentados dois gráficos para visualização dos dados. A primeira opção, faz uso de cores para apresentar as respostas associados aos níveis do fator dose, enquanto os níveis do fator “treat” são apresentados no eixo x.\nJá a segunda opção, faz uso da função facet_wrap, em que são construídos dois gráficos, um para cada nível do fator dose.\n\n\n\nPara construir o modelo para experimento com arranjo fatorial ainda será utilizada a função lm. No entanto, como dois ou mais fatores serão avaliados é preciso incluir as outras variáveis independentes no modelo. Dessa forma, a fórmula seria baseada em: variável resposta~varíavel indepedente_1*varíavel indepedente_2.\n\nmf &lt;- lm (severity ~ treat*dose,\n          data = FAT)\n\n\n\n\n\nanova(mf)\n\nAnalysis of Variance Table\n\nResponse: severity\n           Df   Sum Sq  Mean Sq F value    Pr(&gt;F)    \ntreat       1 0.113232 0.113232  30.358 4.754e-05 ***\ndose        1 0.073683 0.073683  19.755 0.0004077 ***\ntreat:dose  1 0.072739 0.072739  19.502 0.0004326 ***\nResiduals  16 0.059678 0.003730                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nA análise de variância nos mostra que há diferença entre as médias dos tratamentos (treat, F =4.754e-05), entre as médias das doses (dose, F = 0.0004077), e que também há diferenças significativas na interação tratamento*dose (treat:dose, F = 0.0004326).\nPortanto, como há interações entre fatores, será preciso decompor as médias e realizar comparações para os níveis das doses dentro do fator tratamento, e dos níveis do tratamentos dentro do fator dose.\n\n\n\n\nplot(simulateResiduals(mf))\n\n\n\n\n\n\n\n\nOs resultados obtidos pelo pacote DHARMa demonstram que os dados seguem distribuição normal e há homogeneidade de variância entre os grupos.\n\n\n\nPara comparação de médias, também será utilizada a função emmeans, e para análise de um fator dentro de outro é preciso indicar a ordem dos fatores, separado por uma barra ( | ).\n\n\n\nmf_medias &lt;- emmeans(mf, ~ treat | dose)\ncld(mf_medias)\n\ndose = 0.5:\n treat        emmean     SE df lower.CL upper.CL .group\n Tebuconazole 0.0210 0.0273 16 -0.03690   0.0789  1    \n Ionic liquid 0.2921 0.0273 16  0.23420   0.3500   2   \n\ndose = 2.0:\n treat        emmean     SE df lower.CL upper.CL .group\n Tebuconazole 0.0202 0.0273 16 -0.03768   0.0781  1    \n Ionic liquid 0.0501 0.0273 16 -0.00781   0.1080  1    \n\nConfidence level used: 0.95 \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\n\n\n\n\n\nmf_medias &lt;- emmeans(mf, ~ dose | treat) \ncld(mf_medias)\n\ntreat = Ionic liquid:\n dose emmean     SE df lower.CL upper.CL .group\n  2.0 0.0501 0.0273 16 -0.00781   0.1080  1    \n  0.5 0.2921 0.0273 16  0.23420   0.3500   2   \n\ntreat = Tebuconazole:\n dose emmean     SE df lower.CL upper.CL .group\n  2.0 0.0202 0.0273 16 -0.03768   0.0781  1    \n  0.5 0.0210 0.0273 16 -0.03690   0.0789  1    \n\nConfidence level used: 0.95 \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same.",
    "crumbs": [
      "Home",
      "Aula 07",
      "Estatística inferencial - Experimento fatorial"
    ]
  },
  {
    "objectID": "Aula 7.1.html",
    "href": "Aula 7.1.html",
    "title": "Aula 07 - Estatística inferencial - Análise de variância",
    "section": "",
    "text": "Nesta aula, será realizada uma análise de variância (ANOVA) usando o conjunto de dados InsectSprays. Serão demonstrados como ajustar um modelo de regressão linear (lm), necessário para a ANOVA, os passos a seguir para verificar as premissas da ANOVA e os testes para comparação de médias que podem ser aplicados. Também serão apresentadas alternativas para a análise dos dados caso não atendam às pressuposições da ANOVA, como transformações, testes não-paramétricos e modelos lineares generalizados. Por fim, será realizada uma análise fatorial com um segundo conjunto de dados.",
    "crumbs": [
      "Home",
      "Aula 07",
      "Estatística inferencial - Análise de variância"
    ]
  },
  {
    "objectID": "Aula 7.1.html#carregando-os-pacotes",
    "href": "Aula 7.1.html#carregando-os-pacotes",
    "title": "Aula 07 - Estatística inferencial - Análise de variância",
    "section": "Carregando os pacotes",
    "text": "Carregando os pacotes\n\nlibrary(gsheet)\nlibrary(tidyverse)\nlibrary(performance)\nlibrary(DHARMa)\nlibrary(emmeans)\nlibrary(multcomp)\nlibrary(multcompView)",
    "crumbs": [
      "Home",
      "Aula 07",
      "Estatística inferencial - Análise de variância"
    ]
  },
  {
    "objectID": "Aula 7.1.html#exemplo-de-análise-de-variância-anova",
    "href": "Aula 7.1.html#exemplo-de-análise-de-variância-anova",
    "title": "Aula 07 - Estatística inferencial - Análise de variância",
    "section": "Exemplo de Análise de Variância (ANOVA)",
    "text": "Exemplo de Análise de Variância (ANOVA)\nPara realizar a análise de variância (ANOVA), será carregado um conjunto de dados presente no R (conjunto InsectSprays), que será atribuído a um objeto:\n\ninseticida &lt;- InsectSprays\n\ninseticida %&gt;% \n  count(spray)\n\n  spray  n\n1     A 12\n2     B 12\n3     C 12\n4     D 12\n5     E 12\n6     F 12\n\n\nCom a fórmula count, identificamos que nesse conjunto de dados há um fator (inseticida), com 6 níveis (tipos de inseticidas), cada nível com 12 observações.",
    "crumbs": [
      "Home",
      "Aula 07",
      "Estatística inferencial - Análise de variância"
    ]
  },
  {
    "objectID": "Aula 7.1.html#explorando-o-conjunto",
    "href": "Aula 7.1.html#explorando-o-conjunto",
    "title": "Aula 07 - Estatística inferencial - Análise de variância",
    "section": "Explorando o conjunto",
    "text": "Explorando o conjunto\n\ninseticida %&gt;%\n  ggplot(aes(spray, count))+\n  geom_boxplot(width = 0.5)\n\n\n\n\n\n\n\n\nCom o boxplot gerado, é possível notar que há tratamentos que diferem dos demais.",
    "crumbs": [
      "Home",
      "Aula 07",
      "Estatística inferencial - Análise de variância"
    ]
  },
  {
    "objectID": "Aula 7.1.html#ajustar-o-modelo-para-anova",
    "href": "Aula 7.1.html#ajustar-o-modelo-para-anova",
    "title": "Aula 07 - Estatística inferencial - Análise de variância",
    "section": "Ajustar o modelo para ANOVA",
    "text": "Ajustar o modelo para ANOVA\nPara realizar a ANOVA é preciso ajustar um modelo (lm). Isso é necessário para que os resíduos possam ser aplicados nos testes para verificação das premissas da anova. O modelo será atribuído a um objeto.\n\nm1 &lt;- lm(count~spray, data = inseticida)\nsummary(m1)\n\n\nCall:\nlm(formula = count ~ spray, data = inseticida)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-8.333 -1.958 -0.500  1.667  9.333 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  14.5000     1.1322  12.807  &lt; 2e-16 ***\nsprayB        0.8333     1.6011   0.520    0.604    \nsprayC      -12.4167     1.6011  -7.755 7.27e-11 ***\nsprayD       -9.5833     1.6011  -5.985 9.82e-08 ***\nsprayE      -11.0000     1.6011  -6.870 2.75e-09 ***\nsprayF        2.1667     1.6011   1.353    0.181    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 3.922 on 66 degrees of freedom\nMultiple R-squared:  0.7244,    Adjusted R-squared:  0.7036 \nF-statistic:  34.7 on 5 and 66 DF,  p-value: &lt; 2.2e-16\n\n\n\nANOVA\nUma vez definido o modelo, ele será utilizado como um argumento na função anova:\n\nanova(m1)\n\nAnalysis of Variance Table\n\nResponse: count\n          Df Sum Sq Mean Sq F value    Pr(&gt;F)    \nspray      5 2668.8  533.77  34.702 &lt; 2.2e-16 ***\nResiduals 66 1015.2   15.38                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nCom a análise de variância e interpretação da estatística “F” é possível dizer que dentre os tratamentos, há algum que difere estatisticamente dos demais.",
    "crumbs": [
      "Home",
      "Aula 07",
      "Estatística inferencial - Análise de variância"
    ]
  },
  {
    "objectID": "Aula 7.1.html#avaliação-das-premissas",
    "href": "Aula 7.1.html#avaliação-das-premissas",
    "title": "Aula 07 - Estatística inferencial - Análise de variância",
    "section": "Avaliação das premissas",
    "text": "Avaliação das premissas\n\nEstratégia 1\nPrimeiro, será analisada a normalidade dos resíduos de maneira visual (função hist) e estatisticamente (função shapiro.test).\n\nhist(m1$residuals)\n\n\n\n\n\n\n\nshapiro.test(m1$residuals)\n\n\n    Shapiro-Wilk normality test\n\ndata:  m1$residuals\nW = 0.96006, p-value = 0.02226\n\n\nApesar do histograma possuir aspecto de normalidade, o teste de Shapiro-Wilk demonstra que os resíduos não possuem normalidade (valor de P = 0.02).\n\nA normalidade também pode ser avaliada visualmente em um gráifco Q-Q, com as funções qqnorm e qqline:\n\nqqnorm(m1$residuals)\nqqline(m1$residuals)\n\n\n\n\n\n\n\n\nO gráfico Q-Q mostra que os pontos desviam da linha de normalidade apenas nas regiões extremas, o que justifica o fato do teste de Shapiro-Wilk ter rejeitado a hipótese de normalidade dos resíduos.\n\n\nEm sequência, com o teste de Bartlett (bartlett.test), será avaliada a homogeneidade das variâncias entre os grupos:\n\nbartlett.test(count ~ spray,\n              data = inseticida)\n\n\n    Bartlett test of homogeneity of variances\n\ndata:  count by spray\nBartlett's K-squared = 25.96, df = 5, p-value = 9.085e-05\n\n\nO teste de Bartlett demonstra que as variâncias são heterogêneas, pois valor de P é menor que 0.01.\n\n\nEstratégia 2\nUsando o pacote performance:\n\ncheck_normality(m1)\n\nWarning: Non-normality of residuals detected (p = 0.022).\n\n\n\ncheck_heteroscedasticity(m1)\n\nWarning: Heteroscedasticity (non-constant error variance) detected (p &lt; .001).\n\n\nO testes check_normality e check_heteroscedasticity resultaram em não normalidade dos resíduos e heterocedasticidade entre os grupos.\n\n\nEstratégia 3\nCom o pacote DHARMa:\n\nplot(simulateResiduals(m1))\n\n\n\n\n\n\n\n\nDa mesma forma que as estratégias anteriores, aqui observa-se falta de normalidade e homogeneidade entre as variâncias dos grupos.",
    "crumbs": [
      "Home",
      "Aula 07",
      "Estatística inferencial - Análise de variância"
    ]
  },
  {
    "objectID": "Aula 6.1.html",
    "href": "Aula 6.1.html",
    "title": "Aula 06 - Estatística inferencial - Teste t",
    "section": "",
    "text": "Nesta aula serão apresentados alguns passos para condução da estatística inferencial. Inicialmente, serão conduzidos teste-t e, brevemente, alguns passos para realizar uma análise de variância (ANOVA).",
    "crumbs": [
      "Home",
      "Aula 06",
      "Estatística inferencial - Teste t"
    ]
  },
  {
    "objectID": "Aula 6.1.html#obtenção-dos-dados",
    "href": "Aula 6.1.html#obtenção-dos-dados",
    "title": "Aula 06 - Estatística inferencial - Teste t",
    "section": "Obtenção dos dados",
    "text": "Obtenção dos dados\nOs dados serão importados de uma planilha online, utilizado a ferramenta gsheet2tbl (gsheet). O conjunto de dados é referente a avaliação do efeito da suplementação de magnésio (Mg2) sobre o comprimento de lesões.\n\nmg &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=983033137\")\n\nglimpse(mg)\n\nRows: 20\nColumns: 3\n$ trat &lt;chr&gt; \"Mg2\", \"Mg2\", \"Mg2\", \"Mg2\", \"Mg2\", \"Mg2\", \"Mg2\", \"Mg2\", \"Mg2\", \"M…\n$ rep  &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10\n$ comp &lt;dbl&gt; 9.00, 12.50, 10.00, 8.00, 13.20, 11.00, 10.80, 9.50, 10.80, 10.40…",
    "crumbs": [
      "Home",
      "Aula 06",
      "Estatística inferencial - Teste t"
    ]
  },
  {
    "objectID": "Aula 6.1.html#análise-dos-dados",
    "href": "Aula 6.1.html#análise-dos-dados",
    "title": "Aula 06 - Estatística inferencial - Teste t",
    "section": "Análise dos dados",
    "text": "Análise dos dados\nInicialmente, será feito um gráfico do tipo boxplot para analisarmos o conjunto de dados visualmente.\n\nmg %&gt;% \n  ggplot(aes(trat, comp))+\n  geom_boxplot(width = 0.5)\n\n\n\n\n\n\n\n\nO gráfico gerado sugere que há diferença no tamanho das lesões em função do tratamento avaliado. Onde a suplementação com Mg2 parece possuir efeito desejável, reduzindo o comprimento das lesões.\nAlém, o gráfico indica que os dados possuem distribuição normal, pois há simetria em ambos os retângulos; e que também homocedasticidade (homogeneidade das variâncias), já que os dois retângulos possuem tamanho semelhante.",
    "crumbs": [
      "Home",
      "Aula 06",
      "Estatística inferencial - Teste t"
    ]
  },
  {
    "objectID": "Aula 6.1.html#conversão-dos-dados",
    "href": "Aula 6.1.html#conversão-dos-dados",
    "title": "Aula 06 - Estatística inferencial - Teste t",
    "section": "Conversão dos dados",
    "text": "Conversão dos dados\nAntes de realizar o teste-t será preciso transformar a tabela para o formato largo (cada tratamento em uma coluna), para isso será utilizada a função pivot_wider (tidyr):\n\nmg2 &lt;- mg %&gt;%\n  pivot_wider(names_from = trat,\n              values_from = comp)\n\nglimpse(mg2)\n\nRows: 10\nColumns: 3\n$ rep     &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10\n$ Mg2     &lt;dbl&gt; 9.0, 12.5, 10.0, 8.0, 13.2, 11.0, 10.8, 9.5, 10.8, 10.4\n$ control &lt;dbl&gt; 13.72, 15.91, 15.70, 14.20, 15.90, 16.54, 18.00, 14.40, 16.41,…",
    "crumbs": [
      "Home",
      "Aula 06",
      "Estatística inferencial - Teste t"
    ]
  },
  {
    "objectID": "Aula 6.1.html#teste-t",
    "href": "Aula 6.1.html#teste-t",
    "title": "Aula 06 - Estatística inferencial - Teste t",
    "section": "Teste-t",
    "text": "Teste-t\n\nTeste-t para duas amostras independentes\nCom base no conjunto de dados recém transformado, será feito um teste t (função t.test, nativa do R) para duas amostras independentes.\n\nt.test(mg2$Mg2, mg2$control)\n\n\n    Welch Two Sample t-test\n\ndata:  mg2$Mg2 and mg2$control\nt = -8.1549, df = 17.354, p-value = 2.423e-07\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -6.490393 -3.825607\nsample estimates:\nmean of x mean of y \n   10.520    15.678 \n\n\nA partir do resultado do teste, podemos concluir há diferença significativa entre os tratamentos, pois o valor de P foi extretamente baixo (&lt; 0.01).\n\nVerificação das premissas\nPara termos confiança no teste realizado é preciso saber se os dados atendem algumas premissas: se há normalidade entre os conjuntos; e se os conjuntos possuem mesma variância.\n\n\nTeste de normalidade:\n\nHistogramas\nUma forma de se avaliar a normalidade visualmente é por meio de histograma:\n\n\nhist(mg2$control)\n\n\n\n\n\n\n\nhist(mg2$Mg2)\n\n\n\n\n\n\n\n\n\nQ-Q Plot de normalidade\nOutra opção é por meio de Q-Q plots:\n\n\nqqnorm(mg2$control)\nqqline(mg2$control)\n\n\n\n\n\n\n\n\n\nqqnorm(mg2$Mg2)\nqqline(mg2$Mg2)\n\n\n\n\n\n\n\n\n\nAvaliação estatística\nA avaliação também pode ser feita utilizando testes estatísticos. Nesse caso, será aplicada a função shapiro.test (nativa do R):\n\n\nshapiro.test(mg2$control)\n\n\n    Shapiro-Wilk normality test\n\ndata:  mg2$control\nW = 0.93886, p-value = 0.5404\n\nshapiro.test(mg2$Mg2)\n\n\n    Shapiro-Wilk normality test\n\ndata:  mg2$Mg2\nW = 0.97269, p-value = 0.9146\n\n\nAmbas as metodologias demonstram que os dados possuem distribuição normal. Os histogramas possuem formato típico de um conjunto de dados normais. Nos Q-Q Plots, é possível notar que os pontos estão próximo a linha de normalidade. E pelos testes de Shapiro Wilk, não se rejeita a hipótese nula (de normalidade), já que valor de P é maior que o nível de significância adotado (⍺ = 5%).\n\n\nTeste de homogeneidade\nPara avaliação da homogeneidade entre as variâncias será utilizada a função var.test (também nativa do R):\n\nvar.test(mg2$control, mg2$Mg2)\n\n\n    F test to compare two variances\n\ndata:  mg2$control and mg2$Mg2\nF = 0.67654, num df = 9, denom df = 9, p-value = 0.5698\nalternative hypothesis: true ratio of variances is not equal to 1\n95 percent confidence interval:\n 0.1680428 2.7237436\nsample estimates:\nratio of variances \n         0.6765394 \n\n\nCom o resultado do teste não rejeitamos a hipótese nula (de homogeneidade entre as amostras), pois o valor de probabilidade é superior a 5%. Logo, os tratamentos possuem mesma variância.\n\nCom isso (dados normais, com variâncias homogêneas), podemos confiar no teste-t realizado.\n\n\nApresentação dos resultados\nA função report (report) pode ser utilizada para gerar um modelo de texto, reportando os resultados obtidos. Para isso atribuímos o teste-t a um objeto e em sequência executamos a função.\n\nteste1 &lt;- t.test(mg2$Mg2, mg2$control)\nreport(teste1)\n\nEffect sizes were labelled following Cohen's (1988) recommendations.\n\nThe Welch Two Sample t-test testing the difference between mg2$Mg2 and\nmg2$control (mean of x = 10.52, mean of y = 15.68) suggests that the effect is\nnegative, statistically significant, and large (difference = -5.16, 95% CI\n[-6.49, -3.83], t(17.35) = -8.15, p &lt; .001; Cohen's d = -3.65, 95% CI [-5.12,\n-2.14])\n\n\n\n\n\nTeste-t para duas amostras dependentes\nPara demonstrar a aplicação do test-t pareado (ou para amostras dependentes), utilizaremos um conjunto de dados no qual há resultados de avaliação de doenças antes e após o uso de uma escala de doenças, logo o objetivo será determinar se o uso da escala desempenha algum efeito sobre as avaliações.\n\n\n\nQuando há distribuição normal\n\nObtenção, visualização e seleção dos dados\nOs dados serão obtidos de uma planilha excel:\n\nescala &lt;- readxl::read_excel(\"dados-diversos.xlsx\",\n                             sheet = \"escala\")\n\nglimpse(escala)\n\nRows: 20\nColumns: 7\n$ assessment       &lt;chr&gt; \"Unaided\", \"Unaided\", \"Unaided\", \"Unaided\", \"Unaided\"…\n$ rater            &lt;chr&gt; \"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\", \"H\", \"I\", \"J\", \"A\"…\n$ acuracia         &lt;dbl&gt; 0.8092131, 0.7219848, 0.5595983, 0.8175313, 0.7476691…\n$ precisao         &lt;dbl&gt; 0.8262697, 0.7284040, 0.7149415, 0.8187018, 0.7532589…\n$ vies_geral       &lt;dbl&gt; 0.9793570, 0.9911874, 0.7827190, 0.9985702, 0.9925792…\n$ vies_sistematico &lt;dbl&gt; 1.1872167, 0.9217054, 1.1600785, 0.9481874, 1.1038873…\n$ vies_constante   &lt;dbl&gt; 0.1123982, -0.1055045, 0.7301412, -0.0056930, 0.07194…\n\n\nEm seguida, será feito um boxplot para rápida visualização do conjunto de dados:\n\nescala %&gt;%\n  ggplot(aes(assessment, acuracia))+\n  geom_boxplot(width = 0.4)\n\n\n\n\n\n\n\n\nPara condução dos testes, serão selecionadas as colunas “assessment”, “rater” e “acuracia”, que serão colocados no formato largo.\n\nescala2 &lt;- escala %&gt;%\n  dplyr::select( assessment, rater, acuracia) %&gt;% \n  pivot_wider(names_from = assessment,\n              values_from = acuracia)\n\nglimpse(escala2)\n\nRows: 10\nColumns: 3\n$ rater   &lt;chr&gt; \"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\", \"H\", \"I\", \"J\"\n$ Unaided &lt;dbl&gt; 0.8092131, 0.7219848, 0.5595983, 0.8175313, 0.7476691, 0.69491…\n$ Aided1  &lt;dbl&gt; 0.9067211, 0.9126980, 0.9148087, 0.9598576, 0.9593181, 0.90277…\n\n\n\n\nTestar as premissas\n\n\nTeste de normalidade\nA avaliação da normalidade será feita estatisticamente, pelo teste de Shapiro Wilk, com valor de significância (⍺) de 5%:\n\nshapiro.test(escala2$Unaided)\n\n\n    Shapiro-Wilk normality test\n\ndata:  escala2$Unaided\nW = 0.87462, p-value = 0.1131\n\nshapiro.test(escala2$Aided1)\n\n\n    Shapiro-Wilk normality test\n\ndata:  escala2$Aided1\nW = 0.92775, p-value = 0.4261\n\n\nPara ambos os tratamentos há normalidade, já que os valores de P foram superiores a 5%.\n\n\n\nTeste de homogeneidade\nPara avaliação da homogeneidade entre as variâncias, usaremos o teste de variância:\n\nvar.test(escala2$Unaided, escala2$Aided1)\n\n\n    F test to compare two variances\n\ndata:  escala2$Unaided and escala2$Aided1\nF = 5.8683, num df = 9, denom df = 9, p-value = 0.01461\nalternative hypothesis: true ratio of variances is not equal to 1\n95 percent confidence interval:\n  1.457601 23.625712\nsample estimates:\nratio of variances \n          5.868293 \n\n\nO teste de variância demonstra que não há homogeneidade entre os conjuntos de dados, pois o valor de P é menor que 0,05 (5%). Logo, será preciso indicar no teste t que há heterogeneidade.\n\n\n\nTeste t pareado\nComo demonstrado acima, os dados possuem distribuição normal, portanto ainda é possível utilizar um teste paramétrico. No entanto, não há homogeneidade de variâncias, o que precisará ser indicado na construção da função.\nPara executar o teste t pareado utiliza-se a mesma função (t.test), incluindo dois parâmetros:\n\npaired = TRUE, para indicar amostras dependentes (ou pareadas);\ne var.equal = FALSE , para indicar heterocedasticidade.\n\n\nt.test(escala2$Aided1,escala2$Unaided,\n       paired = TRUE,\n       var.equal = FALSE)\n\n\n    Paired t-test\n\ndata:  escala2$Aided1 and escala2$Unaided\nt = 5.9364, df = 9, p-value = 0.000219\nalternative hypothesis: true mean difference is not equal to 0\n95 percent confidence interval:\n 0.1144707 0.2554241\nsample estimates:\nmean difference \n      0.1849474 \n\n\nCom o teste, é possível concluir que o uso da escala teve efeito sobre a acurácia dos avaliadores (P-valor = 0.000219), onde foi perceptível um aumento de acurácia após o uso da assistência.\n\n\n\n\nQuando não há distribuição normal: teste não paramétrico\nPara demonstrar essa situação será utilizado um conjunto de dados similar ao exemplo anterior. No entanto, com alguns valores alterados para não possuir mais distribuição normal.\n\nObtenção, visualização e seleção dos dados\n\nescala3 &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=1729131173\")\n\n\nescala3 %&gt;%\n  ggplot(aes(assessment, acuracia))+\n  geom_boxplot(width = 0.4)\n\n\n\n\n\n\n\n\n\nescala4 &lt;- escala3 %&gt;%\n  dplyr::select(assessment, rater, acuracia) %&gt;% \n  pivot_wider(names_from = assessment,\n              values_from = acuracia)\n\n\n\nTestar as premissas\n\n\nTeste de normalidade\n\nshapiro.test(escala4$Unaided)\n\n\n    Shapiro-Wilk normality test\n\ndata:  escala4$Unaided\nW = 0.7748, p-value = 0.007155\n\nshapiro.test(escala4$Aided1)\n\n\n    Shapiro-Wilk normality test\n\ndata:  escala4$Aided1\nW = 0.92852, p-value = 0.4335\n\n\nO teste mostra que não há normalidade para o tratamento “unaided” (valor de p &lt; 0.05), logo será preciso realizar um teste não paramétrico.\n\n\n\nTeste de Wilcox\nComo o conjunto de dados não possui distribuição normal, será utilizado o teste de Wilcox (wilcox.test). Um teste não paramétrico para amostras dependentes.\n\nwilcox.test(escala4$Aided1,\n            escala4$Unaided,\n            paired = TRUE)\n\n\n    Wilcoxon signed rank test with continuity correction\n\ndata:  escala4$Aided1 and escala4$Unaided\nV = 55, p-value = 0.005889\nalternative hypothesis: true location shift is not equal to 0\n\n\nSimilarmente a situação de normalidade, o teste de Wilcox demonstra que há diferença significativa entre as amostras (P = 0.005 &lt; ⍺ = 0.05), onde o uso da escala influencia positivamente a acurácia dos avaliadores.",
    "crumbs": [
      "Home",
      "Aula 06",
      "Estatística inferencial - Teste t"
    ]
  },
  {
    "objectID": "Aula 4.2.html",
    "href": "Aula 4.2.html",
    "title": "Aula 04 - Tabela de contingência",
    "section": "",
    "text": "A seguir, serão construídas tabelas de contingências. São tabelas que permitem fazer contagens de elementos/ ocorrências de variáveis categóricas dentro de uma mesma coluna rapidamente.\n\n\nOs dados utilizados neste exemplo serão obtidos de uma planilha on-line:\n\ncr &lt;- read.csv(\"https://raw.githubusercontent.com/emdelponte/paper-coffee-rust-Ethiopia/master/data/survey_clean.csv\")\n\n\n\n\nUtilizando a função count (dplyr) é possível contar os valores únicos (níveis) dentro de uma coluna específica (fator).\n\ncr %&gt;%\n  count(region)\n\n  region   n\n1 Oromia 165\n2  SNNPR 240\n\ncr %&gt;% \n  count(zone)\n\n          zone  n\n1         Bale 30\n2   Bench Maji 45\n3        Gedio 45\n4  Ilu AbaBora 45\n5        Jimma 45\n6        Keffa 45\n7        Sheka 45\n8       Sidama 60\n9 West Wellega 45\n\n\n\nTambém é possível contar as ocorrências únicas combinando dois fatores.\n\ncr %&gt;%\n  count(region,zone)\n\n  region         zone  n\n1 Oromia         Bale 30\n2 Oromia  Ilu AbaBora 45\n3 Oromia        Jimma 45\n4 Oromia West Wellega 45\n5  SNNPR   Bench Maji 45\n6  SNNPR        Gedio 45\n7  SNNPR        Keffa 45\n8  SNNPR        Sheka 45\n9  SNNPR       Sidama 60\n\n\n\n\n\nDentro do pacote janitor há a função tabyl, que gera uma tabela de frequências\n\ncr %&gt;% \n  tabyl(region)\n\n region   n   percent\n Oromia 165 0.4074074\n  SNNPR 240 0.5925926\n\ncr %&gt;% \n  tabyl(cultivar, farm_management)\n\n cultivar Intensive Minimal Moderate Unmanaged\n Improved        83       0        0         0\n    Local         0      10        4       102\n  Mixture        82      59       65         0\n\n\n\n\n\nPara avaliar visualmente a ocorrência dos tipos de manejo para cada cultivar, construiremos um gráfico de barras:\n\ncr %&gt;%\n  count(farm_management, cultivar) %&gt;% \n  ggplot(aes(cultivar, n, fill = farm_management))+\n  geom_col(position = \"dodge2\")\n\n\n\n\n\n\n\n\nTambém é possível construir um gráfico com a mesma ideia utilizando a função facet_wrap:\n\ncr %&gt;%\n  count(farm_management, cultivar) %&gt;% \n  ggplot(aes(cultivar, n, fill = farm_management, label = n))+\n  geom_col(position = \"dodge2\")+\n  geom_text(position = position_dodge(width = 0.9))+\n  theme_bw()+\n  facet_wrap(~cultivar, scales = \"free_x\")+\n    theme(strip.text.x = element_blank(),\n          legend.position = \"top\")\n\n\n\n\n\n\n\n\n\n___________\n\nlibrary(gsheet)\ndata &lt;- gsheet::gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1aID5Dh6PlBVCKzU1j7k-WA6zuWQWE2NhtWEgdJtt5iA/edit#gid=921203844\")\n\n\ndata %&gt;%\n  group_by(trat) %&gt;%\n  ggplot(aes(trat, comp))+\n  geom_jitter(width = 0.1)\n\n\n\n\n\n\n\n\n\ndata %&gt;%\n  group_by(trat) %&gt;%\n  summarise(mean_comp = mean(comp),\n            sd_comp = sd(comp)) %&gt;%\n  ggplot(aes(trat, mean_comp))+\n  #geom_col(fill = \"steelblue\", width = 0.5)+\n  geom_point(size = 2)+\n  ylim (5,20)+\n  geom_errorbar(aes(ymin = mean_comp - sd_comp,\n                    ymax = mean_comp + sd_comp),\n                width = 0.2)+\n  annotate(geom = \"text\",\n           x = 1,\n           y = 18,\n           label = \"*\", size =5)+\n  labs(\n    y = \"Mean Comp\")",
    "crumbs": [
      "Home",
      "Aula 04",
      "Tabela de contingência"
    ]
  },
  {
    "objectID": "Aula 4.2.html#tabela-de-contingência",
    "href": "Aula 4.2.html#tabela-de-contingência",
    "title": "Aula 04 - Tabela de contingência",
    "section": "",
    "text": "A seguir, serão construídas tabelas de contingências. São tabelas que permitem fazer contagens de elementos/ ocorrências de variáveis categóricas dentro de uma mesma coluna rapidamente.\n\n\nOs dados utilizados neste exemplo serão obtidos de uma planilha on-line:\n\ncr &lt;- read.csv(\"https://raw.githubusercontent.com/emdelponte/paper-coffee-rust-Ethiopia/master/data/survey_clean.csv\")\n\n\n\n\nUtilizando a função count (dplyr) é possível contar os valores únicos (níveis) dentro de uma coluna específica (fator).\n\ncr %&gt;%\n  count(region)\n\n  region   n\n1 Oromia 165\n2  SNNPR 240\n\ncr %&gt;% \n  count(zone)\n\n          zone  n\n1         Bale 30\n2   Bench Maji 45\n3        Gedio 45\n4  Ilu AbaBora 45\n5        Jimma 45\n6        Keffa 45\n7        Sheka 45\n8       Sidama 60\n9 West Wellega 45\n\n\n\nTambém é possível contar as ocorrências únicas combinando dois fatores.\n\ncr %&gt;%\n  count(region,zone)\n\n  region         zone  n\n1 Oromia         Bale 30\n2 Oromia  Ilu AbaBora 45\n3 Oromia        Jimma 45\n4 Oromia West Wellega 45\n5  SNNPR   Bench Maji 45\n6  SNNPR        Gedio 45\n7  SNNPR        Keffa 45\n8  SNNPR        Sheka 45\n9  SNNPR       Sidama 60\n\n\n\n\n\nDentro do pacote janitor há a função tabyl, que gera uma tabela de frequências\n\ncr %&gt;% \n  tabyl(region)\n\n region   n   percent\n Oromia 165 0.4074074\n  SNNPR 240 0.5925926\n\ncr %&gt;% \n  tabyl(cultivar, farm_management)\n\n cultivar Intensive Minimal Moderate Unmanaged\n Improved        83       0        0         0\n    Local         0      10        4       102\n  Mixture        82      59       65         0\n\n\n\n\n\nPara avaliar visualmente a ocorrência dos tipos de manejo para cada cultivar, construiremos um gráfico de barras:\n\ncr %&gt;%\n  count(farm_management, cultivar) %&gt;% \n  ggplot(aes(cultivar, n, fill = farm_management))+\n  geom_col(position = \"dodge2\")\n\n\n\n\n\n\n\n\nTambém é possível construir um gráfico com a mesma ideia utilizando a função facet_wrap:\n\ncr %&gt;%\n  count(farm_management, cultivar) %&gt;% \n  ggplot(aes(cultivar, n, fill = farm_management, label = n))+\n  geom_col(position = \"dodge2\")+\n  geom_text(position = position_dodge(width = 0.9))+\n  theme_bw()+\n  facet_wrap(~cultivar, scales = \"free_x\")+\n    theme(strip.text.x = element_blank(),\n          legend.position = \"top\")\n\n\n\n\n\n\n\n\n\n___________\n\nlibrary(gsheet)\ndata &lt;- gsheet::gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1aID5Dh6PlBVCKzU1j7k-WA6zuWQWE2NhtWEgdJtt5iA/edit#gid=921203844\")\n\n\ndata %&gt;%\n  group_by(trat) %&gt;%\n  ggplot(aes(trat, comp))+\n  geom_jitter(width = 0.1)\n\n\n\n\n\n\n\n\n\ndata %&gt;%\n  group_by(trat) %&gt;%\n  summarise(mean_comp = mean(comp),\n            sd_comp = sd(comp)) %&gt;%\n  ggplot(aes(trat, mean_comp))+\n  #geom_col(fill = \"steelblue\", width = 0.5)+\n  geom_point(size = 2)+\n  ylim (5,20)+\n  geom_errorbar(aes(ymin = mean_comp - sd_comp,\n                    ymax = mean_comp + sd_comp),\n                width = 0.2)+\n  annotate(geom = \"text\",\n           x = 1,\n           y = 18,\n           label = \"*\", size =5)+\n  labs(\n    y = \"Mean Comp\")",
    "crumbs": [
      "Home",
      "Aula 04",
      "Tabela de contingência"
    ]
  },
  {
    "objectID": "Aula 3.html",
    "href": "Aula 3.html",
    "title": "Aula 03 - Estatísticas descritivas e construção de gráficos simples",
    "section": "",
    "text": "Nesa aula, serão apresentadas ferramentas para se realizar uma análise descritiva do conjunto de dados. Além disso, o pacote tidyverse será utilizado para manipulação, criação de subconjuntos e organização dos dados. Por fim, ao longo da aula será demonstrado como criar gráficos simples.",
    "crumbs": [
      "Home",
      "Aula 03",
      "Estatísticas descritivas e construção de gráficos simples"
    ]
  },
  {
    "objectID": "Aula 3.html#carregando-pacotes-importando-os-dados-e-resumo-estatístico",
    "href": "Aula 3.html#carregando-pacotes-importando-os-dados-e-resumo-estatístico",
    "title": "Aula 03 - Estatísticas descritivas e construção de gráficos simples",
    "section": "Carregando pacotes, importando os dados e resumo estatístico",
    "text": "Carregando pacotes, importando os dados e resumo estatístico\nPrimeiro, será feito o carregamento dos pacotes:\n\nlibrary(tidyverse)\nlibrary(ggplot2)\nlibrary(ggthemes)\nlibrary(patchwork)\n\n\nOs dados utlizados serão importados de um arquivo .csv disponível em nuvem.\nResumidamente, o arquivo traz valores de incidência e severidade da ferrugem do cafeeiro em diferentes regiões da Etiópia, de acordo com o sistema de cultivo, manejo da fazenda, sombreamento, cultivar, etc.:\n\ncr &lt;- read_csv(\"https://raw.githubusercontent.com/emdelponte/paper-coffee-rust-Ethiopia/master/data/survey_clean.csv\")\n\n\nPara uma visualização rápida dos dados, será utilizada a função glimpse:\n\nglimpse(cr)\n\nRows: 405\nColumns: 13\n$ farm            &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16,…\n$ region          &lt;chr&gt; \"SNNPR\", \"SNNPR\", \"SNNPR\", \"SNNPR\", \"SNNPR\", \"SNNPR\", …\n$ zone            &lt;chr&gt; \"Bench Maji\", \"Bench Maji\", \"Bench Maji\", \"Bench Maji\"…\n$ district        &lt;chr&gt; \"Debub Bench\", \"Debub Bench\", \"Debub Bench\", \"Debub Be…\n$ lon             &lt;dbl&gt; 35.44250, 35.44250, 35.42861, 35.42861, 35.42861, 35.3…\n$ lat             &lt;dbl&gt; 6.904722, 6.904722, 6.904444, 6.904444, 6.904444, 6.90…\n$ altitude        &lt;dbl&gt; 1100, 1342, 1434, 1100, 1400, 1342, 1432, 1100, 1400, …\n$ cultivar        &lt;chr&gt; \"Local\", \"Mixture\", \"Mixture\", \"Local\", \"Local\", \"Mixt…\n$ shade           &lt;chr&gt; \"Sun\", \"Mid shade\", \"Mid shade\", \"Sun\", \"Sun\", \"Mid sh…\n$ cropping_system &lt;chr&gt; \"Plantation\", \"Plantation\", \"Plantation\", \"Plantation\"…\n$ farm_management &lt;chr&gt; \"Unmanaged\", \"Minimal\", \"Minimal\", \"Unmanaged\", \"Unman…\n$ inc             &lt;dbl&gt; 86.70805, 51.34354, 43.20000, 76.70805, 47.15808, 51.3…\n$ sev2            &lt;dbl&gt; 55.57986, 17.90349, 8.25120, 46.10154, 12.25167, 19.91…\n\n\n\nA seguir, uma breve descrição estatística dos valores de incidência, com uso da função summary:\n\nsummary(cr$inc)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   9.50   19.43   32.50   34.89   48.20   86.71 \n\n\n\nDos valores de severidade, com uso da função summary:\n\nsummary(cr$sev2)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n 0.2248  2.6892  5.9490  9.0945 12.1593 55.5799",
    "crumbs": [
      "Home",
      "Aula 03",
      "Estatísticas descritivas e construção de gráficos simples"
    ]
  },
  {
    "objectID": "Aula 3.html#resumo-gráfico-geral-do-dataset",
    "href": "Aula 3.html#resumo-gráfico-geral-do-dataset",
    "title": "Aula 03 - Estatísticas descritivas e construção de gráficos simples",
    "section": "Resumo gráfico geral do dataset",
    "text": "Resumo gráfico geral do dataset\nPara uma visualização gráfica dos valores de incidência será criado um histograma:\n\ncr %&gt;%\n  ggplot(aes(x = inc))+\n  geom_histogram ()\n\n\n\n\n\n\n\n\n\nNo histograma gerado, é possível notar que os valores de incidência apresentam três picos (ou seja, são valores de incidência com maior frequência). Além disso, a incidência aparenta não seguir distribuição normal, uma vez que o histograma apresenta um deslocamento à esquerda.\n\nÉ possível criar histogramas por algum critério, por exemplo, as regiões.\nPara isso, será utilizada a função facet_wrap:\n\ncr %&gt;% ggplot(aes(x = inc))+\n  geom_histogram()+\n  facet_wrap(~region)\n\n\n\n\n\n\n\n\nAo analisar os histogramas em função das regiões, é possível notar que na região de Oromia, os valores de incidência são mais frequentes em torno do centro da distribuição. Já na região de SNNPR, as incidências mais frequentes são inferiores a 25%.\n\nTambém serão criados boxplots, divididos por regiões:\n\ncr %&gt;% ggplot(aes(x = inc,))+\n  geom_boxplot()+\n  facet_wrap(~region)+\n  coord_flip()+\n  labs (x = \"Incidence (%)\")",
    "crumbs": [
      "Home",
      "Aula 03",
      "Estatísticas descritivas e construção de gráficos simples"
    ]
  },
  {
    "objectID": "Aula 3.html#estatistícas-descritivas-dos-dados-por-variável",
    "href": "Aula 3.html#estatistícas-descritivas-dos-dados-por-variável",
    "title": "Aula 03 - Estatísticas descritivas e construção de gráficos simples",
    "section": "Estatistícas descritivas dos dados por variável",
    "text": "Estatistícas descritivas dos dados por variável\nPara o agrupamento dos valores em função de uma variável, utiliza-se a função group_by:\n\nAnálise da incidência\n\ncr %&gt;% group_by(cultivar) %&gt;% \n  summarise(inc_mean = mean(inc),\n            inc_median = median(inc),\n            sd_mean = sd(inc))\n\n# A tibble: 3 × 4\n  cultivar inc_mean inc_median sd_mean\n  &lt;chr&gt;       &lt;dbl&gt;      &lt;dbl&gt;   &lt;dbl&gt;\n1 Improved     16.4       15.2    5.66\n2 Local        53.4       50.9   14.3 \n3 Mixture      31.9       31.6   11.2 \n\n\n\n\nComparação da incidência versus severidade\nPara avaliar a correlação de duas variáveis respostas, é possível lançar mão de um gráfico de pontos, plotando nos eixos as variáveis desejadas:\n\ncr %&gt;% \n  ggplot(aes(x = inc, y = sev2))+\n  geom_point()+\n  labs(x = \"Incidence (%)\",\n       y = \"Severity (%)\")\n\n\n\n\n\n\n\n\nNo gráfico gerado é possível observar que há alta correlação positiva entre as variáveis severidade e incidência.\n\n\n\n\nAnálise da severidade\nSerão realizadas análises de severidade em função da região e, em seguida, da cultivar. Para isso, a função group_by será utilizada mais uma vez.\n\n\n\nSeveridade por região\nPara conhecer a média, desvio-padrão e mediana será utilizada a função summarise:\n\ncr %&gt;% group_by(region) %&gt;% \n  summarise(mean_sev = mean(sev2),\n            med_sev = median(sev2),\n            sev_sd = sd(sev2))\n\n# A tibble: 2 × 4\n  region mean_sev med_sev sev_sd\n  &lt;chr&gt;     &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;\n1 Oromia     8.06    6.23   6.82\n2 SNNPR      9.81    4.88  10.5 \n\n\n\nEm sequência, serão gerados histogramas por região utilizado a função face_wrap:\n\ncr %&gt;% \n  ggplot(aes(sev2))+\n  geom_histogram()+\n  facet_wrap(~region)\n\n\n\n\n\n\n\n\n\n\nSeveridade por cultivar\nSeguindo a mesma lógica do item anterior, será feito avaliação da severidade por cultivares:\n\ncr %&gt;%\n  group_by(cultivar) %&gt;%\n  summarise(mean_sev = mean(sev2),\n            med_sev = median(sev2),\n            sd_sev = sd(sev2))\n\n# A tibble: 3 × 4\n  cultivar mean_sev med_sev sd_sev\n  &lt;chr&gt;       &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;\n1 Improved     2.16    1.64   1.82\n2 Local       18.7    17.2   11.1 \n3 Mixture      6.47    5.43   4.35\n\n\n\ncr %&gt;%\n  ggplot(aes(sev2))+\n  geom_histogram()+\n  facet_wrap(~cultivar)\n\n\n\n\n\n\n\n\n\n\nSeveridade por região e cultivar\nAgora, será gerado um histograma da severidade em função de duas variáveis independentes, a região e a cultivar. Nesse caso, primeiro será utilizada a função facet_wrap e depois a função facet_grid:\n\ncr %&gt;% ggplot(aes(x = sev2))+\n  geom_histogram()+\n  facet_wrap(region ~ cultivar)\n\n\n\n\n\n\n\ncr %&gt;%\n  ggplot(aes(sev2))+\n  geom_histogram()+\n  facet_grid(~region~cultivar)\n\n\n\n\n\n\n\n\nÉ possível notar que com a função facet_grid, o plot se torna mais harmônico…\n\n\ng1 &lt;- cr %&gt;% ggplot(aes(x = sev2, fill = region))+\n  geom_histogram(color = \"white\")+\n  facet_grid(region ~ cultivar)+\n  #scale_fill_manual(values = c(\"blue\", \"red\"))+ #Para atribuir cores manualmente.\n  theme(legend.position = \"bottom\")+\n  labs(x = \"Frequency\",\n       y = \"Severity (%)\",\n       fill = \"Region\")\n\n\nPara salvar o plot gerado:\n\nggsave(\"cr.png\", bg = \"white\")",
    "crumbs": [
      "Home",
      "Aula 03",
      "Estatísticas descritivas e construção de gráficos simples"
    ]
  },
  {
    "objectID": "Aula 3.html#criando-subconjuntos",
    "href": "Aula 3.html#criando-subconjuntos",
    "title": "Aula 03 - Estatísticas descritivas e construção de gráficos simples",
    "section": "Criando subconjuntos",
    "text": "Criando subconjuntos\nPara criação de subconjuntos, serão utilizadas duas funções: select e filter.\nA função select faz seleção das colunas em que se deseja trabalhar. Para utilizar essa função, basta colocar como argumentos os títulos das colunas que serão selecionadas.\njá a função filter é responsável por buscar e filtrar, nas linhas, uma informação de interesse. Nesse caso, inicialmente é preciso indicar em qual coluna será feito o filtro, em seguida é indicada a informação de interesse.\nImportante: para o que software busque essa informação é preciso utilizar ==.\n\n\nSerão criados dois subconjuntos apresentando a severidade em função das regiões.\n\nOromia &lt;- cr %&gt;% \n  select(farm, region, cultivar, sev2) %&gt;%\n  filter(region == \"Oromia\")\n\nSNPPR &lt;- cr %&gt;%\n  select(farm, region, cultivar, sev2) %&gt;%\n  filter(region == \"SNNPR\")\n\n\nVisualizando os subconjuntos graficamente:\nPara visualizar os subconjuntos recém-criados:\n\ng1 &lt;- Oromia %&gt;%\n  ggplot(aes(cultivar, sev2, fill = cultivar))+\n  geom_boxplot()+\n  labs(title = \"Oromia\",\n     x = \"Cultivar\",\n     y = \"Severity (%)\")\ng1\n\n\n\n\n\n\n\ng2 &lt;- SNPPR %&gt;%\n  ggplot(aes(cultivar, sev2, fill = cultivar))+\n  geom_boxplot()+\n  labs(title = \"SNPPR\",\n     x = \"Cultivar\",\n     y = \"Severity (%)\")\ng2\n\n\n\n\n\n\n\n\n\n\nCriando uma figura combinando os dois gráficos\nPara criar uma figura combinando os dois gráficos gerados anteriormente, será utilizado o pacote patchwork. É possível plotar um gráfico sobre outro\n\n(g1/g2) + plot_layout(guides = \"collect\")\n\n\n\n\n\n\n\n\nOu então um gráfico ao lado do outro\n\n(g1+g2) + \n  plot_layout(guides = \"collect\")+\n  plot_annotation(tag_levels = \"A\") #Para deixar mais apresentável, é possível                                          remover o título colocado no gráfico                                               anteriormente.\n\n\n\n\n\n\n\n\nTambém é possível inverter o modo como o boxplot é plotado, utilizando a função coord_flip:\n\ng3 &lt;- Oromia %&gt;% \n  ggplot(aes(cultivar, sev2, fill = cultivar))+\n  geom_boxplot()+\nlabs(x = \"\",\n     y = \"Severity (%)\")+\n  theme_classic()+\n  coord_flip()\ng3\n\n\n\n\n\n\n\ng4 &lt;- SNPPR %&gt;% \n  ggplot(aes(cultivar, sev2, fill = cultivar))+\n  geom_boxplot()+\nlabs(x = \"\",\n     y = \"Severity (%)\")+\n  theme_classic()+\n  coord_flip()\ng4\n\n\n\n\n\n\n\n(g3 / g4) + \n  plot_layout(guides = \"collect\", axis_titles = \"collect\")+\n  plot_annotation(title = \"Severity of coffee leaf rust in Ethiopia\",\n                   tag_levels = \"A\")\n\n\n\n\n\n\n\n\nPara o salvar o gráfico criado:\n\nggsave(\"grap2.png\", width = 10, height = 8)\n\nAlém disso, o pacote patchwork permite plotar um gráfico dentro do outro.\nPor exemplo, será criado uma figura apresentando um boxplot da severidade da ferrugem na região de Oromia em função das cultivares e também será apresentado um histograma da severidade nesta região:\n\ng5 &lt;- Oromia %&gt;% \n  ggplot(aes(cultivar, sev2, fill = cultivar))+\n  geom_boxplot()+\nlabs(x = \"\",\n     y = \"Severity (%)\",\n     fill = \"Cultivar\")+\n  theme_classic()+\n  coord_flip()\ng5\n\n\n\n\n\n\n\ng6 &lt;- Oromia %&gt;% \n  ggplot(aes(x = sev2))+\n  geom_histogram()+\n  labs(x = \"\", y = \"\")+\n  theme_classic()\ng6\n\n\n\n\n\n\n\ng5 + inset_element(g6, left = 0.5, bottom = 0.5, right = 1, top = 1)",
    "crumbs": [
      "Home",
      "Aula 03",
      "Estatísticas descritivas e construção de gráficos simples"
    ]
  },
  {
    "objectID": "Aula 2.1.html",
    "href": "Aula 2.1.html",
    "title": "Aula 02 - Importação de dados",
    "section": "",
    "text": "Nesta aula serão apresentadas formas de se importar (carregar) dados/ planilhas, a partir de diferentes fontes, e como fazer uma análise visual rápida dos dados obtidos.",
    "crumbs": [
      "Home",
      "Aula 02",
      "Importação de dados"
    ]
  },
  {
    "objectID": "Aula 2.1.html#importando-dados-planilhas",
    "href": "Aula 2.1.html#importando-dados-planilhas",
    "title": "Aula 02 - Importação de dados",
    "section": "Importando dados/ planilhas",
    "text": "Importando dados/ planilhas\nOs dados/ planilhas podem ser obtidos de diferentes formas.\nInicialmente, será carregado um conjunto de dados presente em um pacote do R (ec50estimator):\n\nlibrary(ec50estimator)\n\ndf1 &lt;- multi_isolate\nhead(df1)\n\n  isolate   field   fungicida  dose     growth\n1       1 Organic Fungicide A 0e+00 20.2082399\n2       1 Organic Fungicide A 1e-05 20.1168279\n3       1 Organic Fungicide A 1e-04 19.2479678\n4       1 Organic Fungicide A 1e-03 15.8123455\n5       1 Organic Fungicide A 1e-02  7.3206757\n6       1 Organic Fungicide A 1e-01  0.6985264\n\n\n\nUma outra maneira, é carregar dados de uma planilha em Excel. Para isso, existem duas alternativas. A primeira faz uso do pacote readxl.\n\nOBS.: Para as opções apresentadas a seguir, é importante mencionar que o arquivo a ser importado deve estar dentro da pasta do projeto.\n\nlibrary(readxl)\ndf2 &lt;- read_excel(\"dados-diversos.xlsx\")\nhead(df2)\n\n# A tibble: 6 × 3\n  trat    rep  comp\n  &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 Mg2       1   9  \n2 Mg2       2  12.5\n3 Mg2       3  10  \n4 Mg2       4   8  \n5 Mg2       5  13.2\n6 Mg2       6  11  \n\n\n\nQuando uma planilha possui mais de uma guia, é necessário indicar na função qual a guia que desejamos importar:\n\ndf21 &lt;- read_excel(\"dados-diversos.xlsx\", sheet = \"escala\")\nhead(df21)\n\n# A tibble: 6 × 7\n  assessment rater acuracia precisao vies_geral vies_sistematico vies_constante\n  &lt;chr&gt;      &lt;chr&gt;    &lt;dbl&gt;    &lt;dbl&gt;      &lt;dbl&gt;            &lt;dbl&gt;          &lt;dbl&gt;\n1 Unaided    A        0.809    0.826      0.979            1.19         0.112  \n2 Unaided    B        0.722    0.728      0.991            0.922       -0.106  \n3 Unaided    C        0.560    0.715      0.783            1.16         0.730  \n4 Unaided    D        0.818    0.819      0.999            0.948       -0.00569\n5 Unaided    E        0.748    0.753      0.993            1.10         0.0719 \n6 Unaided    F        0.695    0.751      0.925            0.802        0.336  \n\n\n\nA segunda forma de importação, faz uso do pacote tidyverse, com a função read_csv:\n\nlibrary(tidyverse)\ndf3 &lt;- read_csv(\"dados-diversos.csv\")\nhead(df3)\n\n# A tibble: 6 × 4\n  Irrigation   rep   day severity\n  &lt;chr&gt;      &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;\n1 Furrow         1     0     0.01\n2 Furrow         2     0     0.01\n3 Furrow         3     0     0.01\n4 Furrow         1     7     0.04\n5 Furrow         2     7     0.04\n6 Furrow         3     7     0.04\n\n\n\nA terceira forma de se carregar dados é a partir de uma planilha google, disponível online.\nPara isso, fazemos uso do pacote gsheet:\n\nlibrary(gsheet)\ndf4 &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1aID5Dh6PlBVCKzU1j7k-WA6zuWQWE2NhtWEgdJtt5iA/edit#gid=921203844\")\nhead(df4)\n\n# A tibble: 6 × 3\n  trat    rep  comp\n  &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 Mg2       1   9  \n2 Mg2       2  12.5\n3 Mg2       3  10  \n4 Mg2       4   8  \n5 Mg2       5  13.2\n6 Mg2       6  11  \n\ndf5 &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1aID5Dh6PlBVCKzU1j7k-WA6zuWQWE2NhtWEgdJtt5iA/edit#gid=517586736\")\nhead(df5)\n\n# A tibble: 6 × 3\n  especie   rep   tcm\n  &lt;chr&gt;   &lt;dbl&gt; &lt;dbl&gt;\n1 Fasi        1  1.5 \n2 Fasi        2  1.59\n3 Fasi        3  1.52\n4 Fasi        4  1.52\n5 Fasi        5  1.6 \n6 Fasi        6  1.56",
    "crumbs": [
      "Home",
      "Aula 02",
      "Importação de dados"
    ]
  },
  {
    "objectID": "Aula 10.3.html",
    "href": "Aula 10.3.html",
    "title": "Aula 10 - Modelo não-linear - Cálculo de EC50",
    "section": "",
    "text": "Na fitopatologia, modelos não-lineares podem ser utilizados para a construção de curvas de EC50.\n\n\n\nfung &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=465348652\")\n\nCálculo da média de germinação em função do isolado.\n\nfung2 &lt;- fung %&gt;% \n  group_by(code, dose) %&gt;% \n  summarise(mean_germ = mean(germination))\n\n\nVisualização da média de germinação com gráfico de pontos\n\nfung2 %&gt;% \n  ggplot(aes(dose, mean_germ))+\n  geom_point()+\n  facet_wrap(~ code)\n\n\n\n\n\n\n\n\n\n\n\nPara modelar a EC50 será utilizado o pacote drc, com a função drm.\nAntes, é preciso criar um novo objeto somente com os dados do isolado selecionado (ex.: FGT05). Em seguida, definimos na função drm que a germinação média será modela em função da dose, qual o conjunto de dados (data = FGT05) e qual a função utilizada (no caso, fct = LL.3()).\n\nlibrary(drc)\n\nFGT05 &lt;- fung2 %&gt;% \n  filter(code ==\"FGT05\")\n\ndrc_fgt05 &lt;- drm(mean_germ ~ dose,\n                 data = FGT05,\n                 fct = LL.3())\n\nsummary(drc_fgt05)\n\n\nModel fitted: Log-logistic (ED50 as parameter) with lower limit at 0 (3 parms)\n\nParameter estimates:\n\n               Estimate Std. Error t-value   p-value    \nb:(Intercept)  0.769933   0.198566  3.8775 0.0303750 *  \nd:(Intercept) 44.924753   3.261699 13.7734 0.0008283 ***\ne:(Intercept)  0.044839   0.019291  2.3243 0.1026764    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error:\n\n 3.253867 (3 degrees of freedom)\n\nAIC(drc_fgt05)\n\n[1] 35.02651\n\nplot(drc_fgt05)\n\n\n\n\n\n\n\n\nÉ importante definir a função para comparar os modelos e selecionar aquele mais simples (com menor AIC).\n\n\n\nSerá utilizada a função ED pacote (drc).\nSeleciona-se o objeto, o valor da varíavel resposta (50), e o tipo de intervalo de confiança que será apresentado.\n\nED(drc_fgt05, 50, interval = \"delta\")\n\n\nEstimated effective doses\n\n        Estimate Std. Error     Lower     Upper\ne:1:50  0.044839   0.019291 -0.016554  0.106231\n\n\nNo caso, a dose que inibe 50% da germinação de conídios foi estimada em 0.04, com -0.01 &lt; IC &lt; 0.10.\n\n\n\nI_165 &lt;- fung2 %&gt;% \n  filter(code ==\"165\")\n\ndrc_165 &lt;- drm(mean_germ ~ dose,\n                 data = I_165,\n                 fct = LL.3())\n\nsummary(drc_165)\n\n\nModel fitted: Log-logistic (ED50 as parameter) with lower limit at 0 (3 parms)\n\nParameter estimates:\n\n              Estimate Std. Error t-value   p-value    \nb:(Intercept)  1.21560    0.26679  4.5564 0.0198145 *  \nd:(Intercept) 36.14322    1.97554 18.2954 0.0003563 ***\ne:(Intercept)  0.55840    0.11420  4.8898 0.0163598 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error:\n\n 2.436519 (3 degrees of freedom)\n\nAIC(drc_165)\n\n[1] 31.55522\n\nplot(drc_165)\n\n\n\n\n\n\n\nED(drc_165,50, interval = \"delta\")\n\n\nEstimated effective doses\n\n       Estimate Std. Error   Lower   Upper\ne:1:50  0.55840    0.11420 0.19498 0.92182\n\n\n\nI_186 &lt;- fung2 %&gt;% \n  filter(code ==\"186\")\n\ndrc_186 &lt;- drm(mean_germ ~ dose,\n                 data = I_186,\n                 fct = LL.3())\n\nsummary(drc_186)\n\n\nModel fitted: Log-logistic (ED50 as parameter) with lower limit at 0 (3 parms)\n\nParameter estimates:\n\n               Estimate Std. Error t-value   p-value    \nb:(Intercept)  4.997636   0.542650  9.2097  0.002708 ** \nd:(Intercept) 48.750109   0.721642 67.5545 7.148e-06 ***\ne:(Intercept)  0.579757   0.013332 43.4853 2.677e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error:\n\n 1.020525 (3 degrees of freedom)\n\nAIC(drc_186)\n\n[1] 21.11219\n\nplot(drc_186)\n\n\n\n\n\n\n\nED(drc_186, 50, interval = \"delta\")\n\n\nEstimated effective doses\n\n       Estimate Std. Error    Lower    Upper\ne:1:50 0.579757   0.013332 0.537328 0.622187\n\n\n\n\n\n\nPelo método anterior, é preciso modelar o EC50 individualmente, o que pode ser trabalhoso, dependendo do número de amostras. Assim, o pacote ec50estimator é útil nessa situações, pois permite modelar, calcular a EC50 e o IC de todos os tratamento de uma só vez.\n\nlibrary(ec50estimator)\n\ndf_ec50 &lt;- estimate_EC50(mean_germ~dose,\n                         data = fung2,\n                         isolate_col = \"code\",\n                         interval = \"delta\",\n                         fct = drc::LL.3())\nview(df_ec50)\n\nlibrary(DT)\ndatatable(df_ec50)\n\n\n\n\n\nProblema, não é possível selecionar a função de cada modelo para melhor se adequar a cada tratamento.\nGráfico com as doses de EC50 e intervalo de confiança:\n\ndf_ec50 %&gt;% \n  ggplot(aes(reorder(ID, Estimate), Estimate))+\n  geom_point()+\n  geom_errorbar(aes(ymin = Lower,\n                    ymax = Upper),\n                width = 0.1)+\n  ylim (0, 1.2)+\n  coord_flip()\n\n\n\n\n\n\n\n\nArgumento reorder(ID, Estimate), Estimate , utilizado para ordenar os tratamentos em função da resposta (ordem crescente).",
    "crumbs": [
      "Home",
      "Aula 10",
      "Modelo não-linear - Cálculo de EC50"
    ]
  },
  {
    "objectID": "Aula 10.3.html#modelo-não-linear",
    "href": "Aula 10.3.html#modelo-não-linear",
    "title": "Aula 10 - Modelo não-linear - Cálculo de EC50",
    "section": "",
    "text": "Na fitopatologia, modelos não-lineares podem ser utilizados para a construção de curvas de EC50.\n\n\n\nfung &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=465348652\")\n\nCálculo da média de germinação em função do isolado.\n\nfung2 &lt;- fung %&gt;% \n  group_by(code, dose) %&gt;% \n  summarise(mean_germ = mean(germination))\n\n\nVisualização da média de germinação com gráfico de pontos\n\nfung2 %&gt;% \n  ggplot(aes(dose, mean_germ))+\n  geom_point()+\n  facet_wrap(~ code)\n\n\n\n\n\n\n\n\n\n\n\nPara modelar a EC50 será utilizado o pacote drc, com a função drm.\nAntes, é preciso criar um novo objeto somente com os dados do isolado selecionado (ex.: FGT05). Em seguida, definimos na função drm que a germinação média será modela em função da dose, qual o conjunto de dados (data = FGT05) e qual a função utilizada (no caso, fct = LL.3()).\n\nlibrary(drc)\n\nFGT05 &lt;- fung2 %&gt;% \n  filter(code ==\"FGT05\")\n\ndrc_fgt05 &lt;- drm(mean_germ ~ dose,\n                 data = FGT05,\n                 fct = LL.3())\n\nsummary(drc_fgt05)\n\n\nModel fitted: Log-logistic (ED50 as parameter) with lower limit at 0 (3 parms)\n\nParameter estimates:\n\n               Estimate Std. Error t-value   p-value    \nb:(Intercept)  0.769933   0.198566  3.8775 0.0303750 *  \nd:(Intercept) 44.924753   3.261699 13.7734 0.0008283 ***\ne:(Intercept)  0.044839   0.019291  2.3243 0.1026764    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error:\n\n 3.253867 (3 degrees of freedom)\n\nAIC(drc_fgt05)\n\n[1] 35.02651\n\nplot(drc_fgt05)\n\n\n\n\n\n\n\n\nÉ importante definir a função para comparar os modelos e selecionar aquele mais simples (com menor AIC).\n\n\n\nSerá utilizada a função ED pacote (drc).\nSeleciona-se o objeto, o valor da varíavel resposta (50), e o tipo de intervalo de confiança que será apresentado.\n\nED(drc_fgt05, 50, interval = \"delta\")\n\n\nEstimated effective doses\n\n        Estimate Std. Error     Lower     Upper\ne:1:50  0.044839   0.019291 -0.016554  0.106231\n\n\nNo caso, a dose que inibe 50% da germinação de conídios foi estimada em 0.04, com -0.01 &lt; IC &lt; 0.10.\n\n\n\nI_165 &lt;- fung2 %&gt;% \n  filter(code ==\"165\")\n\ndrc_165 &lt;- drm(mean_germ ~ dose,\n                 data = I_165,\n                 fct = LL.3())\n\nsummary(drc_165)\n\n\nModel fitted: Log-logistic (ED50 as parameter) with lower limit at 0 (3 parms)\n\nParameter estimates:\n\n              Estimate Std. Error t-value   p-value    \nb:(Intercept)  1.21560    0.26679  4.5564 0.0198145 *  \nd:(Intercept) 36.14322    1.97554 18.2954 0.0003563 ***\ne:(Intercept)  0.55840    0.11420  4.8898 0.0163598 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error:\n\n 2.436519 (3 degrees of freedom)\n\nAIC(drc_165)\n\n[1] 31.55522\n\nplot(drc_165)\n\n\n\n\n\n\n\nED(drc_165,50, interval = \"delta\")\n\n\nEstimated effective doses\n\n       Estimate Std. Error   Lower   Upper\ne:1:50  0.55840    0.11420 0.19498 0.92182\n\n\n\nI_186 &lt;- fung2 %&gt;% \n  filter(code ==\"186\")\n\ndrc_186 &lt;- drm(mean_germ ~ dose,\n                 data = I_186,\n                 fct = LL.3())\n\nsummary(drc_186)\n\n\nModel fitted: Log-logistic (ED50 as parameter) with lower limit at 0 (3 parms)\n\nParameter estimates:\n\n               Estimate Std. Error t-value   p-value    \nb:(Intercept)  4.997636   0.542650  9.2097  0.002708 ** \nd:(Intercept) 48.750109   0.721642 67.5545 7.148e-06 ***\ne:(Intercept)  0.579757   0.013332 43.4853 2.677e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error:\n\n 1.020525 (3 degrees of freedom)\n\nAIC(drc_186)\n\n[1] 21.11219\n\nplot(drc_186)\n\n\n\n\n\n\n\nED(drc_186, 50, interval = \"delta\")\n\n\nEstimated effective doses\n\n       Estimate Std. Error    Lower    Upper\ne:1:50 0.579757   0.013332 0.537328 0.622187\n\n\n\n\n\n\nPelo método anterior, é preciso modelar o EC50 individualmente, o que pode ser trabalhoso, dependendo do número de amostras. Assim, o pacote ec50estimator é útil nessa situações, pois permite modelar, calcular a EC50 e o IC de todos os tratamento de uma só vez.\n\nlibrary(ec50estimator)\n\ndf_ec50 &lt;- estimate_EC50(mean_germ~dose,\n                         data = fung2,\n                         isolate_col = \"code\",\n                         interval = \"delta\",\n                         fct = drc::LL.3())\nview(df_ec50)\n\nlibrary(DT)\ndatatable(df_ec50)\n\n\n\n\n\nProblema, não é possível selecionar a função de cada modelo para melhor se adequar a cada tratamento.\nGráfico com as doses de EC50 e intervalo de confiança:\n\ndf_ec50 %&gt;% \n  ggplot(aes(reorder(ID, Estimate), Estimate))+\n  geom_point()+\n  geom_errorbar(aes(ymin = Lower,\n                    ymax = Upper),\n                width = 0.1)+\n  ylim (0, 1.2)+\n  coord_flip()\n\n\n\n\n\n\n\n\nArgumento reorder(ID, Estimate), Estimate , utilizado para ordenar os tratamentos em função da resposta (ordem crescente).",
    "crumbs": [
      "Home",
      "Aula 10",
      "Modelo não-linear - Cálculo de EC50"
    ]
  },
  {
    "objectID": "Aula 10.1.html",
    "href": "Aula 10.1.html",
    "title": "Aula 10 - Análise de correlação",
    "section": "",
    "text": "Nesta aula, serão abordadas análises de correlação, demonstrando como construir gráficos e analisar os coeficientes obtidos. Também serão demonstradas análises de regressão linear e quadrática e, por fim, o uso de modelos não-lineares aplicados à fitopatologia para o cálculo de EC50.",
    "crumbs": [
      "Home",
      "Aula 10",
      "Análise de correlação"
    ]
  },
  {
    "objectID": "Aula 10.1.html#carregando-os-pacotes",
    "href": "Aula 10.1.html#carregando-os-pacotes",
    "title": "Aula 10 - Análise de correlação",
    "section": "Carregando os pacotes",
    "text": "Carregando os pacotes\n\nlibrary(gsheet)\nlibrary(tidyverse)\nlibrary(patchwork)\nlibrary(AgroR)",
    "crumbs": [
      "Home",
      "Aula 10",
      "Análise de correlação"
    ]
  },
  {
    "objectID": "Aula 10.1.html#análise-de-correlação",
    "href": "Aula 10.1.html#análise-de-correlação",
    "title": "Aula 10 - Análise de correlação",
    "section": "Análise de correlação",
    "text": "Análise de correlação\n\ncorr &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=373270992\")\n\n\nAnálise exploratória - Visualização gráfica\n\nGráfico de Correlação\nConsiderando o software “Assess” como o padrão, serão feitos gráficos de correlação entre ele e os outros softwares, “LeafDoctor” e “ImageJ”. O objetivo é verificar se os métodos possuem alguma correlação com o “Assess” e se essa correlação é positiva ou negativa.\n\ng1 &lt;- corr %&gt;% \n  ggplot(aes(Assess, LeafDoctor))+\n  geom_point()+\n  geom_smooth(method = \"lm\")\n\ng1\n\n\n\n\n\n\n\n\n\ng2 &lt;- corr %&gt;% \n  ggplot(aes(Assess, ImageJ))+\n  geom_point()+\n  geom_smooth(method = \"lm\")\n\ng2\n\n\n\n\n\n\n\n\nOs gráficos acima demonstram que os softwares avaliados possuem correlação positiva com o software “Assess”.\n\n\nBoxplot\nSerá construído um boxplot para verificar a variabilidade dos dados em função do método (software).\n\ng3 &lt;- corr %&gt;%\n  pivot_longer(3:5, names_to = \"method\",\n               values_to = \"value\") %&gt;% \n  ggplot(aes(method , value))+\n  geom_boxplot()\n\ng3\n\n\n\n\n\n\n\n\nCom o pacote patchwork será feito um plot contendo os três gráficos gerados anteriormente:\n\ng3 + (g1/g2)\n\n\n\n\n\n\n\n\n\n\n\nCoeficiente de correlação (r)\nO coeficiente de correlação (ou correlação de Pearson) varia entre -1 e +1. Se o valor for negativo, há correlação negativa; caso seja positivo, a correlação será positiva. Além disso, quanto mais próximo às extremidades (-1 ou +1), mais forte será a correlação.\nUma opção para obter os coeficientes de correlação (r) é adotar a função cor.test (nativa do R):\n\ncor.test(corr$Assess, corr$LeafDoctor)\n\n\n    Pearson's product-moment correlation\n\ndata:  corr$Assess and corr$LeafDoctor\nt = 31.119, df = 68, p-value &lt; 2.2e-16\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.9466882 0.9792005\nsample estimates:\n      cor \n0.9666367 \n\n\n\ncor.test(corr$Assess, corr$ImageJ)\n\n\n    Pearson's product-moment correlation\n\ndata:  corr$Assess and corr$ImageJ\nt = 38.383, df = 68, p-value &lt; 2.2e-16\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.9642331 0.9861219\nsample estimates:\n      cor \n0.9776918 \n\n\nPelo coeficientes obtidos, é possível dizer que os softwares possuem correlação positiva e forte, pois os valores\n\nGráficos para apresentar os coeficientes de correlações entre os métodos\nCom AgroR:\nAntes é preciso criar um objeto com os coeficientes de correlação.\n\ncorr %&gt;% \n  select(3:5) %&gt;%\n  corgraph()\n\n        Var1       Var2       cor            p\n2 LeafDoctor     Assess 0.9666367 5.972544e-42\n3     ImageJ     Assess 0.9776918 8.143613e-48\n6     ImageJ LeafDoctor 0.9797478 3.144091e-49\n\n\n\n\n\n\n\n\n#ou#\n\n\ncorr2 &lt;- corr %&gt;%\n  select(3:5)\n\ncorgraph(corr2)\n\n        Var1       Var2       cor            p\n2 LeafDoctor     Assess 0.9666367 5.972544e-42\n3     ImageJ     Assess 0.9776918 8.143613e-48\n6     ImageJ LeafDoctor 0.9797478 3.144091e-49\n\n\n\n\n\n\n\n\n\nCom corrplot:\n\nlibrary(corrplot)\n\ncorr2_1 &lt;- cor(corr2)\ncorrplot(corr2_1, method = \"square\", type = \"upper\")\n\n\n\n\n\n\n\n\nAlterando alguns parâmetros na função (conferir o help, pois há outras variações possíveis):\n\nO argumento diag = FALSE remove a comparação dentro de um mesmo método, por exemplo, Assess com Assess.\n\n\ncorrplot(corr2_1, method = \"number\", type = \"upper\", diag = FALSE)\n\n\n\n\n\n\n\n\n\n\n\nExemplo 02\nUm outro exemplo de correlação, com o conjunto de dados de aulas passadas.\n\ncampo &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=866852711\")\n\ncampo2 &lt;- campo |&gt; \n  dplyr::select(DFC, FER, PROD)\n\nCom corgraph\n\ncorgraph(campo2)\n\n  Var1 Var2        cor            p\n2  FER  DFC  0.9316978 9.864101e-15\n3 PROD  DFC -0.6928161 1.110652e-05\n6 PROD  FER -0.6258321 1.277444e-04\n\n\n\n\n\n\n\n\n\nCom corrplot\n\ncampo2_1 &lt;- cor(campo2)\ncampo2_1 %&gt;% corrplot(method = \"number\", type = \"lower\", diag = FALSE)\n\n\n\n\n\n\n\n\n\nComparação de correlações\n\ncor.test(campo2$PROD, campo2$DFC)\n\n\n    Pearson's product-moment correlation\n\ndata:  campo2$PROD and campo2$DFC\nt = -5.2623, df = 30, p-value = 1.111e-05\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n -0.8388581 -0.4537361\nsample estimates:\n       cor \n-0.6928161 \n\ncor.test(campo2$PROD, campo2$FER)\n\n\n    Pearson's product-moment correlation\n\ndata:  campo2$PROD and campo2$FER\nt = -4.3949, df = 30, p-value = 0.0001277\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n -0.7999565 -0.3544981\nsample estimates:\n       cor \n-0.6258321 \n\n\nAvalia-se os intervalos de confiança obtidos (IC da correlação entre PROD e DFC vs. IC da correlação entre PROD e FER) e caso não haja sobreposição de intervalos, as correlações diferem estatisticamente.",
    "crumbs": [
      "Home",
      "Aula 10",
      "Análise de correlação"
    ]
  },
  {
    "objectID": "Aula 1.1.html",
    "href": "Aula 1.1.html",
    "title": "Aula 01 - Criação de projetos, documentos e conjunto de dados",
    "section": "",
    "text": "Nessa primeira aula será feita uma breve introdução aos softwares R e RStudio, apresentando como criar projetos, scripts e arquivos e como salvá-los. Além disso, será demonstrado como instalar e carregar pacotes e criar vetores, data frames e realizar operações básicas no RStudio.",
    "crumbs": [
      "Home",
      "Aula 01",
      "Criação de projetos, documentos e conjunto de dados"
    ]
  },
  {
    "objectID": "Aula 1.1.html#criação-do-projeto",
    "href": "Aula 1.1.html#criação-do-projeto",
    "title": "Aula 01 - Criação de projetos, documentos e conjunto de dados",
    "section": "Criação do projeto",
    "text": "Criação do projeto\nInicialmente, será criado um projeto, onde serão mantidos todos os arquivos da disciplina. Para isso, bastar clicar em:\n &gt; “File”\n  &gt; “New Project…”\n   &gt; “New Directory”\n    &gt; “New Project”.\n     Nessa parte, é dado um nome ao projeto e escolhida a pasta em que ele será mantido. Feito isso, prosseguimos, clicando em “Create Project”.",
    "crumbs": [
      "Home",
      "Aula 01",
      "Criação de projetos, documentos e conjunto de dados"
    ]
  },
  {
    "objectID": "Aula 1.1.html#criação-dos-scripts-e-documentos",
    "href": "Aula 1.1.html#criação-dos-scripts-e-documentos",
    "title": "Aula 01 - Criação de projetos, documentos e conjunto de dados",
    "section": "Criação dos scripts e documentos",
    "text": "Criação dos scripts e documentos\n\nScripts\nO script é o local onde são desenvolvidos e salvos os códigos. Para criar um novo script no RStudio, clique em:\n &gt; “File”\n  &gt; “New File”\n   &gt; “R Script”\n\n\n\nDocumentos\nAo longo da disciplina, as atividades desenvolvidas serão salvas em documentos. O objetivo é permitir que os códigos desenvolvidos, as análises realizadas e os resultados obtidos, junto com as interpretações e comentários, sejam mantidos em um mesmo arquivo (documento), facilitando o acesso e entendimento do que foi feito.\nOs formatos dos documentos que podem ser utilizados são “R Markdown” (.rmd) e “Quarto document” (.qmd). Daremos preferência ao último.\nPortanto, para criar um novo documento em “.qmd”, seguiremos o seguinte caminho:\n &gt; “File”\n  &gt; “New File”\n   &gt; “Quarto document…”\n    Nessa janela, será dado um título ao arquivo, o nome do autor e em seguida, seleciona-se “Create”.\nO novo documento será salvo na pasta do projeto, criado anteriormente.",
    "crumbs": [
      "Home",
      "Aula 01",
      "Criação de projetos, documentos e conjunto de dados"
    ]
  },
  {
    "objectID": "Aula 1.1.html#instalando-e-carregando-pacotes",
    "href": "Aula 1.1.html#instalando-e-carregando-pacotes",
    "title": "Aula 01 - Criação de projetos, documentos e conjunto de dados",
    "section": "Instalando e carregando pacotes",
    "text": "Instalando e carregando pacotes\nOs pacotes são fundamentais para o funcionamento do RStudio, pois contém funções que serão utilizadas em várias análises no decorrer da disciplina.\nUm pacote pode ser instalado manualmente, clicando em:\n &gt; “Packages”\n  &gt; “Install”\n    &gt; Na linha “Packages”, digite o nome do pacote de interesse, por exemplo, “Agricolae”.\n    &gt; Em sequência, clique em “Install”\nOutra opção, é realizar a instalação com uma fórmula, como segue:\n\ninstall.packages(\"ggplot2\")\n\nApós a instalação, é preciso carregar o pacote, para isso:\n\nlibrary(ggplot2)",
    "crumbs": [
      "Home",
      "Aula 01",
      "Criação de projetos, documentos e conjunto de dados"
    ]
  },
  {
    "objectID": "Aula 1.1.html#criando-vetores",
    "href": "Aula 1.1.html#criando-vetores",
    "title": "Aula 01 - Criação de projetos, documentos e conjunto de dados",
    "section": "Criando vetores",
    "text": "Criando vetores\nPara trabalhar no R, algumas vezes devemos criar vetores, segue alguns exemplos simples de como o fazer:\n\nx &lt;- 5\nx\n\n[1] 5\n\n\nTambém é possível criar um vetor com um conjunto de valores:\n\nA &lt;- c(1:20)\nA\n\n [1]  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20\n\n\nNo RStudio, também é possível realizar operações com os vetores criados, por exemplo\n\ny &lt;- x^2\ny\n\n[1] 25\n\n\n\nz &lt;- y-2*x\nz\n\n[1] 15\n\n\n\nB &lt;- A*5\nB\n\n [1]   5  10  15  20  25  30  35  40  45  50  55  60  65  70  75  80  85  90  95\n[20] 100",
    "crumbs": [
      "Home",
      "Aula 01",
      "Criação de projetos, documentos e conjunto de dados"
    ]
  },
  {
    "objectID": "Aula 1.1.html#criando-data-frames",
    "href": "Aula 1.1.html#criando-data-frames",
    "title": "Aula 01 - Criação de projetos, documentos e conjunto de dados",
    "section": "Criando data frames",
    "text": "Criando data frames\nPara criação de dataframes, é utilizada a função data.frame. Primeiros é dado um nome ao objeto (df), em sequência especificamos o que será colocado nele (os vetores A e B).\n\ndf &lt;- data.frame(A,B)\ndf\n\n    A   B\n1   1   5\n2   2  10\n3   3  15\n4   4  20\n5   5  25\n6   6  30\n7   7  35\n8   8  40\n9   9  45\n10 10  50\n11 11  55\n12 12  60\n13 13  65\n14 14  70\n15 15  75\n16 16  80\n17 17  85\n18 18  90\n19 19  95\n20 20 100",
    "crumbs": [
      "Home",
      "Aula 01",
      "Criação de projetos, documentos e conjunto de dados"
    ]
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Sumário",
    "section": "",
    "text": "Este site foi criado para armazenar os dados gerados ao longo da disciplina FIP 606 - Análise e Visualização de Dados em Fitopatologia. Abaixo, um sumário dos conteúdos de cada aula.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAula 01 - Criação de projetos, documentos e conjunto de dados\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAula 01 - Manipulações de dados\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAula 02 - Importação de dados\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAula 02 - Importação de dados e criação de gráficos simples\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAula 03 - Estatísticas descritivas e construção de gráficos simples\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAula 04 - Tabela de contingência\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAula 04 - Uso do datapasta\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAula 05 - Atividade prática\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAula 06 - Estatística inferencial - Análise de variância\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAula 06 - Estatística inferencial - Teste t\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAula 07 - Estatística inferencial - Alternativas de análise\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAula 07 - Estatística inferencial - Análise de variância\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAula 07 - Estatística inferencial - Experimento fatorial\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAula 08 - Curva de progresso da doença\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAula 08 - Estatística inferencial - Experimento em DBC\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAula 09 - Estatística inferencial - Análise de múltiplos ensaios\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAula 09 - Estatística inferencial - Experimento em parcelas subdivididas\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAula 09 - Estatística inferencial - Regressão linear\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAula 10 - Análise de correlação\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAula 10 - Modelo não-linear - Cálculo de EC50\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAula 10 - Regressão linear de segunda ordem (quadrática)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAula 11 - Construção de gráficos com R\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFIP 606 | por Caio M.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNo matching items\n\n Back to top",
    "crumbs": [
      "Home",
      "Sumário"
    ]
  },
  {
    "objectID": "Aula 1.2.html",
    "href": "Aula 1.2.html",
    "title": "Aula 01 - Manipulações de dados",
    "section": "",
    "text": "Para manipulação de dados e/ou data frames, é possível adotar funções presentes no pacote dplyr. Alguns exemplos.\n\nlibrary(dplyr)\n\n\n\nEssa função é capaz de criar novas colunas em função das já existentes. Além disso, com ela é possível modificar e deletar colunas.\n\ndf &lt;- df %&gt;% \n  mutate(C = A*0.5,\n         D = A^2,\n         E = B*C*A)\ndf\n\n    A   B    C   D       E\n1   1   5  0.5   1     2.5\n2   2  10  1.0   4    20.0\n3   3  15  1.5   9    67.5\n4   4  20  2.0  16   160.0\n5   5  25  2.5  25   312.5\n6   6  30  3.0  36   540.0\n7   7  35  3.5  49   857.5\n8   8  40  4.0  64  1280.0\n9   9  45  4.5  81  1822.5\n10 10  50  5.0 100  2500.0\n11 11  55  5.5 121  3327.5\n12 12  60  6.0 144  4320.0\n13 13  65  6.5 169  5492.5\n14 14  70  7.0 196  6860.0\n15 15  75  7.5 225  8437.5\n16 16  80  8.0 256 10240.0\n17 17  85  8.5 289 12282.5\n18 18  90  9.0 324 14580.0\n19 19  95  9.5 361 17147.5\n20 20 100 10.0 400 20000.0\n\n\nPara deletar colunas:\n\ndf &lt;- df %&gt;% \n  mutate(C = NULL)\ndf\n\n    A   B   D       E\n1   1   5   1     2.5\n2   2  10   4    20.0\n3   3  15   9    67.5\n4   4  20  16   160.0\n5   5  25  25   312.5\n6   6  30  36   540.0\n7   7  35  49   857.5\n8   8  40  64  1280.0\n9   9  45  81  1822.5\n10 10  50 100  2500.0\n11 11  55 121  3327.5\n12 12  60 144  4320.0\n13 13  65 169  5492.5\n14 14  70 196  6860.0\n15 15  75 225  8437.5\n16 16  80 256 10240.0\n17 17  85 289 12282.5\n18 18  90 324 14580.0\n19 19  95 361 17147.5\n20 20 100 400 20000.0\n\n\n\n\n\nEssa função permite alterar o nome atribuído as colunas, usando a seguinte ordem: nome novo = nome antigo. Por exemplo:\n\ndf &lt;- df %&gt;% \n  rename(C = E)\ndf\n\n    A   B   D       C\n1   1   5   1     2.5\n2   2  10   4    20.0\n3   3  15   9    67.5\n4   4  20  16   160.0\n5   5  25  25   312.5\n6   6  30  36   540.0\n7   7  35  49   857.5\n8   8  40  64  1280.0\n9   9  45  81  1822.5\n10 10  50 100  2500.0\n11 11  55 121  3327.5\n12 12  60 144  4320.0\n13 13  65 169  5492.5\n14 14  70 196  6860.0\n15 15  75 225  8437.5\n16 16  80 256 10240.0\n17 17  85 289 12282.5\n18 18  90 324 14580.0\n19 19  95 361 17147.5\n20 20 100 400 20000.0\n\n\n\n\n\nCom essa função, é possível criar um novo data frame, selecionado colunas de um data frame já existente, por exemplo:\n\ndf2 &lt;- df %&gt;% \n  select(A, B, C)\ndf2\n\n    A   B       C\n1   1   5     2.5\n2   2  10    20.0\n3   3  15    67.5\n4   4  20   160.0\n5   5  25   312.5\n6   6  30   540.0\n7   7  35   857.5\n8   8  40  1280.0\n9   9  45  1822.5\n10 10  50  2500.0\n11 11  55  3327.5\n12 12  60  4320.0\n13 13  65  5492.5\n14 14  70  6860.0\n15 15  75  8437.5\n16 16  80 10240.0\n17 17  85 12282.5\n18 18  90 14580.0\n19 19  95 17147.5\n20 20 100 20000.0\n\n\nSe for utilizado o operador :, serão selecionadas todas as colunas entre o intervalo especificado, por exemplo:\n\ndf3 &lt;- df %&gt;% \n  select(B:C)\ndf3\n\n     B   D       C\n1    5   1     2.5\n2   10   4    20.0\n3   15   9    67.5\n4   20  16   160.0\n5   25  25   312.5\n6   30  36   540.0\n7   35  49   857.5\n8   40  64  1280.0\n9   45  81  1822.5\n10  50 100  2500.0\n11  55 121  3327.5\n12  60 144  4320.0\n13  65 169  5492.5\n14  70 196  6860.0\n15  75 225  8437.5\n16  80 256 10240.0\n17  85 289 12282.5\n18  90 324 14580.0\n19  95 361 17147.5\n20 100 400 20000.0\n\n\n\n\n\nEssa função ordena as linhas de um data frame em função dos valores das colunas selecionadas. Por exemlo:\n\ndf2 %&gt;% \n  arrange(A,C)\n\n    A   B       C\n1   1   5     2.5\n2   2  10    20.0\n3   3  15    67.5\n4   4  20   160.0\n5   5  25   312.5\n6   6  30   540.0\n7   7  35   857.5\n8   8  40  1280.0\n9   9  45  1822.5\n10 10  50  2500.0\n11 11  55  3327.5\n12 12  60  4320.0\n13 13  65  5492.5\n14 14  70  6860.0\n15 15  75  8437.5\n16 16  80 10240.0\n17 17  85 12282.5\n18 18  90 14580.0\n19 19  95 17147.5\n20 20 100 20000.0\n\n\nOu em ordem decrescente, com o argumento desc:\n\ndf2 %&gt;% \n  arrange(desc(A))\n\n    A   B       C\n1  20 100 20000.0\n2  19  95 17147.5\n3  18  90 14580.0\n4  17  85 12282.5\n5  16  80 10240.0\n6  15  75  8437.5\n7  14  70  6860.0\n8  13  65  5492.5\n9  12  60  4320.0\n10 11  55  3327.5\n11 10  50  2500.0\n12  9  45  1822.5\n13  8  40  1280.0\n14  7  35   857.5\n15  6  30   540.0\n16  5  25   312.5\n17  4  20   160.0\n18  3  15    67.5\n19  2  10    20.0\n20  1   5     2.5\n\n\n\n\n\nCom essa função é possível filtrar linhas do data frame que satisfaçam uma condição específica. Por exemplo:\n\ndf4 &lt;- df2 %&gt;% \n  filter(A &gt;= 5)\ndf4\n\n    A   B       C\n1   5  25   312.5\n2   6  30   540.0\n3   7  35   857.5\n4   8  40  1280.0\n5   9  45  1822.5\n6  10  50  2500.0\n7  11  55  3327.5\n8  12  60  4320.0\n9  13  65  5492.5\n10 14  70  6860.0\n11 15  75  8437.5\n12 16  80 10240.0\n13 17  85 12282.5\n14 18  90 14580.0\n15 19  95 17147.5\n16 20 100 20000.0\n\ndf5 &lt;- df2 %&gt;% \n  filter(A &lt; 5)\ndf5\n\n  A  B     C\n1 1  5   2.5\n2 2 10  20.0\n3 3 15  67.5\n4 4 20 160.0\n\ndf6 &lt;- df2 %&gt;% \n  filter(A == 5)\ndf6\n\n  A  B     C\n1 5 25 312.5\n\n\n\n\n\nCom essa função é possível selecionar uma coluna de interesse e obter medidas estatísticas dela. Com isso é criado um novo data frame as medidas selecionadas. Alguns exemplos:\n\nsumm &lt;- df2 %&gt;% \n  summarise(media = mean (A),\n            mediana = median(A),\n            sd = sd(A),\n            min = min(A),\n            max = max(A))\nsumm\n\n  media mediana      sd min max\n1  10.5    10.5 5.91608   1  20",
    "crumbs": [
      "Home",
      "Aula 01",
      "Manipulações de dados"
    ]
  },
  {
    "objectID": "Aula 1.2.html#manipulação-de-dados",
    "href": "Aula 1.2.html#manipulação-de-dados",
    "title": "Aula 01 - Manipulações de dados",
    "section": "",
    "text": "Para manipulação de dados e/ou data frames, é possível adotar funções presentes no pacote dplyr. Alguns exemplos.\n\nlibrary(dplyr)\n\n\n\nEssa função é capaz de criar novas colunas em função das já existentes. Além disso, com ela é possível modificar e deletar colunas.\n\ndf &lt;- df %&gt;% \n  mutate(C = A*0.5,\n         D = A^2,\n         E = B*C*A)\ndf\n\n    A   B    C   D       E\n1   1   5  0.5   1     2.5\n2   2  10  1.0   4    20.0\n3   3  15  1.5   9    67.5\n4   4  20  2.0  16   160.0\n5   5  25  2.5  25   312.5\n6   6  30  3.0  36   540.0\n7   7  35  3.5  49   857.5\n8   8  40  4.0  64  1280.0\n9   9  45  4.5  81  1822.5\n10 10  50  5.0 100  2500.0\n11 11  55  5.5 121  3327.5\n12 12  60  6.0 144  4320.0\n13 13  65  6.5 169  5492.5\n14 14  70  7.0 196  6860.0\n15 15  75  7.5 225  8437.5\n16 16  80  8.0 256 10240.0\n17 17  85  8.5 289 12282.5\n18 18  90  9.0 324 14580.0\n19 19  95  9.5 361 17147.5\n20 20 100 10.0 400 20000.0\n\n\nPara deletar colunas:\n\ndf &lt;- df %&gt;% \n  mutate(C = NULL)\ndf\n\n    A   B   D       E\n1   1   5   1     2.5\n2   2  10   4    20.0\n3   3  15   9    67.5\n4   4  20  16   160.0\n5   5  25  25   312.5\n6   6  30  36   540.0\n7   7  35  49   857.5\n8   8  40  64  1280.0\n9   9  45  81  1822.5\n10 10  50 100  2500.0\n11 11  55 121  3327.5\n12 12  60 144  4320.0\n13 13  65 169  5492.5\n14 14  70 196  6860.0\n15 15  75 225  8437.5\n16 16  80 256 10240.0\n17 17  85 289 12282.5\n18 18  90 324 14580.0\n19 19  95 361 17147.5\n20 20 100 400 20000.0\n\n\n\n\n\nEssa função permite alterar o nome atribuído as colunas, usando a seguinte ordem: nome novo = nome antigo. Por exemplo:\n\ndf &lt;- df %&gt;% \n  rename(C = E)\ndf\n\n    A   B   D       C\n1   1   5   1     2.5\n2   2  10   4    20.0\n3   3  15   9    67.5\n4   4  20  16   160.0\n5   5  25  25   312.5\n6   6  30  36   540.0\n7   7  35  49   857.5\n8   8  40  64  1280.0\n9   9  45  81  1822.5\n10 10  50 100  2500.0\n11 11  55 121  3327.5\n12 12  60 144  4320.0\n13 13  65 169  5492.5\n14 14  70 196  6860.0\n15 15  75 225  8437.5\n16 16  80 256 10240.0\n17 17  85 289 12282.5\n18 18  90 324 14580.0\n19 19  95 361 17147.5\n20 20 100 400 20000.0\n\n\n\n\n\nCom essa função, é possível criar um novo data frame, selecionado colunas de um data frame já existente, por exemplo:\n\ndf2 &lt;- df %&gt;% \n  select(A, B, C)\ndf2\n\n    A   B       C\n1   1   5     2.5\n2   2  10    20.0\n3   3  15    67.5\n4   4  20   160.0\n5   5  25   312.5\n6   6  30   540.0\n7   7  35   857.5\n8   8  40  1280.0\n9   9  45  1822.5\n10 10  50  2500.0\n11 11  55  3327.5\n12 12  60  4320.0\n13 13  65  5492.5\n14 14  70  6860.0\n15 15  75  8437.5\n16 16  80 10240.0\n17 17  85 12282.5\n18 18  90 14580.0\n19 19  95 17147.5\n20 20 100 20000.0\n\n\nSe for utilizado o operador :, serão selecionadas todas as colunas entre o intervalo especificado, por exemplo:\n\ndf3 &lt;- df %&gt;% \n  select(B:C)\ndf3\n\n     B   D       C\n1    5   1     2.5\n2   10   4    20.0\n3   15   9    67.5\n4   20  16   160.0\n5   25  25   312.5\n6   30  36   540.0\n7   35  49   857.5\n8   40  64  1280.0\n9   45  81  1822.5\n10  50 100  2500.0\n11  55 121  3327.5\n12  60 144  4320.0\n13  65 169  5492.5\n14  70 196  6860.0\n15  75 225  8437.5\n16  80 256 10240.0\n17  85 289 12282.5\n18  90 324 14580.0\n19  95 361 17147.5\n20 100 400 20000.0\n\n\n\n\n\nEssa função ordena as linhas de um data frame em função dos valores das colunas selecionadas. Por exemlo:\n\ndf2 %&gt;% \n  arrange(A,C)\n\n    A   B       C\n1   1   5     2.5\n2   2  10    20.0\n3   3  15    67.5\n4   4  20   160.0\n5   5  25   312.5\n6   6  30   540.0\n7   7  35   857.5\n8   8  40  1280.0\n9   9  45  1822.5\n10 10  50  2500.0\n11 11  55  3327.5\n12 12  60  4320.0\n13 13  65  5492.5\n14 14  70  6860.0\n15 15  75  8437.5\n16 16  80 10240.0\n17 17  85 12282.5\n18 18  90 14580.0\n19 19  95 17147.5\n20 20 100 20000.0\n\n\nOu em ordem decrescente, com o argumento desc:\n\ndf2 %&gt;% \n  arrange(desc(A))\n\n    A   B       C\n1  20 100 20000.0\n2  19  95 17147.5\n3  18  90 14580.0\n4  17  85 12282.5\n5  16  80 10240.0\n6  15  75  8437.5\n7  14  70  6860.0\n8  13  65  5492.5\n9  12  60  4320.0\n10 11  55  3327.5\n11 10  50  2500.0\n12  9  45  1822.5\n13  8  40  1280.0\n14  7  35   857.5\n15  6  30   540.0\n16  5  25   312.5\n17  4  20   160.0\n18  3  15    67.5\n19  2  10    20.0\n20  1   5     2.5\n\n\n\n\n\nCom essa função é possível filtrar linhas do data frame que satisfaçam uma condição específica. Por exemplo:\n\ndf4 &lt;- df2 %&gt;% \n  filter(A &gt;= 5)\ndf4\n\n    A   B       C\n1   5  25   312.5\n2   6  30   540.0\n3   7  35   857.5\n4   8  40  1280.0\n5   9  45  1822.5\n6  10  50  2500.0\n7  11  55  3327.5\n8  12  60  4320.0\n9  13  65  5492.5\n10 14  70  6860.0\n11 15  75  8437.5\n12 16  80 10240.0\n13 17  85 12282.5\n14 18  90 14580.0\n15 19  95 17147.5\n16 20 100 20000.0\n\ndf5 &lt;- df2 %&gt;% \n  filter(A &lt; 5)\ndf5\n\n  A  B     C\n1 1  5   2.5\n2 2 10  20.0\n3 3 15  67.5\n4 4 20 160.0\n\ndf6 &lt;- df2 %&gt;% \n  filter(A == 5)\ndf6\n\n  A  B     C\n1 5 25 312.5\n\n\n\n\n\nCom essa função é possível selecionar uma coluna de interesse e obter medidas estatísticas dela. Com isso é criado um novo data frame as medidas selecionadas. Alguns exemplos:\n\nsumm &lt;- df2 %&gt;% \n  summarise(media = mean (A),\n            mediana = median(A),\n            sd = sd(A),\n            min = min(A),\n            max = max(A))\nsumm\n\n  media mediana      sd min max\n1  10.5    10.5 5.91608   1  20",
    "crumbs": [
      "Home",
      "Aula 01",
      "Manipulações de dados"
    ]
  },
  {
    "objectID": "Aula 10.2.html",
    "href": "Aula 10.2.html",
    "title": "Aula 10 - Regressão linear de segunda ordem (quadrática)",
    "section": "",
    "text": "estande &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=401662555\")\n\nNa aula anterior, foi visto que o ensaio 2 não apresentava uma tendência linear.\nEsse ensaio será utilizado para exemplificar uma regressão linear de segunda ordem.\n\nexp2 &lt;- estande %&gt;% \n  filter(exp == 2)\n\n\nexp2 %&gt;% \n  ggplot(aes(trat, nplants))+\n  geom_point()+\n  ylim(0,100)+\n  geom_smooth(method = \"lm\",\n              se = F,\n              color = \"green\",\n              formula = y ~ poly(x,2))+\n  geom_smooth(method = \"lm\",\n              se = F,\n              color = \"red\")\n\n\n\n\n\n\n\n\nEm vermelho, a linha que indica o modelo linear de primeira ordem. Em verde, o modelo linear de segunda ordem.\n\n\n\nlm2 &lt;- lm(nplants ~ trat,\n          data = exp2)\n\nsummary(lm2)\n\n\nCall:\nlm(formula = nplants ~ trat, data = exp2)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-25.7816  -7.7150   0.5653   8.1929  19.2184 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  60.9857     3.6304  16.798 4.93e-14 ***\ntrat         -0.7007     0.1605  -4.365 0.000247 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 12.95 on 22 degrees of freedom\nMultiple R-squared:  0.4641,    Adjusted R-squared:  0.4398 \nF-statistic: 19.05 on 1 and 22 DF,  p-value: 0.0002473\n\n\nComo o resultado demonstra, para o modelo linear, o coeficiente de determinação é baixo (R2 = 0.43) , logo boa parte da variação dos dados não são explicados por esse modelo.\n\n\n\nPara construir o modelo quadrático é preciso acrescentar uma coluna ao conjunto de dados, onde a varíavel independente (nesse caso, trat) será elevada ao quadrado. Isso é necessário para obtermos um segundo coeficiente no momento de criar o modelo.\n\nexp2$trat2 &lt;- exp2$trat^2\n\n\nlm2_quad &lt;- lm(nplants ~ trat + trat2,\n               data = exp2)\nsummary(lm2_quad)\n\n\nCall:\nlm(formula = nplants ~ trat + trat2, data = exp2)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-25.439  -6.019   1.789   8.016  19.561 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 66.30156    4.42097  14.997 1.08e-12 ***\ntrat        -1.77720    0.58467  -3.040  0.00623 ** \ntrat2        0.02223    0.01166   1.906  0.07036 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 12.24 on 21 degrees of freedom\nMultiple R-squared:  0.5432,    Adjusted R-squared:  0.4997 \nF-statistic: 12.49 on 2 and 21 DF,  p-value: 0.0002675\n\n\nCom a função polynomial (AgroR):\n\nwith(exp2, polynomial(trat, nplants, grau = 2))\n\n\n----------------------------------------------------\nRegression Models\n----------------------------------------------------\n               Estimate Std. Error   t value     Pr(&gt;|t|)\n(Intercept) 66.30156250 4.42096799 14.997069 1.079972e-12\ntrat        -1.77719814 0.58467380 -3.039640 6.230050e-03\nI(trat^2)    0.02222876 0.01165948  1.906496 7.036247e-02\n\n----------------------------------------------------\nDeviations from regression\n----------------------------------------------------\n          Df       SSq       MSQ         F      p-value\nLinear     1 3196.2031 3196.2031 21.823293 0.0001899378\nQuadratic  1  544.5029  544.5029  3.717801 0.0697619482\nDeviation  3  509.6690  169.8897  1.159986 0.3523240106\nResidual  18 2636.2500  146.4583                       \n\n\n[[1]]\n\n\n\n\n\n\n\n\n\n\n\n\n\nAIC(lm2)\n\n[1] 194.9597\n\nAIC(lm2_quad)\n\n[1] 193.1284\n\n\nPelo teste de AIC, em comparação ao modelo linear, o modelo quadrático explica melhor a variação dos dados, pois AIC(lm2_quad) &lt; AIC(lm2).\n\n\n\nwith(exp2, polynomial(trat, nplants, grau = 3))\n\n\n----------------------------------------------------\nRegression Models\n----------------------------------------------------\n                Estimate  Std. Error   t value     Pr(&gt;|t|)\n(Intercept) 70.265143802 5.300440019 13.256474 2.295186e-11\ntrat        -3.609380523 1.514625525 -2.383018 2.720299e-02\nI(trat^2)    0.140522077 0.091192577  1.540938 1.390058e-01\nI(trat^3)   -0.001712445 0.001309648 -1.307561 2.058546e-01\n\n----------------------------------------------------\nDeviations from regression\n----------------------------------------------------\n          Df       SSq       MSQ          F      p-value\nLinear     1 3196.2031 3196.2031 21.8232929 0.0001899378\nQuadratic  1  544.5029  544.5029  3.7178008 0.0697619482\nCubic      1  247.7520  247.7520  1.6916208 0.2097934169\nDeviation  2  261.9170  130.9585  0.8941691 0.4263523326\nResidual  18 2636.2500  146.4583                        \n\n\n[[1]]\n\n\n\n\n\n\n\n\n\nApesar do polinômio de grau 3 explicar melhor os dados, o modelo não possui explicação biológica plausível (do estande de plantas aumentar em função do aumento do inóculo para depois decrescer).",
    "crumbs": [
      "Home",
      "Aula 10",
      "Regressão linear de segunda ordem (quadrática)"
    ]
  },
  {
    "objectID": "Aula 10.2.html#regressão-linear-de-segunda-ordem-quadrática",
    "href": "Aula 10.2.html#regressão-linear-de-segunda-ordem-quadrática",
    "title": "Aula 10 - Regressão linear de segunda ordem (quadrática)",
    "section": "",
    "text": "estande &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=401662555\")\n\nNa aula anterior, foi visto que o ensaio 2 não apresentava uma tendência linear.\nEsse ensaio será utilizado para exemplificar uma regressão linear de segunda ordem.\n\nexp2 &lt;- estande %&gt;% \n  filter(exp == 2)\n\n\nexp2 %&gt;% \n  ggplot(aes(trat, nplants))+\n  geom_point()+\n  ylim(0,100)+\n  geom_smooth(method = \"lm\",\n              se = F,\n              color = \"green\",\n              formula = y ~ poly(x,2))+\n  geom_smooth(method = \"lm\",\n              se = F,\n              color = \"red\")\n\n\n\n\n\n\n\n\nEm vermelho, a linha que indica o modelo linear de primeira ordem. Em verde, o modelo linear de segunda ordem.\n\n\n\nlm2 &lt;- lm(nplants ~ trat,\n          data = exp2)\n\nsummary(lm2)\n\n\nCall:\nlm(formula = nplants ~ trat, data = exp2)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-25.7816  -7.7150   0.5653   8.1929  19.2184 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  60.9857     3.6304  16.798 4.93e-14 ***\ntrat         -0.7007     0.1605  -4.365 0.000247 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 12.95 on 22 degrees of freedom\nMultiple R-squared:  0.4641,    Adjusted R-squared:  0.4398 \nF-statistic: 19.05 on 1 and 22 DF,  p-value: 0.0002473\n\n\nComo o resultado demonstra, para o modelo linear, o coeficiente de determinação é baixo (R2 = 0.43) , logo boa parte da variação dos dados não são explicados por esse modelo.\n\n\n\nPara construir o modelo quadrático é preciso acrescentar uma coluna ao conjunto de dados, onde a varíavel independente (nesse caso, trat) será elevada ao quadrado. Isso é necessário para obtermos um segundo coeficiente no momento de criar o modelo.\n\nexp2$trat2 &lt;- exp2$trat^2\n\n\nlm2_quad &lt;- lm(nplants ~ trat + trat2,\n               data = exp2)\nsummary(lm2_quad)\n\n\nCall:\nlm(formula = nplants ~ trat + trat2, data = exp2)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-25.439  -6.019   1.789   8.016  19.561 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 66.30156    4.42097  14.997 1.08e-12 ***\ntrat        -1.77720    0.58467  -3.040  0.00623 ** \ntrat2        0.02223    0.01166   1.906  0.07036 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 12.24 on 21 degrees of freedom\nMultiple R-squared:  0.5432,    Adjusted R-squared:  0.4997 \nF-statistic: 12.49 on 2 and 21 DF,  p-value: 0.0002675\n\n\nCom a função polynomial (AgroR):\n\nwith(exp2, polynomial(trat, nplants, grau = 2))\n\n\n----------------------------------------------------\nRegression Models\n----------------------------------------------------\n               Estimate Std. Error   t value     Pr(&gt;|t|)\n(Intercept) 66.30156250 4.42096799 14.997069 1.079972e-12\ntrat        -1.77719814 0.58467380 -3.039640 6.230050e-03\nI(trat^2)    0.02222876 0.01165948  1.906496 7.036247e-02\n\n----------------------------------------------------\nDeviations from regression\n----------------------------------------------------\n          Df       SSq       MSQ         F      p-value\nLinear     1 3196.2031 3196.2031 21.823293 0.0001899378\nQuadratic  1  544.5029  544.5029  3.717801 0.0697619482\nDeviation  3  509.6690  169.8897  1.159986 0.3523240106\nResidual  18 2636.2500  146.4583                       \n\n\n[[1]]\n\n\n\n\n\n\n\n\n\n\n\n\n\nAIC(lm2)\n\n[1] 194.9597\n\nAIC(lm2_quad)\n\n[1] 193.1284\n\n\nPelo teste de AIC, em comparação ao modelo linear, o modelo quadrático explica melhor a variação dos dados, pois AIC(lm2_quad) &lt; AIC(lm2).\n\n\n\nwith(exp2, polynomial(trat, nplants, grau = 3))\n\n\n----------------------------------------------------\nRegression Models\n----------------------------------------------------\n                Estimate  Std. Error   t value     Pr(&gt;|t|)\n(Intercept) 70.265143802 5.300440019 13.256474 2.295186e-11\ntrat        -3.609380523 1.514625525 -2.383018 2.720299e-02\nI(trat^2)    0.140522077 0.091192577  1.540938 1.390058e-01\nI(trat^3)   -0.001712445 0.001309648 -1.307561 2.058546e-01\n\n----------------------------------------------------\nDeviations from regression\n----------------------------------------------------\n          Df       SSq       MSQ          F      p-value\nLinear     1 3196.2031 3196.2031 21.8232929 0.0001899378\nQuadratic  1  544.5029  544.5029  3.7178008 0.0697619482\nCubic      1  247.7520  247.7520  1.6916208 0.2097934169\nDeviation  2  261.9170  130.9585  0.8941691 0.4263523326\nResidual  18 2636.2500  146.4583                        \n\n\n[[1]]\n\n\n\n\n\n\n\n\n\nApesar do polinômio de grau 3 explicar melhor os dados, o modelo não possui explicação biológica plausível (do estande de plantas aumentar em função do aumento do inóculo para depois decrescer).",
    "crumbs": [
      "Home",
      "Aula 10",
      "Regressão linear de segunda ordem (quadrática)"
    ]
  },
  {
    "objectID": "Aula 11.html",
    "href": "Aula 11.html",
    "title": "Aula 11",
    "section": "",
    "text": "Nesta aula, serão apresentadas formas de confeccionar mapas utilizando o R. Além dos pacotes comumente utilizados até o momento, três novos serão essenciais: rnaturalearth, rnaturalearthhires e ggspatial.",
    "crumbs": [
      "Home",
      "Aula 11",
      "Construção de gráficos com R"
    ]
  },
  {
    "objectID": "Aula 11.html#carregando-os-pacotes",
    "href": "Aula 11.html#carregando-os-pacotes",
    "title": "Aula 11",
    "section": "Carregando os pacotes",
    "text": "Carregando os pacotes\n\n#|eval: false\n#|output: false\n\n\n#Para instalar o pacote rnaturalearthhires:\nremotes::install_github(\"ropensci/rnaturalearthhires\")\n\n\n── R CMD build ─────────────────────────────────────────────────────────────────\n* checking for file 'C:\\Users\\Caio Mattos\\AppData\\Local\\Temp\\Rtmp4U32XU\\remotes391853fe5fd5\\ropensci-rnaturalearthhires-dd1e210/DESCRIPTION' ... OK\n* preparing 'rnaturalearthhires':\n* checking DESCRIPTION meta-information ... OK\n* checking for LF line-endings in source and make files and shell scripts\n* checking for empty or unneeded directories\n* building 'rnaturalearthhires_1.0.0.9000.tar.gz'\n\n\ninstall.packages(\"rnaturalearthhires\", repos = \"https://ropensci.r-universe.dev\", type = \"source\")\n\n\nlibrary(tidyverse)\nlibrary(gsheet)\nlibrary(ggthemes)\nlibrary(r4pde)\nlibrary(ggspatial)\nlibrary(rnaturalearth)\nlibrary(rnaturalearthhires)\nlibrary(plotly)",
    "crumbs": [
      "Home",
      "Aula 11",
      "Construção de gráficos com R"
    ]
  },
  {
    "objectID": "Aula 11.html#criando-mapas",
    "href": "Aula 11.html#criando-mapas",
    "title": "Aula 11",
    "section": "Criando mapas",
    "text": "Criando mapas\n\nMapa-múndi\nPara criação de um mapa simples, faremos uso de dois pacotes: rnaturalearth e ggplot.\nCom a função ne_countries, é possível criar mapa-múndi, mapas de continentes ou países. Um vez definida a região, a função geom_sf é utilizada para visualização de objetos “simple feature” (sf).\n\nWORLD &lt;- ne_countries()\n\nggplot(WORLD)+\n  geom_sf()+\n  theme_map()\n\n\n\n\n\n\n\n\nPara criar um mapa destacando um continente ou país, por exemplo, utilizamos os argumentos continent ou country, respectivamente:\n\nAS &lt;- ne_countries(continent = \"Asia\")\n\nggplot(AS)+\n  geom_sf()+\n  theme_map()\n\n\n\n\n\n\n\n\n\nPara criar um mapa-múndi com países selecionados em destaque:\n\n# Definindo os países a serem destacados\nWORLD_destaque &lt;- c(\"Brazil\", \"China\", \"France\", \"Ethiopia\", \"Australia\")\n\n# Criando uma coluna para identificar os países selecionados\nWORLD$destaque &lt;- ifelse(WORLD$name %in% WORLD_destaque, \"destaque\", \"normal\")\n\n# Plotando o mapa com os países destacados\nggplot(data = WORLD) +\n  geom_sf(aes(fill = destaque), color = \"black\", show.legend = FALSE) +\n  scale_fill_manual(values = c(\"destaque\" = \"darkred\", \"normal\" = \"white\")) +\n  theme_map ()\n\n\n\n\n\n\n\n\n\n\nMapas de países\nPara criar um mapa de um país, é utilizada a função ne_states, incluindo o argumento country em que é definido o país de interesse.\n\nBRA &lt;- ne_states(country = \"Brazil\",\n                 returnclass = c(\"sf\"))\n\nggplot(BRA) + \n  geom_sf(fill = \"white\",\n          color = \"black\")#+\n\n\n\n\n\n\n\n  #theme_map()\n\nA partir do objeto criado anteriormente, é possível criar um mapa destacando um estado ou localidade de interesse. Para isso, é criado um novo objeto, filtrando o estado de interesse, por exemplo, Minas Gerais:\n\nMG &lt;- BRA %&gt;% \n  filter(name_en == \"Minas Gerais\")\n\nMapa com o estado em destaque:\n\nggplot(BRA) +\ngeom_sf(color = \"black\",\n          fill = \"white\") +\n  geom_sf(data = MG, \n          color = \"lightgrey\",\n          fill = \"darkred\")\n\n\n\n\n\n\n\n\nMapa de um estado:\n\nggplot(MG) +\n  geom_sf(fill = \"white\")",
    "crumbs": [
      "Home",
      "Aula 11",
      "Construção de gráficos com R"
    ]
  },
  {
    "objectID": "Aula 11.html#criando-mapas-interativos",
    "href": "Aula 11.html#criando-mapas-interativos",
    "title": "Aula 11",
    "section": "Criando mapas interativos",
    "text": "Criando mapas interativos\nCom o R, também é possível criarmos mapas interativos, seja com a função ggplotly (plotly) ou com a função leaflet (leaflet).\n\nCom plotly\n\nBR_int &lt;- ggplot(BRA) +\n  geom_sf(fill = \"white\",\n          color = \"black\",\n          linewidth = 0.3)+\n  theme_map()\n\nggplotly(BR_int)\n\n\n\n\n\n\n\nCom leaflet\nCom a função leaflet é possível criar mapas de localidades específicas. Para isso, é preciso conhecer a latitude e a longitude do local de interesse.\nSerá usado como exemplo a longitude e latitude de Viçosa (lng = -42.8825, lat = -20.7546).\n\nlibrary(leaflet)\n\nleaflet() %&gt;% \n  addTiles() %&gt;% \n  setView(lng = -42.8825, lat = -20.7546, zoom = 13)\n\n\n\n\n\nOs mapas gerados pela função leaflet são customizáveis e uma opção interessante é utilizar visuais (aparências) de terceiros, o que é possível com a função addProviderTiles. Uma lista de opções pode ser encontrada em “providers”.\n\nleaflet() %&gt;% \n  addProviderTiles(providers$OpenStreetMap.Mapnik) %&gt;% \n  setView(lng = -42.87127507493794, lat = -20.758814863222565, zoom = 18)",
    "crumbs": [
      "Home",
      "Aula 11",
      "Construção de gráficos com R"
    ]
  },
  {
    "objectID": "Aula 11.html#mapas-interativos-com-pontos",
    "href": "Aula 11.html#mapas-interativos-com-pontos",
    "title": "Aula 11",
    "section": "Mapas interativos com pontos",
    "text": "Mapas interativos com pontos\nPara criar um mapa com pontos é preciso que no conjunto de dados existam colunas identificadas como “latitude” (ou lat) e longitutude” (ou lgn). Essas coordenadas serão necessárias para plotar (geom_point) os pontos no gráfico.\n\nsbr &lt;- r4pde::RustSoybean\n\n\nBR_int &lt;- ggplot(BRA) +\n  geom_sf(fill = \"white\",\n          color = \"black\",\n          linewidth = 0.3)+\n  geom_point(data = sbr,\n             aes(longitude, latitude),\n             color = \"darkred\")+\n  theme_map()\n\nggplotly(BR_int)\n\n\n\n\n\nO mesmo pode ser feito com a função leaflet. No entanto, nesse caso, é preciso identificar o conjunto de dados e utilizar uma segunda função (addCircleMarkers) que permitirá adicionar a camada com os pontos.\n\nleaflet(sbr,\n        options = leafletOptions(minZoom = 4,\n                                 maxZoom = 6)) %&gt;% \n  addTiles() %&gt;% \n #comando que permite centralizar o mapa em um local:\n #setView(lng = -42.8825, lat = -20.7546, zoom = 4) %&gt;% \n  addCircleMarkers(radius = 5,\n                   stroke = FALSE)",
    "crumbs": [
      "Home",
      "Aula 11",
      "Construção de gráficos com R"
    ]
  },
  {
    "objectID": "Aula 11.html#criando-mapas-associados-a-gráficos",
    "href": "Aula 11.html#criando-mapas-associados-a-gráficos",
    "title": "Aula 11",
    "section": "Criando mapas associados a gráficos",
    "text": "Criando mapas associados a gráficos\nPara exemplificar essa aplicação, será utilizado um conjunto de dados que relata a ocorrência de doenças em determinadas localidades.\n\ndata &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1pAIFKsdKxk_UQQXdYwIO-O5NOkYNhpclImJcLziYnk4/edit#gid=50258992\")\n\nAlém disso, dois novos pacotes serão utilizados:\nggrepel, função que permite adicionar nomes aos pontos de latitude e longitude.\nscatterpie, função que transforma os pontos em um gráfico de pizza, em função das variáveis.\n\nlibrary(ggrepel)\nlibrary(scatterpie)\n\n\nCriando o mapa\n\nggplot(BRA) +\n  geom_sf(fill = \"gray70\", alpha = 0.5, color = \"white\") +\n  coord_sf()+\n  geom_scatterpie(aes(x = lon, y = lat, r = 0.6), alpha = 0.8, color = NA, data = data,\n                  cols = c(\"DFC\",\n                           \"MA\",\n                           \"FER\",\n                           \"ANTR\",\n                           \"OIDIO\"))+\n  geom_text_repel(data = data, aes(lon, lat, label = Local),\n                   size = 2, nudge_x = 0.2, nudge_y = 0.27, color = \"gray30\", family = \"Arial\") +\n  ggthemes::scale_fill_calc()+\n  ggthemes::theme_map() +\n  labs(x = \"Longitude\", \n       y = \"Latitude\", \n       legend = \"\", \n       fill = \"Doença\")+\n  theme(legend.position = \"bottom\", \n        text = element_text(family = \"Arial\", size = 8))",
    "crumbs": [
      "Home",
      "Aula 11",
      "Construção de gráficos com R"
    ]
  },
  {
    "objectID": "Aula 2.2.html",
    "href": "Aula 2.2.html",
    "title": "Aula 02 - Importação de dados e criação de gráficos simples",
    "section": "",
    "text": "A seguir os pacotes tidyverse, ggplot2 e ggthemes serão utilizados para gerar um gráfico e possibilitar uma visualização rápida de um determinado dataframe carregado.\n\nlibrary(tidyverse)\nlibrary(ggplot2)\nlibrary(ggthemes)\n\n\nInicialmente, será feito um gráfico simples de pontos. O objetivo é plotar as observações, de acordo com os tratamentos, e conhecer a distribuição dos dados de um determinado data frame (df4):\n\ng1 &lt;- df4 %&gt;% \n  ggplot(aes(trat, comp))+\n  geom_point()\n\ng1\n\n\n\n\n\n\n\n\n\nUm segundo gráfico simples, de outro conjunto de dados:\n\ng2 &lt;- df1 %&gt;%\n  ggplot(aes(growth))+\n  geom_histogram()\n\ng2\n\n\n\n\n\n\n\n\n\nA seguir, será feito um novo plot. Este, consistirá de um gráfico do tipo boxplot, acrescido de pontos dispersos:\n\ng3 &lt;- df4 %&gt;%\n  ggplot(aes(trat, comp))+\n  geom_boxplot(outlier.alpha = 0)+\n  geom_jitter(width = 0.07,\n              color = \"black\",\n              shape = 1,\n              size = 2)+\n  scale_y_continuous(limits = c(0,20), n.breaks = 10)+\n  #ylim(0,20)+\n  labs(x = \"Tratamento\", y = \"Comprimento\", title = \"Boxplot\", caption = \"Fonte: Primeiro Boxplot\")+\n  theme_clean()\n\ng3\n\n\n\n\n\n\n\n\n\nPor fim, para salvar os gráficos gerados, podemos utilizar a função ggsave. Porém, essa função salvará o último gráfico gerado.\n\nggsave(\"Boxplot.png\", bg=\"transparent\")\n\n\nOutra opção para salvar plots gerados anteriormente é a seguinte:\n\n#Em .pdf:\npdf(\"histograma.pdf\", bg = \"transparent\")\nprint(g2)\ndev.off()\n\n#Em .png:\npng(\"Pontos.png\", bg = \"transparent\")\nprint(g1)\ndev.off()",
    "crumbs": [
      "Home",
      "Aula 02",
      "Importação de dados e criação de gráficos simples"
    ]
  },
  {
    "objectID": "Aula 2.2.html#uso-do-tidyverse-ggplot2-para-visualização-rápida-dos-dados",
    "href": "Aula 2.2.html#uso-do-tidyverse-ggplot2-para-visualização-rápida-dos-dados",
    "title": "Aula 02 - Importação de dados e criação de gráficos simples",
    "section": "",
    "text": "A seguir os pacotes tidyverse, ggplot2 e ggthemes serão utilizados para gerar um gráfico e possibilitar uma visualização rápida de um determinado dataframe carregado.\n\nlibrary(tidyverse)\nlibrary(ggplot2)\nlibrary(ggthemes)\n\n\nInicialmente, será feito um gráfico simples de pontos. O objetivo é plotar as observações, de acordo com os tratamentos, e conhecer a distribuição dos dados de um determinado data frame (df4):\n\ng1 &lt;- df4 %&gt;% \n  ggplot(aes(trat, comp))+\n  geom_point()\n\ng1\n\n\n\n\n\n\n\n\n\nUm segundo gráfico simples, de outro conjunto de dados:\n\ng2 &lt;- df1 %&gt;%\n  ggplot(aes(growth))+\n  geom_histogram()\n\ng2\n\n\n\n\n\n\n\n\n\nA seguir, será feito um novo plot. Este, consistirá de um gráfico do tipo boxplot, acrescido de pontos dispersos:\n\ng3 &lt;- df4 %&gt;%\n  ggplot(aes(trat, comp))+\n  geom_boxplot(outlier.alpha = 0)+\n  geom_jitter(width = 0.07,\n              color = \"black\",\n              shape = 1,\n              size = 2)+\n  scale_y_continuous(limits = c(0,20), n.breaks = 10)+\n  #ylim(0,20)+\n  labs(x = \"Tratamento\", y = \"Comprimento\", title = \"Boxplot\", caption = \"Fonte: Primeiro Boxplot\")+\n  theme_clean()\n\ng3\n\n\n\n\n\n\n\n\n\nPor fim, para salvar os gráficos gerados, podemos utilizar a função ggsave. Porém, essa função salvará o último gráfico gerado.\n\nggsave(\"Boxplot.png\", bg=\"transparent\")\n\n\nOutra opção para salvar plots gerados anteriormente é a seguinte:\n\n#Em .pdf:\npdf(\"histograma.pdf\", bg = \"transparent\")\nprint(g2)\ndev.off()\n\n#Em .png:\npng(\"Pontos.png\", bg = \"transparent\")\nprint(g1)\ndev.off()",
    "crumbs": [
      "Home",
      "Aula 02",
      "Importação de dados e criação de gráficos simples"
    ]
  },
  {
    "objectID": "Aula 4.1.html",
    "href": "Aula 4.1.html",
    "title": "Aula 04 - Uso do datapasta",
    "section": "",
    "text": "Nesta aula, serão apresentados diversas operações com dados datapasta, para copiar e colar dados como vetores, data frames e tribbles. Além disso, serão feitas tabelas de contingência e gráficos de barras para análise de dados categóricos, utilizando as funções count e tabyl do pacote janitor.",
    "crumbs": [
      "Home",
      "Aula 04",
      "Uso do datapasta"
    ]
  },
  {
    "objectID": "Aula 4.1.html#carregando-os-pacotes",
    "href": "Aula 4.1.html#carregando-os-pacotes",
    "title": "Aula 04 - Uso do datapasta",
    "section": "Carregando os pacotes",
    "text": "Carregando os pacotes\nInicialmente, serão instalados (datapasta e janitor) e carregados os pacotes que serão necessários durante esta aula:\n\ninstall.packages(\"datapasta\")\ninstall.packages(\"janitor\")\n\n\nlibrary(datapasta)\nlibrary(janitor)\nlibrary(tidyverse)\nlibrary(ggthemes)",
    "crumbs": [
      "Home",
      "Aula 04",
      "Uso do datapasta"
    ]
  },
  {
    "objectID": "Aula 4.1.html#pacote-datapasta",
    "href": "Aula 4.1.html#pacote-datapasta",
    "title": "Aula 04 - Uso do datapasta",
    "section": "Pacote datapasta",
    "text": "Pacote datapasta\nO pacote datapasta fornece ao RStudio funções adicionais que permitem copiar e colar dados de outras fontes.\nPara usá-lo é preciso criar um novo chunk, copiar os valores desejados, clicar em Addins e selecionar o formato em que os valores serão colados.\n\nPaste as vector\nPara colar valores como um vetor, seleciona-se “Paste as vector”\n\nvet &lt;- c(\"comp\", \"9\", \"12.5\", \"10\", \"8\", \"13.2\", \"11\", \"10.8\", \"9.5\", \"10.8\", \"10.4\", \"13.72\", \"15.91\", \"15.7\", \"14.2\", \"15.9\", \"16.54\", \"18\", \"14.4\", \"16.41\", \"16\")\n\n\n\nPaste as data.frame\nAlém disso, também é possível colar valores como um data frame. Nesse caso, valores presentes em mais de uma coluna são copiados e colados selecionando a função “Paste as data.frame”:\n\ndat &lt;- data.frame(\n  stringsAsFactors = FALSE,\n                     trat = c(\"Mg2\",\"Mg2\",\n                              \"Mg2\",\"Mg2\",\"Mg2\",\"Mg2\",\"Mg2\",\"Mg2\",\"Mg2\",\n                              \"Mg2\",\"control\",\"control\",\"control\",\"control\",\n                              \"control\",\"control\",\"control\",\"control\",\"control\",\n                              \"control\"),\n                      rep = c(1L,2L,3L,4L,\n                              5L,6L,7L,8L,9L,10L,1L,2L,3L,4L,5L,6L,7L,\n                              8L,9L,10L),\n                     comp = c(9,12.5,10,8,\n                              13.2,11,10.8,9.5,10.8,10.4,13.72,15.91,15.7,\n                              14.2,15.9,16.54,18,14.4,16.41,16))\n\ndat\n\n      trat rep  comp\n1      Mg2   1  9.00\n2      Mg2   2 12.50\n3      Mg2   3 10.00\n4      Mg2   4  8.00\n5      Mg2   5 13.20\n6      Mg2   6 11.00\n7      Mg2   7 10.80\n8      Mg2   8  9.50\n9      Mg2   9 10.80\n10     Mg2  10 10.40\n11 control   1 13.72\n12 control   2 15.91\n13 control   3 15.70\n14 control   4 14.20\n15 control   5 15.90\n16 control   6 16.54\n17 control   7 18.00\n18 control   8 14.40\n19 control   9 16.41\n20 control  10 16.00\n\n\n\n\nPaste as tribble\nOutra opção para criar um novo data frame é colar utilizando a opção “Paste as tribble”:\n\ndat2 &lt;- tibble::tribble(\n      ~trat, ~rep, ~comp,\n      \"Mg2\",   1L,     9,\n      \"Mg2\",   2L,  12.5,\n      \"Mg2\",   3L,    10,\n      \"Mg2\",   4L,     8,\n      \"Mg2\",   5L,  13.2,\n      \"Mg2\",   6L,    11,\n      \"Mg2\",   7L,  10.8,\n      \"Mg2\",   8L,   9.5,\n      \"Mg2\",   9L,  10.8,\n      \"Mg2\",  10L,  10.4,\n  \"control\",   1L, 13.72,\n  \"control\",   2L, 15.91,\n  \"control\",   3L,  15.7,\n  \"control\",   4L,  14.2,\n  \"control\",   5L,  15.9,\n  \"control\",   6L, 16.54,\n  \"control\",   7L,    18,\n  \"control\",   8L,  14.4,\n  \"control\",   9L, 16.41,\n  \"control\",  10L,    16\n  )\n\ndat2\n\n# A tibble: 20 × 3\n   trat      rep  comp\n   &lt;chr&gt;   &lt;int&gt; &lt;dbl&gt;\n 1 Mg2         1   9  \n 2 Mg2         2  12.5\n 3 Mg2         3  10  \n 4 Mg2         4   8  \n 5 Mg2         5  13.2\n 6 Mg2         6  11  \n 7 Mg2         7  10.8\n 8 Mg2         8   9.5\n 9 Mg2         9  10.8\n10 Mg2        10  10.4\n11 control     1  13.7\n12 control     2  15.9\n13 control     3  15.7\n14 control     4  14.2\n15 control     5  15.9\n16 control     6  16.5\n17 control     7  18  \n18 control     8  14.4\n19 control     9  16.4\n20 control    10  16  \n\n\nA função tribble também pode ser utilizada para colar dados obtidos da internet.\nExemplo 1:\n\ndat3 &lt;- tibble::tribble(\n  ~Estado, ~Cidade, ~Pop.2010, ~Pop.2022, ~Variacao,\n  \"MG\",            \"Serra.da.Saudade\", 815, 833,  \"2,20%\",\n  \"SP\",                       \"Bora\",    805,    907,  \"12,70%\",\n  \"GO\",                 \"Anhanguera\",   1.02,    924,  \"-9,40%\",\n  \"MT\",                 \"Araguainha\",  1.096,   1.01,  \"-7,80%\",\n  \"SP\",              \"Nova Castilho\",  1.125,  1.062,  \"-5,60%\",\n  \"MG\",            \"Cedro do Abaete\",   1.21,  1.081, \"-10,70%\",\n  \"RS\",             \"Andre da Rocha\",  1.216,  1.135,  \"-6,70%\",\n  \"TO\",         \"Oliveira de Fátima\",  1.037,  1.164,  \"12,20%\",\n  \"RS\",             \"União da Serra\",  1.487,   1.17, \"-21,30%\",\n  \"MG\", \"São Sebastião do Rio Preto\",  1.613,  1.259, \"-21,90%\",\n  \"RS\",             \"Coqueiro Baixo\",  1.528,   1.29, \"-15,60%\",\n  \"RS\",              \"Engenho Velho\",  1.527,  1.296, \"-15,10%\"\n  )\n\ndat3\n\n# A tibble: 12 × 5\n   Estado Cidade                     Pop.2010 Pop.2022 Variacao\n   &lt;chr&gt;  &lt;chr&gt;                         &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;   \n 1 MG     Serra.da.Saudade             815      833    2,20%   \n 2 SP     Bora                         805      907    12,70%  \n 3 GO     Anhanguera                     1.02   924    -9,40%  \n 4 MT     Araguainha                     1.10     1.01 -7,80%  \n 5 SP     Nova Castilho                  1.12     1.06 -5,60%  \n 6 MG     Cedro do Abaete                1.21     1.08 -10,70% \n 7 RS     Andre da Rocha                 1.22     1.14 -6,70%  \n 8 TO     Oliveira de Fátima             1.04     1.16 12,20%  \n 9 RS     União da Serra                 1.49     1.17 -21,30% \n10 MG     São Sebastião do Rio Preto     1.61     1.26 -21,90% \n11 RS     Coqueiro Baixo                 1.53     1.29 -15,60% \n12 RS     Engenho Velho                  1.53     1.30 -15,10% \n\n\n\nExemplo 2:\n\ndat4 &lt;- tibble::tribble(\n  ~Ranking,       ~País, ~`Produção.em.2022/23.(milhões.de.sacos.de.60.kg)`, ~Participação.total.no.mercado,\n  \"1\",\"Brasil\",664,\"38,1 %\",\n  \"2\",\"Vietnã\",311,\"17,8%\",\n  \"3\",\"Colômbia\",116,\"6,7%\",\n  \"4\",\"Indonésia\",97,\"5,6%\",\n  \"5\",\"Etiópia\",835,\"4,8%\",\n  \"Total\",\"Mundo\",170019,\"100%\")\n\ndat4\n\n# A tibble: 6 × 4\n  Ranking País      Produção.em.2022/23.(milhões.de.sac…¹ Participação.total.n…²\n  &lt;chr&gt;   &lt;chr&gt;                                     &lt;dbl&gt; &lt;chr&gt;                 \n1 1       Brasil                                      664 38,1 %                \n2 2       Vietnã                                      311 17,8%                 \n3 3       Colômbia                                    116 6,7%                  \n4 4       Indonésia                                    97 5,6%                  \n5 5       Etiópia                                     835 4,8%                  \n6 Total   Mundo                                    170019 100%                  \n# ℹ abbreviated names: ¹​`Produção.em.2022/23.(milhões.de.sacos.de.60.kg)`,\n#   ²​Participação.total.no.mercado\n\n\n\n\nTrabalhando com alguns dados\n\nImportando\nUtilizando a função “paste as tribble”, os dados presentes neste link (https://r4pde.net/temporal-fitting.html#entering-data - seção 10.4) serão importados:\n\npepper &lt;- \n  tribble(\n   ~t,  ~`1`,  ~`2`,  ~`3`,\n   0,  0.08, 0.001, 0.001,\n   7,  0.13,  0.01, 0.001,\n  14,  0.78,  0.09,  0.01,\n  21,  0.92,  0.25,  0.05,\n  28,  0.99,   0.8,  0.18,\n  35, 0.995,  0.98,  0.34,\n  42, 0.999,  0.99,  0.48,\n  49, 0.999, 0.999,  0.74\n  )\n\npepper\n\n# A tibble: 8 × 4\n      t   `1`   `2`   `3`\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1     0 0.08  0.001 0.001\n2     7 0.13  0.01  0.001\n3    14 0.78  0.09  0.01 \n4    21 0.92  0.25  0.05 \n5    28 0.99  0.8   0.18 \n6    35 0.995 0.98  0.34 \n7    42 0.999 0.99  0.48 \n8    49 0.999 0.999 0.74 \n\n\n\n\nConvertendo\nVisualizando os dados importados acima, é possível notar que eles estão no formato largo. Logo, será preciso transformá-los para o formato longo. Para isso, será utilizada a função pivot_longer (tidyr). Indicamos quais colunas serão transformadas para o formato longo e atribuímos nomes às novas colunas:\n\npepper2 &lt;- pepper %&gt;% \n  pivot_longer(2:4,\n               names_to = \"epidemic\",\n               values_to = \"inc\")\n\npepper2\n\n# A tibble: 24 × 3\n       t epidemic   inc\n   &lt;dbl&gt; &lt;chr&gt;    &lt;dbl&gt;\n 1     0 1        0.08 \n 2     0 2        0.001\n 3     0 3        0.001\n 4     7 1        0.13 \n 5     7 2        0.01 \n 6     7 3        0.001\n 7    14 1        0.78 \n 8    14 2        0.09 \n 9    14 3        0.01 \n10    21 1        0.92 \n# ℹ 14 more rows\n\n\n\n\nConstruindo gráfico\nEm seguida, com pacote ggplot2, será feito um gráfico de pontos e linhas a partir dos dados carregados:\n\npepper2 %&gt;% \n  ggplot(aes(t, inc, color = epidemic))+\n  geom_point()+\n  geom_line()+\n  annotate(geom = \"text\",\n           x = 12,\n           y = 0.75,\n           label = \"1\")+\n  annotate(geom = \"text\",\n           x = 22,\n           y = 0.50,\n           label = \"2\")+\n   annotate(geom = \"text\",\n           x = 32,\n           y = 0.35,\n           label = \"3\")+\n  theme_grey()+\n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\n\nlibrary(gsheet)\ndata &lt;- gsheet::gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1aID5Dh6PlBVCKzU1j7k-WA6zuWQWE2NhtWEgdJtt5iA/edit#gid=921203844\")\n\n\ndata %&gt;%\n  group_by(trat) %&gt;%\n  ggplot(aes(trat, comp))+\n  geom_jitter(width = 0.1)\n\n\n\n\n\n\n\n\n\ndata %&gt;%\n  group_by(trat) %&gt;%\n  summarise(mean_comp = mean(comp),\n            sd_comp = sd(comp)) %&gt;%\n  ggplot(aes(trat, mean_comp))+\n  #geom_col(fill = \"steelblue\", width = 0.5)+\n  geom_point(size = 2)+\n  ylim (5,20)+\n  geom_errorbar(aes(ymin = mean_comp - sd_comp,\n                    ymax = mean_comp + sd_comp),\n                width = 0.2)+\n  annotate(geom = \"text\",\n           x = 1,\n           y = 18,\n           label = \"*\", size =5)+\n  labs(\n    y = \"Mean Comp\")",
    "crumbs": [
      "Home",
      "Aula 04",
      "Uso do datapasta"
    ]
  },
  {
    "objectID": "Aula 5.html",
    "href": "Aula 5.html",
    "title": "Aula 05 - Atividade prática",
    "section": "",
    "text": "Nesta aula, serão analisados e interpretados os valores das notas das duas primeiras atividades avaliativas da disciplina FIP 606.",
    "crumbs": [
      "Home",
      "Aula 05",
      "Atividade prática"
    ]
  },
  {
    "objectID": "Aula 5.html#carregando-os-pacotes",
    "href": "Aula 5.html#carregando-os-pacotes",
    "title": "Aula 05 - Atividade prática",
    "section": "Carregando os pacotes",
    "text": "Carregando os pacotes\nInicialmente, serão carregados os pacotes necessários para o desenvolvimento das análises.\n\nlibrary(gsheet)\nlibrary(tidyverse)\nlibrary(ggthemes)\nlibrary(patchwork)",
    "crumbs": [
      "Home",
      "Aula 05",
      "Atividade prática"
    ]
  },
  {
    "objectID": "Aula 5.html#obtenção-e-visualização-dos-dados",
    "href": "Aula 5.html#obtenção-e-visualização-dos-dados",
    "title": "Aula 05 - Atividade prática",
    "section": "Obtenção e visualização dos dados",
    "text": "Obtenção e visualização dos dados\nOs dados utilizados foram disponibilizados em uma planilha online e serão importados utilizando a função gsheet2tbl (gsheet):\n\ndados &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=1092065531\")\n\n\nPara uma rápida visualização dos dados importados, será aplicada a função glimpse (dplyr):\n\nglimpse(dados)\n\nRows: 44\nColumns: 3\n$ prova  &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …\n$ pontos &lt;dbl&gt; 10, 13, 12, 6, 14, 12, 14, 8, 14, 10, 10, 13, 9, 14, 9, 14, 12,…\n$ nota   &lt;dbl&gt; 71.40, 92.90, 85.70, 42.90, 100.00, 85.70, 100.00, 57.10, 100.0…\n\n\n\nAo avaliar o arquivo gerado acima, é possível notar que a coluna “prova” está definida como númerica (“dbl”), portanto será necessário transformá-la para um novo tipo de dado (fator - “fct”), a fim de viabilizar o decorrer da atividade.\nPara isso, será utilizada a função as.factor:\n\ndados$prova &lt;- as.factor(dados$prova)\nglimpse(dados)\n\nRows: 44\nColumns: 3\n$ prova  &lt;fct&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …\n$ pontos &lt;dbl&gt; 10, 13, 12, 6, 14, 12, 14, 8, 14, 10, 10, 13, 9, 14, 9, 14, 12,…\n$ nota   &lt;dbl&gt; 71.40, 92.90, 85.70, 42.90, 100.00, 85.70, 100.00, 57.10, 100.0…",
    "crumbs": [
      "Home",
      "Aula 05",
      "Atividade prática"
    ]
  },
  {
    "objectID": "Aula 5.html#sumário-estatístico",
    "href": "Aula 5.html#sumário-estatístico",
    "title": "Aula 05 - Atividade prática",
    "section": "Sumário estatístico",
    "text": "Sumário estatístico\nPara um breve sumário estatístico dos valores das avaliações, será utilizada a coluna “nota” (normalizada previamente). Será feito o agrupamento dos valores de acordo com a “prova”, utilizando a função group_by. Em seguida, será aplicada a função summarise para a obtenção de algumas estatísticas descritivas. Ambas as funções pertencem ao pacote dplyr.\n\ndados %&gt;% group_by(prova) %&gt;%\n  summarise(n = n(),\n            mín = min(nota),\n            máx = max(nota),\n            mean = mean(nota),\n            sd = sd(nota),\n            median = median(nota))\n\n# A tibble: 2 × 7\n  prova     n   mín   máx  mean    sd median\n  &lt;fct&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n1 1        22  42.9   100  79.5  19.0   85.7\n2 2        22  43.8   100  79.3  19.7   84.4",
    "crumbs": [
      "Home",
      "Aula 05",
      "Atividade prática"
    ]
  },
  {
    "objectID": "Aula 5.html#visualização-gráfica-dos-valores-de-nota",
    "href": "Aula 5.html#visualização-gráfica-dos-valores-de-nota",
    "title": "Aula 05 - Atividade prática",
    "section": "Visualização gráfica dos valores de nota",
    "text": "Visualização gráfica dos valores de nota\n\nHistograma geral\nInicialmente, será feito um gráfico do tipo histograma para conhecer a distribuição geral das notas. Será utilizada a função geom_histogram (ggplot2).\n\ndados %&gt;%\n  ggplot(aes(nota))+\n  geom_histogram(binwidth = 3)+\n  labs(x = \"Nota\",\n       y = \"Frequência\")+\n  lims(x = c(NA,100),\n       y = c(0,NA))+\n  theme_bw()\n\n\n\n\n\n\n\n\n\n\nBoxplot por avaliação\nPara visualizar a distribuição dos valores das notas em função da prova, será construído um gráfico do tipo boxplot (geom_boxplot) acrescido de pontos (geom_jitter), representando as observações individuais.\n\ndados %&gt;%\n  ggplot(aes(prova, nota))+\n  geom_boxplot(width = 0.4)+\n  geom_jitter(width = 0.2, alpha = 0.5)+\n  labs(x = \"Avaliação\",\n       y = \"Nota\")+\n  lims(y=c(30,110))+\n  theme_bw()\n\n\n\n\n\n\n\n\n\n\nHistograma por avaliação\nPrimeiro, será necessário criar novos dataframes em função da avaliação (1 ou 2).\nPara isso, as colunas “prova” e “nota” serão selecionadas (select, pacote dplyr) e em seguida, o filtro (filter, pacote dplyr) será aplicado na coluna “prova”:\n\ndados1 &lt;-    \n  dados %&gt;% select(prova, nota) %&gt;%   \n  filter(prova == \"1\")  \n\n\ndados2 &lt;-   \n  dados %&gt;% select(prova, nota) %&gt;%    \n  filter(prova == \"2\")\n\n\nHistograma da avaliação 1:\n\nm1 &lt;- mean(dados1$nota)\n\ng1 &lt;- dados1 %&gt;%\n  ggplot(aes(nota))+\n  geom_histogram(color = \"white\", bins =5, fill = \"tomato1\", alpha = 0.9)+\n  geom_vline(xintercept = c(m1), alpha = 0.9, linetype = \"dashed\", linewidth = 0.9, colour = \"coral4\")+\n  annotate(\"text\", x = 70, y = 10, label = \"Média\")+\n  labs(x = \"Nota\",\n       y = \"Frequência\")+\n  ylim(c(0, 15))+\n  coord_fixed(ratio = 7)+\n  scale_x_continuous(breaks = seq(20,105,10))+\n  ggtitle(\"Prova 1\")+\n  theme_classic()+\n  theme(plot.title = element_text(vjust = 3))\n\ng1\n\n\n\n\n\n\n\n\n\n\nHistograma da avaliação 2:\n\nm2 &lt;- mean(dados2$nota)\n\ng2 &lt;- dados2 %&gt;%\n  ggplot(aes(nota))+\n  geom_histogram(color = \"white\", bins =5, fill = \"navy\", alpha = 0.9)+\n  geom_vline(xintercept = c(m2), alpha = 0.9, linetype = \"dashed\", linewidth = 0.9, colour = \"skyblue2\")+\n  annotate(\"text\", x = 70, y = 10, label = \"Média\")+\n  labs(x = \"Nota\",\n       y = \"Frequência\")+\n  ylim(c(0, 15))+\n  ggtitle(\"Prova 2\")+\n  coord_fixed(ratio = 7)+\n  scale_x_continuous(breaks = seq(20,105,10))+\n  theme_classic()+\n  theme(plot.title = element_text(vjust = 3))\n\ng2\n\n\n\n\n\n\n\n\n\n\nHistogramas combinados:\nPara combinar os histogramas individuais em uma única imagem, será aplicado o pacote patchwork:\n\n(g1+g2)",
    "crumbs": [
      "Home",
      "Aula 05",
      "Atividade prática"
    ]
  },
  {
    "objectID": "Aula 5.html#interpretação",
    "href": "Aula 5.html#interpretação",
    "title": "Aula 05 - Atividade prática",
    "section": "Interpretação",
    "text": "Interpretação\nEm ambas as atividades, foram avaliadas 22 amostras (provas). Os gráficos demonstram que as notas mais frequentes estiveram entre aproximadamente 80 e 100, nas duas avaliações. Na primeira avaliação, as notas variaram de 42.90 a 100, com valor médio próximo a 79.5 (± 19) e valor mediano de 85.7. Na segunda avaliação, as notas variaram de 43.75 a 100, com média próxima de 79.2 (± 19.7) e mediana de 84.3. Comparando os valores médios das duas avaliações, os estudantes apresentaram desempenho similar.\n_____",
    "crumbs": [
      "Home",
      "Aula 05",
      "Atividade prática"
    ]
  },
  {
    "objectID": "Aula 6.2.html",
    "href": "Aula 6.2.html",
    "title": "Aula 06 - Estatística inferencial - Análise de variância",
    "section": "",
    "text": "A análise de variância é adotada quando desejamos comparar três ou mais variáveis quantitativas independentes e que possuem distribuição normal.\n\n\n\n\n\nOs dados serão importados de uma planilha excel e apresentam a taxa de crescimento micelial de 5 espécies de Fusarium.\n\nmicelial &lt;- readxl::read_excel(\"dados-diversos.xlsx\",\n                               sheet = \"micelial\")\nglimpse(micelial)\n\nRows: 42\nColumns: 3\n$ especie &lt;chr&gt; \"Fasi\", \"Fasi\", \"Fasi\", \"Fasi\", \"Fasi\", \"Fasi\", \"Faus\", \"Faus\"…\n$ rep     &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 7, 8, 9,…\n$ tcm     &lt;dbl&gt; 1.50, 1.59, 1.52, 1.52, 1.24, 1.29, 1.52, 1.25, 1.27, 0.88, 1.…\n\n#tcm = taxa de crescimento micelial\n\nPara visualização dos dados, será construído um simples gráfico de pontos (geom_jitter) ao invés de boxplots (geom_boxplot).\nComo cada tratamento possui em torno de 10 respostas (pontos), esse tipo de gráfico já é suficiente para visualizar a distribuição dos valores.\n\nmicelial %&gt;% \n  ggplot(aes(especie, tcm))+\n  geom_jitter(width = 0.1)\n\n\n\n\n\n\n\n\n\n\n\n\n\nAntes de realizar a ANOVA, é preciso ajustar um modelo linear (lm). Para isso, será utilizada a função lm. Nessa função, os modelos são construídos simbolicamente: com a variável dependente, seguida de um ~, e a variável independente. Em seguida, informamos no argumento data qual o conjunto de dados (data frame) que contém as variáveis do modelo.\nEssa fórmula será atribuída a um objeto.\n\nm1 &lt;- lm(tcm ~ especie, data = micelial)\n\n\n\n\nUma vez construído o modelo, é necessário determinar se os dados satisfazem as premissas para proceder a análise de variância.\n\n\n\n\nhist(m1$residuals)\n\n\n\n\n\n\n\nshapiro.test(m1$residuals)\n\n\n    Shapiro-Wilk normality test\n\ndata:  m1$residuals\nW = 0.95101, p-value = 0.07022\n\n\nTanto visualmente, quanto estatisticamente, os resíduos possuem distribuição normal.\n\n\n\n\nbartlett.test(tcm ~ especie, data = micelial)\n\n\n    Bartlett test of homogeneity of variances\n\ndata:  tcm by especie\nBartlett's K-squared = 3.1169, df = 4, p-value = 0.5385\n\n\nO teste de Barlett indica que o conjunto de dados possui homogeneidade de variância.\n\n\n\nO modelo criado é utilizado dentro da função anova:\n\nanova(m1)\n\nAnalysis of Variance Table\n\nResponse: tcm\n          Df  Sum Sq Mean Sq F value Pr(&gt;F)\nespecie    4 0.46917 0.11729   1.983 0.1173\nResiduals 37 2.18853 0.05915               \n\n\nCom esse conjunto de dados, é possível concluir que as taxas de crescimento micelial das espécies de Fusarium não diferem significativamente entre si (F = 0.1173 &gt; ⍺ = 0.05).\n\nA função summary será aplicada para produzir um sumário dos resultados do modelo ajustado.\n\nsummary(m1)\n\n\nCall:\nlm(formula = tcm ~ especie, data = micelial)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.45933 -0.20028  0.06067  0.14017  0.36167 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  1.44333    0.09929  14.537   &lt;2e-16 ***\nespecieFaus -0.28500    0.14042  -2.030   0.0496 *  \nespecieFcor -0.28400    0.11748  -2.417   0.0207 *  \nespecieFgra -0.30000    0.14042  -2.137   0.0393 *  \nespecieFmer -0.14222    0.12818  -1.110   0.2744    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.2432 on 37 degrees of freedom\nMultiple R-squared:  0.1765,    Adjusted R-squared:  0.08751 \nF-statistic: 1.983 on 4 and 37 DF,  p-value: 0.1173\n\n\nO intercepto indica a média do primeiro nível (Fasi = 1.43) e em seguida são apresentados as diferenças para cada nível em relação ao primeiro. Por exemplo, a média da taxa de crescimento micelial do nível Faus será 1.15 (1.43 - 0.28).\n\n\nO intercepto pode ser removido incluindo -1 na construção do modelo. Dessa forma, serão apresentados os valores de média de cada nível:\n\nm2 &lt;- lm(tcm ~ especie - 1, data = micelial)\nsummary(m2)\n\n\nCall:\nlm(formula = tcm ~ especie - 1, data = micelial)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.45933 -0.20028  0.06067  0.14017  0.36167 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \nespecieFasi  1.44333    0.09929   14.54  &lt; 2e-16 ***\nespecieFaus  1.15833    0.09929   11.67 5.85e-14 ***\nespecieFcor  1.15933    0.06280   18.46  &lt; 2e-16 ***\nespecieFgra  1.14333    0.09929   11.52 8.56e-14 ***\nespecieFmer  1.30111    0.08107   16.05  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.2432 on 37 degrees of freedom\nMultiple R-squared:  0.9668,    Adjusted R-squared:  0.9623 \nF-statistic: 215.7 on 5 and 37 DF,  p-value: &lt; 2.2e-16\n\n\n\n\n\n\nUm conjunto de dados similar ao anterior será importado de uma planilha online. Nesse novo conjunto os dados foram alterados para apresentarem diferença estatística e avançarmos na análise inferencial.\n\n\n\n\n\nmicelial2 &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=959387827\")\n\n#tcm = taxa de crescimento micelial\n\n\nmicelial2 %&gt;% \n  ggplot(aes(especie, tcm))+\n  geom_jitter(width = 0.1)\n\n\n\n\n\n\n\n\n\n\n\nm3 &lt;- lm(tcm ~ especie, data = micelial2)\n\n\n\n\n\n\n\n\nhist(m3$residuals)\n\n\n\n\n\n\n\nshapiro.test(m3$residuals)\n\n\n    Shapiro-Wilk normality test\n\ndata:  m3$residuals\nW = 0.9821, p-value = 0.8782\n\n\nTanto visualmente, quanto estatisticamente, os resíduos possuem distribuição normal.\n\n\n\n\nbartlett.test(tcm ~ especie, data = micelial2)\n\n\n    Bartlett test of homogeneity of variances\n\ndata:  tcm by especie\nBartlett's K-squared = 4.4367, df = 4, p-value = 0.3501\n\n\nO teste de Barlett indica que o conjunto de dados possui homogeneidade de variância.\n\n\n\n\n\nanova(m3)\n\nAnalysis of Variance Table\n\nResponse: tcm\n          Df  Sum Sq Mean Sq F value    Pr(&gt;F)    \nespecie    4 1.46958 0.36739  19.629 2.028e-07 ***\nResiduals 25 0.46792 0.01872                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nsummary(m3)\n\n\nCall:\nlm(formula = tcm ~ especie, data = micelial2)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.23667 -0.09667  0.01583  0.08833  0.28333 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  1.57167    0.05585  28.140  &lt; 2e-16 ***\nespecieFaus -0.33500    0.07899  -4.241 0.000266 ***\nespecieFcor -0.25000    0.07899  -3.165 0.004047 ** \nespecieFgra -0.66000    0.07899  -8.356 1.05e-08 ***\nespecieFmer -0.14500    0.07899  -1.836 0.078317 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1368 on 25 degrees of freedom\nMultiple R-squared:  0.7585,    Adjusted R-squared:  0.7199 \nF-statistic: 19.63 on 4 and 25 DF,  p-value: 2.028e-07\n\n\nCom esse novo conjunto de dados, conclui-se que as taxas de crescimento micelial das espécies de Fusarium diferem significativamente entre si (F = 2.2 * 10-7 &gt; ⍺ = 0.05). O próximo passo será adotar um teste de comparação de médias para conhecer como as espécies se agrupam quanto as taxas de crescimento.\n\n\n\nPara realizar o teste de Tukey, utilizaremos os pacotes emmeans, multcomp e multcompview.\nInicialmente, a função emmeans (pacote emmeans) será aplicada para estimar as médias de um fator específico em um modelo linear. O resultado será atribuído a um objeto.\n\nmedias1 &lt;- emmeans(m3, ~ especie)\n\nPara comparação de médias - Teste de Tukey - será utilizada a função cld (pacote multcomp).\n\ncld(medias1)\n\n especie emmean     SE df lower.CL upper.CL .group\n Fgra     0.912 0.0559 25    0.797     1.03  1    \n Faus     1.237 0.0559 25    1.122     1.35   2   \n Fcor     1.322 0.0559 25    1.207     1.44   2   \n Fmer     1.427 0.0559 25    1.312     1.54   23  \n Fasi     1.572 0.0559 25    1.457     1.69    3  \n\nConfidence level used: 0.95 \nP value adjustment: tukey method for comparing a family of 5 estimates \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\n\nCom o resultado obtido a um nível de significância de 5%, interpretamos que Fgra possui a menor taxa de crescimento, em comparação as demais espécies. Faus, Fcor e Fmer possuem taxa de crescimento estatisticamente similar. Já Fmer e Fasi são estatisticamente similares e possuem a maior taxa de crescimento.\n\n\n\n\n\n\nplot(simulateResiduals(m3))\n\n\n\n\n\n\n\n\n\n\n\n\nlibrary(performance)\ncheck_normality(m3)\n\nOK: residuals appear as normally distributed (p = 0.878).\n\ncheck_heteroscedasticity(m3)\n\nOK: Error variance appears to be homoscedastic (p = 0.880).\n\ncheck_model(m3)",
    "crumbs": [
      "Home",
      "Aula 06",
      "Estatística inferencial - Análise de variância"
    ]
  },
  {
    "objectID": "Aula 6.2.html#análise-de-variância-anova",
    "href": "Aula 6.2.html#análise-de-variância-anova",
    "title": "Aula 06 - Estatística inferencial - Análise de variância",
    "section": "",
    "text": "A análise de variância é adotada quando desejamos comparar três ou mais variáveis quantitativas independentes e que possuem distribuição normal.\n\n\n\n\n\nOs dados serão importados de uma planilha excel e apresentam a taxa de crescimento micelial de 5 espécies de Fusarium.\n\nmicelial &lt;- readxl::read_excel(\"dados-diversos.xlsx\",\n                               sheet = \"micelial\")\nglimpse(micelial)\n\nRows: 42\nColumns: 3\n$ especie &lt;chr&gt; \"Fasi\", \"Fasi\", \"Fasi\", \"Fasi\", \"Fasi\", \"Fasi\", \"Faus\", \"Faus\"…\n$ rep     &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 7, 8, 9,…\n$ tcm     &lt;dbl&gt; 1.50, 1.59, 1.52, 1.52, 1.24, 1.29, 1.52, 1.25, 1.27, 0.88, 1.…\n\n#tcm = taxa de crescimento micelial\n\nPara visualização dos dados, será construído um simples gráfico de pontos (geom_jitter) ao invés de boxplots (geom_boxplot).\nComo cada tratamento possui em torno de 10 respostas (pontos), esse tipo de gráfico já é suficiente para visualizar a distribuição dos valores.\n\nmicelial %&gt;% \n  ggplot(aes(especie, tcm))+\n  geom_jitter(width = 0.1)\n\n\n\n\n\n\n\n\n\n\n\n\n\nAntes de realizar a ANOVA, é preciso ajustar um modelo linear (lm). Para isso, será utilizada a função lm. Nessa função, os modelos são construídos simbolicamente: com a variável dependente, seguida de um ~, e a variável independente. Em seguida, informamos no argumento data qual o conjunto de dados (data frame) que contém as variáveis do modelo.\nEssa fórmula será atribuída a um objeto.\n\nm1 &lt;- lm(tcm ~ especie, data = micelial)\n\n\n\n\nUma vez construído o modelo, é necessário determinar se os dados satisfazem as premissas para proceder a análise de variância.\n\n\n\n\nhist(m1$residuals)\n\n\n\n\n\n\n\nshapiro.test(m1$residuals)\n\n\n    Shapiro-Wilk normality test\n\ndata:  m1$residuals\nW = 0.95101, p-value = 0.07022\n\n\nTanto visualmente, quanto estatisticamente, os resíduos possuem distribuição normal.\n\n\n\n\nbartlett.test(tcm ~ especie, data = micelial)\n\n\n    Bartlett test of homogeneity of variances\n\ndata:  tcm by especie\nBartlett's K-squared = 3.1169, df = 4, p-value = 0.5385\n\n\nO teste de Barlett indica que o conjunto de dados possui homogeneidade de variância.\n\n\n\nO modelo criado é utilizado dentro da função anova:\n\nanova(m1)\n\nAnalysis of Variance Table\n\nResponse: tcm\n          Df  Sum Sq Mean Sq F value Pr(&gt;F)\nespecie    4 0.46917 0.11729   1.983 0.1173\nResiduals 37 2.18853 0.05915               \n\n\nCom esse conjunto de dados, é possível concluir que as taxas de crescimento micelial das espécies de Fusarium não diferem significativamente entre si (F = 0.1173 &gt; ⍺ = 0.05).\n\nA função summary será aplicada para produzir um sumário dos resultados do modelo ajustado.\n\nsummary(m1)\n\n\nCall:\nlm(formula = tcm ~ especie, data = micelial)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.45933 -0.20028  0.06067  0.14017  0.36167 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  1.44333    0.09929  14.537   &lt;2e-16 ***\nespecieFaus -0.28500    0.14042  -2.030   0.0496 *  \nespecieFcor -0.28400    0.11748  -2.417   0.0207 *  \nespecieFgra -0.30000    0.14042  -2.137   0.0393 *  \nespecieFmer -0.14222    0.12818  -1.110   0.2744    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.2432 on 37 degrees of freedom\nMultiple R-squared:  0.1765,    Adjusted R-squared:  0.08751 \nF-statistic: 1.983 on 4 and 37 DF,  p-value: 0.1173\n\n\nO intercepto indica a média do primeiro nível (Fasi = 1.43) e em seguida são apresentados as diferenças para cada nível em relação ao primeiro. Por exemplo, a média da taxa de crescimento micelial do nível Faus será 1.15 (1.43 - 0.28).\n\n\nO intercepto pode ser removido incluindo -1 na construção do modelo. Dessa forma, serão apresentados os valores de média de cada nível:\n\nm2 &lt;- lm(tcm ~ especie - 1, data = micelial)\nsummary(m2)\n\n\nCall:\nlm(formula = tcm ~ especie - 1, data = micelial)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.45933 -0.20028  0.06067  0.14017  0.36167 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \nespecieFasi  1.44333    0.09929   14.54  &lt; 2e-16 ***\nespecieFaus  1.15833    0.09929   11.67 5.85e-14 ***\nespecieFcor  1.15933    0.06280   18.46  &lt; 2e-16 ***\nespecieFgra  1.14333    0.09929   11.52 8.56e-14 ***\nespecieFmer  1.30111    0.08107   16.05  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.2432 on 37 degrees of freedom\nMultiple R-squared:  0.9668,    Adjusted R-squared:  0.9623 \nF-statistic: 215.7 on 5 and 37 DF,  p-value: &lt; 2.2e-16\n\n\n\n\n\n\nUm conjunto de dados similar ao anterior será importado de uma planilha online. Nesse novo conjunto os dados foram alterados para apresentarem diferença estatística e avançarmos na análise inferencial.\n\n\n\n\n\nmicelial2 &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=959387827\")\n\n#tcm = taxa de crescimento micelial\n\n\nmicelial2 %&gt;% \n  ggplot(aes(especie, tcm))+\n  geom_jitter(width = 0.1)\n\n\n\n\n\n\n\n\n\n\n\nm3 &lt;- lm(tcm ~ especie, data = micelial2)\n\n\n\n\n\n\n\n\nhist(m3$residuals)\n\n\n\n\n\n\n\nshapiro.test(m3$residuals)\n\n\n    Shapiro-Wilk normality test\n\ndata:  m3$residuals\nW = 0.9821, p-value = 0.8782\n\n\nTanto visualmente, quanto estatisticamente, os resíduos possuem distribuição normal.\n\n\n\n\nbartlett.test(tcm ~ especie, data = micelial2)\n\n\n    Bartlett test of homogeneity of variances\n\ndata:  tcm by especie\nBartlett's K-squared = 4.4367, df = 4, p-value = 0.3501\n\n\nO teste de Barlett indica que o conjunto de dados possui homogeneidade de variância.\n\n\n\n\n\nanova(m3)\n\nAnalysis of Variance Table\n\nResponse: tcm\n          Df  Sum Sq Mean Sq F value    Pr(&gt;F)    \nespecie    4 1.46958 0.36739  19.629 2.028e-07 ***\nResiduals 25 0.46792 0.01872                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nsummary(m3)\n\n\nCall:\nlm(formula = tcm ~ especie, data = micelial2)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.23667 -0.09667  0.01583  0.08833  0.28333 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  1.57167    0.05585  28.140  &lt; 2e-16 ***\nespecieFaus -0.33500    0.07899  -4.241 0.000266 ***\nespecieFcor -0.25000    0.07899  -3.165 0.004047 ** \nespecieFgra -0.66000    0.07899  -8.356 1.05e-08 ***\nespecieFmer -0.14500    0.07899  -1.836 0.078317 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1368 on 25 degrees of freedom\nMultiple R-squared:  0.7585,    Adjusted R-squared:  0.7199 \nF-statistic: 19.63 on 4 and 25 DF,  p-value: 2.028e-07\n\n\nCom esse novo conjunto de dados, conclui-se que as taxas de crescimento micelial das espécies de Fusarium diferem significativamente entre si (F = 2.2 * 10-7 &gt; ⍺ = 0.05). O próximo passo será adotar um teste de comparação de médias para conhecer como as espécies se agrupam quanto as taxas de crescimento.\n\n\n\nPara realizar o teste de Tukey, utilizaremos os pacotes emmeans, multcomp e multcompview.\nInicialmente, a função emmeans (pacote emmeans) será aplicada para estimar as médias de um fator específico em um modelo linear. O resultado será atribuído a um objeto.\n\nmedias1 &lt;- emmeans(m3, ~ especie)\n\nPara comparação de médias - Teste de Tukey - será utilizada a função cld (pacote multcomp).\n\ncld(medias1)\n\n especie emmean     SE df lower.CL upper.CL .group\n Fgra     0.912 0.0559 25    0.797     1.03  1    \n Faus     1.237 0.0559 25    1.122     1.35   2   \n Fcor     1.322 0.0559 25    1.207     1.44   2   \n Fmer     1.427 0.0559 25    1.312     1.54   23  \n Fasi     1.572 0.0559 25    1.457     1.69    3  \n\nConfidence level used: 0.95 \nP value adjustment: tukey method for comparing a family of 5 estimates \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\n\nCom o resultado obtido a um nível de significância de 5%, interpretamos que Fgra possui a menor taxa de crescimento, em comparação as demais espécies. Faus, Fcor e Fmer possuem taxa de crescimento estatisticamente similar. Já Fmer e Fasi são estatisticamente similares e possuem a maior taxa de crescimento.\n\n\n\n\n\n\nplot(simulateResiduals(m3))\n\n\n\n\n\n\n\n\n\n\n\n\nlibrary(performance)\ncheck_normality(m3)\n\nOK: residuals appear as normally distributed (p = 0.878).\n\ncheck_heteroscedasticity(m3)\n\nOK: Error variance appears to be homoscedastic (p = 0.880).\n\ncheck_model(m3)",
    "crumbs": [
      "Home",
      "Aula 06",
      "Estatística inferencial - Análise de variância"
    ]
  },
  {
    "objectID": "Aula 7.2.html",
    "href": "Aula 7.2.html",
    "title": "Aula 07 - Estatística inferencial - Alternativas de análise",
    "section": "",
    "text": "Diante dos resultados obtidos, conclui-se que o conjunto de dados não atende as pressuposições da ANOVA, logo é necessário definir uma estratégia para prosseguir na análise dos dados. É possível realizar transformações da variável resposta, adotar um teste não-paramétrico (por exemplo, teste de Kruskal-Wallis), ou utilizar um modelo linear generalizado (Generalized Linear Model - GLM). A seguir, são apresentados exemplos de como se adotar cada estratégia:\n\n\nOs dados serão transformados com a função sqrt e a coluna da variável resposta será substituída com os novos valores:\n\ninseticida &lt;- inseticida %&gt;% \n  mutate(count2 = sqrt(count))\n\nglimpse(inseticida)\n\nRows: 72\nColumns: 3\n$ count  &lt;dbl&gt; 10, 7, 20, 14, 14, 12, 10, 23, 17, 20, 14, 13, 11, 17, 21, 11, …\n$ spray  &lt;fct&gt; A, A, A, A, A, A, A, A, A, A, A, A, B, B, B, B, B, B, B, B, B, …\n$ count2 &lt;dbl&gt; 3.162278, 2.645751, 4.472136, 3.741657, 3.741657, 3.464102, 3.1…\n\n\n\n\n\ninseticida %&gt;%\n  ggplot(aes(spray, count2))+\n  geom_boxplot(width = 0.5)\n\n\n\n\n\n\n\n\nVisualmente, é possível dizer que, possivelmente, os dados transformados agora possuem normalidade e homocedasticidade, pois os valores de mediana tendem a se encontrar nos centros da caixas e essas tem tamanho mais ou menos similar entre si.\n\n\n\n\nm2 &lt;- lm(count2 ~ spray,\n         data = inseticida)\n\nsummary(m2)\n\n\nCall:\nlm(formula = count2 ~ spray, data = inseticida)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1.24486 -0.39970 -0.01902  0.42661  1.40089 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   3.7607     0.1814  20.733  &lt; 2e-16 ***\nsprayB        0.1160     0.2565   0.452    0.653    \nsprayC       -2.5158     0.2565  -9.807 1.64e-14 ***\nsprayD       -1.5963     0.2565  -6.223 3.80e-08 ***\nsprayE       -1.9512     0.2565  -7.606 1.34e-10 ***\nsprayF        0.2579     0.2565   1.006    0.318    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.6283 on 66 degrees of freedom\nMultiple R-squared:  0.7724,    Adjusted R-squared:  0.7552 \nF-statistic:  44.8 on 5 and 66 DF,  p-value: &lt; 2.2e-16\n\n\n\n\n\n\nanova (m2)\n\nAnalysis of Variance Table\n\nResponse: count2\n          Df Sum Sq Mean Sq F value    Pr(&gt;F)    \nspray      5 88.438 17.6876  44.799 &lt; 2.2e-16 ***\nResiduals 66 26.058  0.3948                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nMesmo após transformação, os dados continuem apresentando diferença significativa, ou seja, há pelo menos uma média que difere das demais.\n\n\n\n\nhist(m2$residuals)\n\n\n\n\n\n\n\n\n\nqqnorm(m2$residuals)\nqqline(m2$residuals)\n\n\n\n\n\n\n\n\n\nshapiro.test(m2$residuals)\n\n\n    Shapiro-Wilk normality test\n\ndata:  m2$residuals\nW = 0.98721, p-value = 0.6814\n\n\nVisual e estatisticamente, conclui-se que os resíduos do conjunto de dados transformados possuem distribuição normal.\n\n\n\n\nbartlett.test(count2 ~ spray,\n              data = inseticida)\n\n\n    Bartlett test of homogeneity of variances\n\ndata:  count2 by spray\nBartlett's K-squared = 3.7525, df = 5, p-value = 0.5856\n\n\nApós a transformação, é possível dizer que há homogeneidade de variâncias entre os grupos.\n\n\n\n\ncheck_normality(m2)\n\nOK: residuals appear as normally distributed (p = 0.681).\n\ncheck_heteroscedasticity(m2)\n\nOK: Error variance appears to be homoscedastic (p = 0.854).\n\n\n\n\n\n\nplot(simulateResiduals(m2))\n\n\n\n\n\n\n\n\nApós os vários testes realizados, temos confiança que os dados transformados possuem distribuição normal e homogeneidade das variâncias. Logo, é possível realizar comparações de médias.\n\n\n\n\n\n\nApenas à título de curiosidade, será feita uma comparação de médias com base nos valores originais. O que não é correto, uma vez que esses não satisfazem as pressuposições da ANOVA.\nPara isso, a função emmeans, indicando o modelo (m1) e os tratamentos (spray), será atribuída a um objeto.\n\nm1_medias &lt;- emmeans(m1, ~ spray)\nplot(m1_medias)\n\n\n\n\n\n\n\n\nO gráfico gerado mostra que para essa situação, os tratamentos tendem a formar dois grupos de eficiência.\n\nmultcomp::cld(m1_medias)\n\n spray emmean   SE df lower.CL upper.CL .group\n C       2.08 1.13 66   -0.177     4.34  1    \n E       3.50 1.13 66    1.240     5.76  1    \n D       4.92 1.13 66    2.656     7.18  1    \n A      14.50 1.13 66   12.240    16.76   2   \n B      15.33 1.13 66   13.073    17.59   2   \n F      16.67 1.13 66   14.406    18.93   2   \n\nConfidence level used: 0.95 \nP value adjustment: tukey method for comparing a family of 6 estimates \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\n\nO que é comprovado estatisticamente pela comparação de médias, utilizando o teste de Tukey.\n\n\n\nPara os dados transformados, serão aplicados os mesmos passos descritos acima:\n\nm2_medias &lt;- emmeans(m2, ~ spray)\nplot(m2_medias)\n\n\n\n\n\n\n\n\nVisualmente, é possível dizer que os inseticidas formam três grupos distintos.\n\nmultcomp::cld(m2_medias)\n\n spray emmean    SE df lower.CL upper.CL .group\n C       1.24 0.181 66    0.883     1.61  1    \n E       1.81 0.181 66    1.447     2.17  12   \n D       2.16 0.181 66    1.802     2.53   2   \n A       3.76 0.181 66    3.399     4.12    3  \n B       3.88 0.181 66    3.514     4.24    3  \n F       4.02 0.181 66    3.656     4.38    3  \n\nConfidence level used: 0.95 \nP value adjustment: tukey method for comparing a family of 6 estimates \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\n\nCom a média transformada, o teste de Tukey agrupa os tratamentos em 3 grupos distintos, logo houve melhor discriminação. Com isso, concluímos que, em comparação aos demais, o inseticida C foi o mais eficiente, pois apresentou menor número de insetos contados. Em seguida, os inseticidas E e D apresentaram desempenho intermediário. Por fim, há um grupo com os inseticidas menos eficientes, nesse caso, contendo os tratamentos A, B e F.\n\n\n\n\n\n\nA função pwpm (emmeans) constrói uma matriz de valores de probabilidade, onde são apresentadas as comparações entre tratamentos, par a par. Nas diagonais, entre colchetes, são apresentados os valores de média de cada tratamento.\n\npwpm(m2_medias)\n\n       A      B      C      D      E      F\nA [3.76] 0.9975 &lt;.0001 &lt;.0001 &lt;.0001 0.9145\nB -0.116 [3.88] &lt;.0001 &lt;.0001 &lt;.0001 0.9936\nC  2.516  2.632 [1.24] 0.0081 0.2513 &lt;.0001\nD  1.596  1.712 -0.919 [2.16] 0.7366 &lt;.0001\nE  1.951  2.067 -0.565  0.355 [1.81] &lt;.0001\nF -0.258 -0.142 -2.774 -1.854 -2.209 [4.02]\n\nRow and column labels: spray\nUpper triangle: P values   adjust = \"tukey\"\nDiagonal: [Estimates] (emmean) \nLower triangle: Comparisons (estimate)   earlier vs. later\n\n\n\n\n\nA função pwpp (emmeans) constrói uma plotagem de valores de probabilidade associados as comparações pareadas das médias marginais estimadas.\n\npwpp (m2_medias)\n\n\n\n\n\n\n\n\n\n\n\nA função pairs apresenta os contrastes ortogonais dos valores de médias dos tratamentos, associados aos valores de probabilidade.\n\npairs(m2_medias)\n\n contrast estimate    SE df t.ratio p.value\n A - B      -0.116 0.257 66  -0.452  0.9975\n A - C       2.516 0.257 66   9.807  &lt;.0001\n A - D       1.596 0.257 66   6.223  &lt;.0001\n A - E       1.951 0.257 66   7.606  &lt;.0001\n A - F      -0.258 0.257 66  -1.006  0.9145\n B - C       2.632 0.257 66  10.259  &lt;.0001\n B - D       1.712 0.257 66   6.675  &lt;.0001\n B - E       2.067 0.257 66   8.058  &lt;.0001\n B - F      -0.142 0.257 66  -0.554  0.9936\n C - D      -0.919 0.257 66  -3.584  0.0081\n C - E      -0.565 0.257 66  -2.201  0.2513\n C - F      -2.774 0.257 66 -10.813  &lt;.0001\n D - E       0.355 0.257 66   1.383  0.7366\n D - F      -1.854 0.257 66  -7.229  &lt;.0001\n E - F      -2.209 0.257 66  -8.612  &lt;.0001\n\nP value adjustment: tukey method for comparing a family of 6 estimates \n\n\n\n\n\n\nPara tentar sanar o problema da falta de normalidade e/ou heterocedasticidade, é possível utilizar um segundo tipo de transformação, neste caso a transformação de Box-Cox.\nA transformação de Box-Cox se baseia na seguinte equação:\n\\(y_{(\\lambda)} = (y^{\\lambda} - 1)/ \\lambda\\)\nOnde, y representa a variável resposta original; \\(y_{(\\lambda)}\\) é a variável resposta transformada; e lambda (𝛌) é o parâmetro de transformação, variando entre - ∞ e + ∞.\n\nPara conduzir essa transformação, é utilizada a função boxcox (pacote MASS). A função calcula e identifica o valor 𝛌 ótimo para um determinado conjunto de dados (onde o valor de Y é máximo).\n\nlibrary(MASS)\n\nb &lt;- boxcox(lm(inseticida$count + 0.1 ~ 1))\n\n\n\n\n\n\n\n\n\nlambda &lt;- b$x [which.max(b$y)]\nlambda\n\n[1] 0.4242424\n\n\nCom os comandos acima é possível determinar na equação (b) o valor de 𝛌 (no eixo x), cujo valor de y é máximo. Logo, para o conjunto em análise, 𝛌 ≅ 0.42.\n\n\nCom o valor calculado acima, realiza-se a transformação de Box-Cox:\n\ninseticida$count3 &lt;-(inseticida$count ^ lambda - 1) / lambda\n\n\nNovo modelo\n\nm3 &lt;- lm(count3 ~ spray,\n         data = inseticida)\n\n\nAvaliação de normalidade e homogeneidade de variâncias entre os grupos:\n\nhist(inseticida$count3)\n\n\n\n\n\n\n\n\n\nqqnorm (m3$residuals)\nqqline (m3$residuals)\n\n\n\n\n\n\n\nshapiro.test(m3$residuals)\n\n\n    Shapiro-Wilk normality test\n\ndata:  m3$residuals\nW = 0.98873, p-value = 0.7723\n\n\n\nbartlett.test(count3 ~ spray,\n              data = inseticida)\n\n\n    Bartlett test of homogeneity of variances\n\ndata:  count3 by spray\nBartlett's K-squared = 5.7412, df = 5, p-value = 0.3322\n\n\nCom a transformação de Box-Cox, os dados passaram a possuir normalidade e homocedasticidade, satisfazendo as pressuposições da ANOVA. Em seguida poderiam ser feitos ANOVA e comparação de médias como já demonstrado anteriormente.\n\n\n\n\nComo a variável resposta do conjunto de dados em estudo é do tipo numérica discreta e não pareada, é adotado o teste de Kruskal Wallis.\n\n\n\n\nEssa função faz um teste de Kruskal Wallis e é útil apenas para informar se há alguma diferença estatística significativa entre os grupos.\n\nkruskal.test(count ~ spray,\n             data = inseticida)\n\n\n    Kruskal-Wallis rank sum test\n\ndata:  count by spray\nKruskal-Wallis chi-squared = 54.691, df = 5, p-value = 1.511e-10\n\n\n\n\n\nAlém de realizar o teste de Kruskal Wallis, faz a comparação post hoc utilizando o critério da diferença menos significativa de Fisher.\n\nlibrary(agricolae)\n\nKWT &lt;- kruskal(inseticida$count,\n               inseticida$spray,\n               group = TRUE)\nKWT\n\n$statistics\n     Chisq Df      p.chisq  t.value      MSD\n  54.69134  5 1.510845e-10 1.996564 8.462804\n\n$parameters\n            test p.ajusted           name.t ntr alpha\n  Kruskal-Wallis      none inseticida$spray   6  0.05\n\n$means\n  inseticida.count     rank      std  r Min Max   Q25  Q50   Q75\nA        14.500000 52.16667 4.719399 12   7  23 11.50 14.0 17.75\nB        15.333333 54.83333 4.271115 12   7  21 12.50 16.5 17.50\nC         2.083333 11.45833 1.975225 12   0   7  1.00  1.5  3.00\nD         4.916667 25.58333 2.503028 12   2  12  3.75  5.0  5.00\nE         3.500000 19.33333 1.732051 12   1   6  2.75  3.0  5.00\nF        16.666667 55.62500 6.213378 12   9  26 12.50 15.0 22.50\n\n$comparison\nNULL\n\n$groups\n  inseticida$count groups\nF         55.62500      a\nB         54.83333      a\nA         52.16667      a\nD         25.58333      b\nE         19.33333     bc\nC         11.45833      c\n\nattr(,\"class\")\n[1] \"group\"\n\n\nO teste não paramétrico resultou na mesma resposta que o modelo com os dados transformados (modelo m2).\n\n\n\n\nO uso de modelos lineares generalizados pode ser visto como um método de transformação mais bonito e elegante que os apresentados anteriormente, mesmo que ambas as metodologias estejam corretas.\nCom o GLM, o modelo (a função) mais apropriado é definido de acordo com a distribuição dos dados em análise.\nNeste exemplo, será aplicada uma distribuição de Poisson, já que a variável resposta é do tipo numérica discreta.\nA função glm é utilizada para ajustar o modelo linear, onde é preciso indicar a variável resposta, a variável independente, a família de distribuição de probabilidade e o conjunto de dados utilizado.\n\nm4 &lt;- glm(count ~ spray,\n          family = poisson,\n          data = inseticida)\n\nsummary(m4)\n\n\nCall:\nglm(formula = count ~ spray, family = poisson, data = inseticida)\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  2.67415    0.07581  35.274  &lt; 2e-16 ***\nsprayB       0.05588    0.10574   0.528    0.597    \nsprayC      -1.94018    0.21389  -9.071  &lt; 2e-16 ***\nsprayD      -1.08152    0.15065  -7.179 7.03e-13 ***\nsprayE      -1.42139    0.17192  -8.268  &lt; 2e-16 ***\nsprayF       0.13926    0.10367   1.343    0.179    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 409.041  on 71  degrees of freedom\nResidual deviance:  98.329  on 66  degrees of freedom\nAIC: 376.59\n\nNumber of Fisher Scoring iterations: 5\n\nanova(m4)\n\nAnalysis of Deviance Table\n\nModel: poisson, link: log\n\nResponse: count\n\nTerms added sequentially (first to last)\n\n      Df Deviance Resid. Df Resid. Dev\nNULL                     71     409.04\nspray  5   310.71        66      98.33\n\n\n\nlibrary(car)\nAnova(m4)\n\nAnalysis of Deviance Table (Type II tests)\n\nResponse: count\n      LR Chisq Df Pr(&gt;Chisq)    \nspray   310.71  5  &lt; 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n\nplot(simulateResiduals(m4))\n\n\n\n\n\n\n\n\n\n\n\n\nm4_medias &lt;- emmeans(m4, ~ spray,\n                     type =  \"response\") #para apresentar as médias no formato original, não em log#\n\nm4_medias\n\n spray  rate    SE  df asymp.LCL asymp.UCL\n A     14.50 1.099 Inf     12.50     16.82\n B     15.33 1.130 Inf     13.27     17.72\n C      2.08 0.417 Inf      1.41      3.08\n D      4.92 0.640 Inf      3.81      6.35\n E      3.50 0.540 Inf      2.59      4.74\n F     16.67 1.179 Inf     14.51     19.14\n\nConfidence level used: 0.95 \nIntervals are back-transformed from the log scale \n\ncld(m4_medias)\n\n spray  rate    SE  df asymp.LCL asymp.UCL .group\n C      2.08 0.417 Inf      1.41      3.08  1    \n E      3.50 0.540 Inf      2.59      4.74  12   \n D      4.92 0.640 Inf      3.81      6.35   2   \n A     14.50 1.099 Inf     12.50     16.82    3  \n B     15.33 1.130 Inf     13.27     17.72    3  \n F     16.67 1.179 Inf     14.51     19.14    3  \n\nConfidence level used: 0.95 \nIntervals are back-transformed from the log scale \nP value adjustment: tukey method for comparing a family of 6 estimates \nTests are performed on the log scale \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same.",
    "crumbs": [
      "Home",
      "Aula 07",
      "Estatística inferencial - Alternativas de análise"
    ]
  },
  {
    "objectID": "Aula 7.2.html#transformação-dos-dados",
    "href": "Aula 7.2.html#transformação-dos-dados",
    "title": "Aula 07 - Estatística inferencial - Alternativas de análise",
    "section": "",
    "text": "Diante dos resultados obtidos, conclui-se que o conjunto de dados não atende as pressuposições da ANOVA, logo é necessário definir uma estratégia para prosseguir na análise dos dados. É possível realizar transformações da variável resposta, adotar um teste não-paramétrico (por exemplo, teste de Kruskal-Wallis), ou utilizar um modelo linear generalizado (Generalized Linear Model - GLM). A seguir, são apresentados exemplos de como se adotar cada estratégia:\n\n\nOs dados serão transformados com a função sqrt e a coluna da variável resposta será substituída com os novos valores:\n\ninseticida &lt;- inseticida %&gt;% \n  mutate(count2 = sqrt(count))\n\nglimpse(inseticida)\n\nRows: 72\nColumns: 3\n$ count  &lt;dbl&gt; 10, 7, 20, 14, 14, 12, 10, 23, 17, 20, 14, 13, 11, 17, 21, 11, …\n$ spray  &lt;fct&gt; A, A, A, A, A, A, A, A, A, A, A, A, B, B, B, B, B, B, B, B, B, …\n$ count2 &lt;dbl&gt; 3.162278, 2.645751, 4.472136, 3.741657, 3.741657, 3.464102, 3.1…\n\n\n\n\n\ninseticida %&gt;%\n  ggplot(aes(spray, count2))+\n  geom_boxplot(width = 0.5)\n\n\n\n\n\n\n\n\nVisualmente, é possível dizer que, possivelmente, os dados transformados agora possuem normalidade e homocedasticidade, pois os valores de mediana tendem a se encontrar nos centros da caixas e essas tem tamanho mais ou menos similar entre si.\n\n\n\n\nm2 &lt;- lm(count2 ~ spray,\n         data = inseticida)\n\nsummary(m2)\n\n\nCall:\nlm(formula = count2 ~ spray, data = inseticida)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1.24486 -0.39970 -0.01902  0.42661  1.40089 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   3.7607     0.1814  20.733  &lt; 2e-16 ***\nsprayB        0.1160     0.2565   0.452    0.653    \nsprayC       -2.5158     0.2565  -9.807 1.64e-14 ***\nsprayD       -1.5963     0.2565  -6.223 3.80e-08 ***\nsprayE       -1.9512     0.2565  -7.606 1.34e-10 ***\nsprayF        0.2579     0.2565   1.006    0.318    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.6283 on 66 degrees of freedom\nMultiple R-squared:  0.7724,    Adjusted R-squared:  0.7552 \nF-statistic:  44.8 on 5 and 66 DF,  p-value: &lt; 2.2e-16\n\n\n\n\n\n\nanova (m2)\n\nAnalysis of Variance Table\n\nResponse: count2\n          Df Sum Sq Mean Sq F value    Pr(&gt;F)    \nspray      5 88.438 17.6876  44.799 &lt; 2.2e-16 ***\nResiduals 66 26.058  0.3948                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nMesmo após transformação, os dados continuem apresentando diferença significativa, ou seja, há pelo menos uma média que difere das demais.\n\n\n\n\nhist(m2$residuals)\n\n\n\n\n\n\n\n\n\nqqnorm(m2$residuals)\nqqline(m2$residuals)\n\n\n\n\n\n\n\n\n\nshapiro.test(m2$residuals)\n\n\n    Shapiro-Wilk normality test\n\ndata:  m2$residuals\nW = 0.98721, p-value = 0.6814\n\n\nVisual e estatisticamente, conclui-se que os resíduos do conjunto de dados transformados possuem distribuição normal.\n\n\n\n\nbartlett.test(count2 ~ spray,\n              data = inseticida)\n\n\n    Bartlett test of homogeneity of variances\n\ndata:  count2 by spray\nBartlett's K-squared = 3.7525, df = 5, p-value = 0.5856\n\n\nApós a transformação, é possível dizer que há homogeneidade de variâncias entre os grupos.\n\n\n\n\ncheck_normality(m2)\n\nOK: residuals appear as normally distributed (p = 0.681).\n\ncheck_heteroscedasticity(m2)\n\nOK: Error variance appears to be homoscedastic (p = 0.854).\n\n\n\n\n\n\nplot(simulateResiduals(m2))\n\n\n\n\n\n\n\n\nApós os vários testes realizados, temos confiança que os dados transformados possuem distribuição normal e homogeneidade das variâncias. Logo, é possível realizar comparações de médias.\n\n\n\n\n\n\nApenas à título de curiosidade, será feita uma comparação de médias com base nos valores originais. O que não é correto, uma vez que esses não satisfazem as pressuposições da ANOVA.\nPara isso, a função emmeans, indicando o modelo (m1) e os tratamentos (spray), será atribuída a um objeto.\n\nm1_medias &lt;- emmeans(m1, ~ spray)\nplot(m1_medias)\n\n\n\n\n\n\n\n\nO gráfico gerado mostra que para essa situação, os tratamentos tendem a formar dois grupos de eficiência.\n\nmultcomp::cld(m1_medias)\n\n spray emmean   SE df lower.CL upper.CL .group\n C       2.08 1.13 66   -0.177     4.34  1    \n E       3.50 1.13 66    1.240     5.76  1    \n D       4.92 1.13 66    2.656     7.18  1    \n A      14.50 1.13 66   12.240    16.76   2   \n B      15.33 1.13 66   13.073    17.59   2   \n F      16.67 1.13 66   14.406    18.93   2   \n\nConfidence level used: 0.95 \nP value adjustment: tukey method for comparing a family of 6 estimates \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\n\nO que é comprovado estatisticamente pela comparação de médias, utilizando o teste de Tukey.\n\n\n\nPara os dados transformados, serão aplicados os mesmos passos descritos acima:\n\nm2_medias &lt;- emmeans(m2, ~ spray)\nplot(m2_medias)\n\n\n\n\n\n\n\n\nVisualmente, é possível dizer que os inseticidas formam três grupos distintos.\n\nmultcomp::cld(m2_medias)\n\n spray emmean    SE df lower.CL upper.CL .group\n C       1.24 0.181 66    0.883     1.61  1    \n E       1.81 0.181 66    1.447     2.17  12   \n D       2.16 0.181 66    1.802     2.53   2   \n A       3.76 0.181 66    3.399     4.12    3  \n B       3.88 0.181 66    3.514     4.24    3  \n F       4.02 0.181 66    3.656     4.38    3  \n\nConfidence level used: 0.95 \nP value adjustment: tukey method for comparing a family of 6 estimates \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\n\nCom a média transformada, o teste de Tukey agrupa os tratamentos em 3 grupos distintos, logo houve melhor discriminação. Com isso, concluímos que, em comparação aos demais, o inseticida C foi o mais eficiente, pois apresentou menor número de insetos contados. Em seguida, os inseticidas E e D apresentaram desempenho intermediário. Por fim, há um grupo com os inseticidas menos eficientes, nesse caso, contendo os tratamentos A, B e F.\n\n\n\n\n\n\nA função pwpm (emmeans) constrói uma matriz de valores de probabilidade, onde são apresentadas as comparações entre tratamentos, par a par. Nas diagonais, entre colchetes, são apresentados os valores de média de cada tratamento.\n\npwpm(m2_medias)\n\n       A      B      C      D      E      F\nA [3.76] 0.9975 &lt;.0001 &lt;.0001 &lt;.0001 0.9145\nB -0.116 [3.88] &lt;.0001 &lt;.0001 &lt;.0001 0.9936\nC  2.516  2.632 [1.24] 0.0081 0.2513 &lt;.0001\nD  1.596  1.712 -0.919 [2.16] 0.7366 &lt;.0001\nE  1.951  2.067 -0.565  0.355 [1.81] &lt;.0001\nF -0.258 -0.142 -2.774 -1.854 -2.209 [4.02]\n\nRow and column labels: spray\nUpper triangle: P values   adjust = \"tukey\"\nDiagonal: [Estimates] (emmean) \nLower triangle: Comparisons (estimate)   earlier vs. later\n\n\n\n\n\nA função pwpp (emmeans) constrói uma plotagem de valores de probabilidade associados as comparações pareadas das médias marginais estimadas.\n\npwpp (m2_medias)\n\n\n\n\n\n\n\n\n\n\n\nA função pairs apresenta os contrastes ortogonais dos valores de médias dos tratamentos, associados aos valores de probabilidade.\n\npairs(m2_medias)\n\n contrast estimate    SE df t.ratio p.value\n A - B      -0.116 0.257 66  -0.452  0.9975\n A - C       2.516 0.257 66   9.807  &lt;.0001\n A - D       1.596 0.257 66   6.223  &lt;.0001\n A - E       1.951 0.257 66   7.606  &lt;.0001\n A - F      -0.258 0.257 66  -1.006  0.9145\n B - C       2.632 0.257 66  10.259  &lt;.0001\n B - D       1.712 0.257 66   6.675  &lt;.0001\n B - E       2.067 0.257 66   8.058  &lt;.0001\n B - F      -0.142 0.257 66  -0.554  0.9936\n C - D      -0.919 0.257 66  -3.584  0.0081\n C - E      -0.565 0.257 66  -2.201  0.2513\n C - F      -2.774 0.257 66 -10.813  &lt;.0001\n D - E       0.355 0.257 66   1.383  0.7366\n D - F      -1.854 0.257 66  -7.229  &lt;.0001\n E - F      -2.209 0.257 66  -8.612  &lt;.0001\n\nP value adjustment: tukey method for comparing a family of 6 estimates \n\n\n\n\n\n\nPara tentar sanar o problema da falta de normalidade e/ou heterocedasticidade, é possível utilizar um segundo tipo de transformação, neste caso a transformação de Box-Cox.\nA transformação de Box-Cox se baseia na seguinte equação:\n\\(y_{(\\lambda)} = (y^{\\lambda} - 1)/ \\lambda\\)\nOnde, y representa a variável resposta original; \\(y_{(\\lambda)}\\) é a variável resposta transformada; e lambda (𝛌) é o parâmetro de transformação, variando entre - ∞ e + ∞.\n\nPara conduzir essa transformação, é utilizada a função boxcox (pacote MASS). A função calcula e identifica o valor 𝛌 ótimo para um determinado conjunto de dados (onde o valor de Y é máximo).\n\nlibrary(MASS)\n\nb &lt;- boxcox(lm(inseticida$count + 0.1 ~ 1))\n\n\n\n\n\n\n\n\n\nlambda &lt;- b$x [which.max(b$y)]\nlambda\n\n[1] 0.4242424\n\n\nCom os comandos acima é possível determinar na equação (b) o valor de 𝛌 (no eixo x), cujo valor de y é máximo. Logo, para o conjunto em análise, 𝛌 ≅ 0.42.\n\n\nCom o valor calculado acima, realiza-se a transformação de Box-Cox:\n\ninseticida$count3 &lt;-(inseticida$count ^ lambda - 1) / lambda\n\n\nNovo modelo\n\nm3 &lt;- lm(count3 ~ spray,\n         data = inseticida)\n\n\nAvaliação de normalidade e homogeneidade de variâncias entre os grupos:\n\nhist(inseticida$count3)\n\n\n\n\n\n\n\n\n\nqqnorm (m3$residuals)\nqqline (m3$residuals)\n\n\n\n\n\n\n\nshapiro.test(m3$residuals)\n\n\n    Shapiro-Wilk normality test\n\ndata:  m3$residuals\nW = 0.98873, p-value = 0.7723\n\n\n\nbartlett.test(count3 ~ spray,\n              data = inseticida)\n\n\n    Bartlett test of homogeneity of variances\n\ndata:  count3 by spray\nBartlett's K-squared = 5.7412, df = 5, p-value = 0.3322\n\n\nCom a transformação de Box-Cox, os dados passaram a possuir normalidade e homocedasticidade, satisfazendo as pressuposições da ANOVA. Em seguida poderiam ser feitos ANOVA e comparação de médias como já demonstrado anteriormente.\n\n\n\n\nComo a variável resposta do conjunto de dados em estudo é do tipo numérica discreta e não pareada, é adotado o teste de Kruskal Wallis.\n\n\n\n\nEssa função faz um teste de Kruskal Wallis e é útil apenas para informar se há alguma diferença estatística significativa entre os grupos.\n\nkruskal.test(count ~ spray,\n             data = inseticida)\n\n\n    Kruskal-Wallis rank sum test\n\ndata:  count by spray\nKruskal-Wallis chi-squared = 54.691, df = 5, p-value = 1.511e-10\n\n\n\n\n\nAlém de realizar o teste de Kruskal Wallis, faz a comparação post hoc utilizando o critério da diferença menos significativa de Fisher.\n\nlibrary(agricolae)\n\nKWT &lt;- kruskal(inseticida$count,\n               inseticida$spray,\n               group = TRUE)\nKWT\n\n$statistics\n     Chisq Df      p.chisq  t.value      MSD\n  54.69134  5 1.510845e-10 1.996564 8.462804\n\n$parameters\n            test p.ajusted           name.t ntr alpha\n  Kruskal-Wallis      none inseticida$spray   6  0.05\n\n$means\n  inseticida.count     rank      std  r Min Max   Q25  Q50   Q75\nA        14.500000 52.16667 4.719399 12   7  23 11.50 14.0 17.75\nB        15.333333 54.83333 4.271115 12   7  21 12.50 16.5 17.50\nC         2.083333 11.45833 1.975225 12   0   7  1.00  1.5  3.00\nD         4.916667 25.58333 2.503028 12   2  12  3.75  5.0  5.00\nE         3.500000 19.33333 1.732051 12   1   6  2.75  3.0  5.00\nF        16.666667 55.62500 6.213378 12   9  26 12.50 15.0 22.50\n\n$comparison\nNULL\n\n$groups\n  inseticida$count groups\nF         55.62500      a\nB         54.83333      a\nA         52.16667      a\nD         25.58333      b\nE         19.33333     bc\nC         11.45833      c\n\nattr(,\"class\")\n[1] \"group\"\n\n\nO teste não paramétrico resultou na mesma resposta que o modelo com os dados transformados (modelo m2).\n\n\n\n\nO uso de modelos lineares generalizados pode ser visto como um método de transformação mais bonito e elegante que os apresentados anteriormente, mesmo que ambas as metodologias estejam corretas.\nCom o GLM, o modelo (a função) mais apropriado é definido de acordo com a distribuição dos dados em análise.\nNeste exemplo, será aplicada uma distribuição de Poisson, já que a variável resposta é do tipo numérica discreta.\nA função glm é utilizada para ajustar o modelo linear, onde é preciso indicar a variável resposta, a variável independente, a família de distribuição de probabilidade e o conjunto de dados utilizado.\n\nm4 &lt;- glm(count ~ spray,\n          family = poisson,\n          data = inseticida)\n\nsummary(m4)\n\n\nCall:\nglm(formula = count ~ spray, family = poisson, data = inseticida)\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  2.67415    0.07581  35.274  &lt; 2e-16 ***\nsprayB       0.05588    0.10574   0.528    0.597    \nsprayC      -1.94018    0.21389  -9.071  &lt; 2e-16 ***\nsprayD      -1.08152    0.15065  -7.179 7.03e-13 ***\nsprayE      -1.42139    0.17192  -8.268  &lt; 2e-16 ***\nsprayF       0.13926    0.10367   1.343    0.179    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 409.041  on 71  degrees of freedom\nResidual deviance:  98.329  on 66  degrees of freedom\nAIC: 376.59\n\nNumber of Fisher Scoring iterations: 5\n\nanova(m4)\n\nAnalysis of Deviance Table\n\nModel: poisson, link: log\n\nResponse: count\n\nTerms added sequentially (first to last)\n\n      Df Deviance Resid. Df Resid. Dev\nNULL                     71     409.04\nspray  5   310.71        66      98.33\n\n\n\nlibrary(car)\nAnova(m4)\n\nAnalysis of Deviance Table (Type II tests)\n\nResponse: count\n      LR Chisq Df Pr(&gt;Chisq)    \nspray   310.71  5  &lt; 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n\nplot(simulateResiduals(m4))\n\n\n\n\n\n\n\n\n\n\n\n\nm4_medias &lt;- emmeans(m4, ~ spray,\n                     type =  \"response\") #para apresentar as médias no formato original, não em log#\n\nm4_medias\n\n spray  rate    SE  df asymp.LCL asymp.UCL\n A     14.50 1.099 Inf     12.50     16.82\n B     15.33 1.130 Inf     13.27     17.72\n C      2.08 0.417 Inf      1.41      3.08\n D      4.92 0.640 Inf      3.81      6.35\n E      3.50 0.540 Inf      2.59      4.74\n F     16.67 1.179 Inf     14.51     19.14\n\nConfidence level used: 0.95 \nIntervals are back-transformed from the log scale \n\ncld(m4_medias)\n\n spray  rate    SE  df asymp.LCL asymp.UCL .group\n C      2.08 0.417 Inf      1.41      3.08  1    \n E      3.50 0.540 Inf      2.59      4.74  12   \n D      4.92 0.640 Inf      3.81      6.35   2   \n A     14.50 1.099 Inf     12.50     16.82    3  \n B     15.33 1.130 Inf     13.27     17.72    3  \n F     16.67 1.179 Inf     14.51     19.14    3  \n\nConfidence level used: 0.95 \nIntervals are back-transformed from the log scale \nP value adjustment: tukey method for comparing a family of 6 estimates \nTests are performed on the log scale \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same.",
    "crumbs": [
      "Home",
      "Aula 07",
      "Estatística inferencial - Alternativas de análise"
    ]
  },
  {
    "objectID": "Aula 8.1.html",
    "href": "Aula 8.1.html",
    "title": "Aula 08 - Estatística inferencial - Experimento em DBC",
    "section": "",
    "text": "Esta aula aborda a análise de variância (ANOVA) de um experimento conduzido em delineamento com blocos ao acaso. Transformações de dados, como raiz quadrada e Box-Cox, são aplicadas quando necessário. Comparações de médias são feitas utilizando os pacotes emmeans e multcomp. Em seguida, é apresentado como construir uma curva de progresso da doença, calculando a área sob a curva (AUDPC) e realizando ANOVA para avaliar as diferenças entre tratamentos.",
    "crumbs": [
      "Home",
      "Aula 08",
      "Estatística inferencial - Experimento em DBC"
    ]
  },
  {
    "objectID": "Aula 8.1.html#carregando-os-pacotes",
    "href": "Aula 8.1.html#carregando-os-pacotes",
    "title": "Aula 08 - Estatística inferencial - Experimento em DBC",
    "section": "Carregando os pacotes",
    "text": "Carregando os pacotes\n\nlibrary(gsheet)\nlibrary(tidyverse)\nlibrary(patchwork)\nlibrary(performance)\nlibrary(DHARMa)\nlibrary(emmeans)\nlibrary(multcomp)\nlibrary(multcompView)\nlibrary(MASS)\nlibrary(epifitter)",
    "crumbs": [
      "Home",
      "Aula 08",
      "Estatística inferencial - Experimento em DBC"
    ]
  },
  {
    "objectID": "Aula 8.1.html#importando-dados",
    "href": "Aula 8.1.html#importando-dados",
    "title": "Aula 08 - Estatística inferencial - Experimento em DBC",
    "section": "Importando dados",
    "text": "Importando dados\n\nsoja &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=866852711\")\n\n\nOs dados são referentes a um experimento de soja em campo, conduzido em blocos casualizados, onde o efeito de diferentes fungicidas (coluna “TRAT”, 1 nível, 8 fatores) foi avaliado sobre as doenças de final de ciclo (DFC), a severidade da ferrugem (FER) e a produtividade (PROD).\n\nComo os dados da coluna TRAT e BLOCO são do tipo numérico, é preciso transformá-los para fator.\n\nsoja$TRAT &lt;- as.factor(soja$TRAT)\nsoja$BLOCO &lt;- as.factor(soja$BLOCO)\n\n\n#ou#\n\n\nsoja &lt;- soja %&gt;% \n  mutate(TRAT = as.factor(TRAT),\n         BLOCO = as.factor(BLOCO))\n\n\nglimpse(soja)\n\nRows: 32\nColumns: 5\n$ TRAT  &lt;fct&gt; 1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3, 4, 4, 4, 4, 5, 5, 5, 5, 6, 6…\n$ BLOCO &lt;fct&gt; 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2…\n$ DFC   &lt;dbl&gt; 10.0, 10.5, 12.0, 11.0, 6.2, 6.0, 7.0, 6.5, 6.0, 6.2, 6.5, 5.5, …\n$ FER   &lt;dbl&gt; 17.0, 21.0, 25.0, 18.0, 6.5, 4.0, 8.0, 5.0, 6.0, 3.5, 2.5, 4.0, …\n$ PROD  &lt;dbl&gt; 4611, 4312, 4545, 3409, 5023, 4839, 4903, 4975, 5235, 5014, 5263…",
    "crumbs": [
      "Home",
      "Aula 08",
      "Estatística inferencial - Experimento em DBC"
    ]
  },
  {
    "objectID": "Aula 8.1.html#estatística-descritiva---visualização-gráfica",
    "href": "Aula 8.1.html#estatística-descritiva---visualização-gráfica",
    "title": "Aula 08 - Estatística inferencial - Experimento em DBC",
    "section": "Estatística Descritiva - Visualização gráfica",
    "text": "Estatística Descritiva - Visualização gráfica\nPara visualização dos dados das variáveis dependentes (DFC, FER e PROD), serão construídos gráficos de pontos (ggplot: geom_jitter) acrescido do intervalo de confiança.\nPara a apresentação do intervalo de confiança, será utilizada a função stat_summary (fun.data), com o argumento \"mean_cl_boot\".\n\nDFC\n\nDFC &lt;- soja %&gt;% \n  ggplot(aes(TRAT, DFC))+\n  geom_jitter(width = 0.05)+\n  stat_summary (fun.data = \"mean_cl_boot\", color = \"darkred\", alpha = 0.5)\nDFC\n\n\n\n\n\n\n\n\n\n\nFER\n\nFER &lt;- soja %&gt;% \n  ggplot(aes(TRAT, FER))+\n  geom_jitter(width = 0.05)+\n    stat_summary (fun.data = \"mean_cl_boot\", color = \"darkred\", alpha = 0.5)\nFER\n\n\n\n\n\n\n\n\n\n\nPROD\n\nPROD &lt;- soja %&gt;% \n  ggplot(aes(TRAT, PROD))+\n  geom_jitter(width = 0.05)+\n    stat_summary (fun.data = \"mean_cl_boot\", color = \"darkred\", alpha = 0.5)\nPROD\n\n\n\n\n\n\n\n\n\n\nDFC+FER+PROD\nPara combinar os gráficos em uma única figura, utiliza-se o pacote patchwork:\n\n(PROD + DFC / FER)",
    "crumbs": [
      "Home",
      "Aula 08",
      "Estatística inferencial - Experimento em DBC"
    ]
  },
  {
    "objectID": "Aula 8.1.html#estatística-inferencial",
    "href": "Aula 8.1.html#estatística-inferencial",
    "title": "Aula 08 - Estatística inferencial - Experimento em DBC",
    "section": "Estatística Inferencial",
    "text": "Estatística Inferencial",
    "crumbs": [
      "Home",
      "Aula 08",
      "Estatística inferencial - Experimento em DBC"
    ]
  },
  {
    "objectID": "Aula 8.1.html#dfc-1",
    "href": "Aula 8.1.html#dfc-1",
    "title": "Aula 08 - Estatística inferencial - Experimento em DBC",
    "section": "DFC",
    "text": "DFC\n\nANOVA\nPara realizar a análise de variância é preciso construir um modelo, nesse caso, um modelo linear (função lm), considerando TRAT e BLOCO como fatores fixos.\n\naov_dfc &lt;- lm (DFC ~ TRAT + BLOCO,\n               data = soja)\n\nanova(aov_dfc)\n\nAnalysis of Variance Table\n\nResponse: DFC\n          Df  Sum Sq Mean Sq F value    Pr(&gt;F)    \nTRAT       7 149.299 21.3284 51.5490 8.218e-12 ***\nBLOCO      3   0.461  0.1537  0.3716    0.7743    \nResiduals 21   8.689  0.4138                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nPara o fator fixo, TRAT, há efeito significativo, logo há algum tratamento que difere dos demais. Para o fator BLOCO, não houve efeito, logo, não há diferença significativa entre eles.\n\n\n\nPressuposições da ANOVA\nA avaliação das pressuposições da ANOVA será realizada com as funções check_normality e check_heteroscedasticity (pacote Performance).\n\ncheck_normality(aov_dfc)\n\nOK: residuals appear as normally distributed (p = 0.978).\n\ncheck_heteroscedasticity(aov_dfc)\n\nOK: Error variance appears to be homoscedastic (p = 0.532).\n\n\nOs testes mostram que os resíduos são normalmente distribuídos e que há homogeneidade de variâncias entre os grupos. Assim, é possível proceder a comparação de médias.\n\n\nComparação de médias\nPara comparação de médias o modelo gerado acima será aplicado à função emmeans para criação de um novo objeto. Essa função estima uma média com base no modelo, logo algumas vezes pode não ser igual a média aritmética.\n\nmedias_dfc &lt;- emmeans(aov_dfc, ~TRAT)\nmedias_dfc\n\n TRAT emmean    SE df lower.CL upper.CL\n 1     10.88 0.322 21    10.21    11.54\n 2      6.42 0.322 21     5.76     7.09\n 3      6.05 0.322 21     5.38     6.72\n 4      4.75 0.322 21     4.08     5.42\n 5      4.20 0.322 21     3.53     4.87\n 6      4.00 0.322 21     3.33     4.67\n 7      4.08 0.322 21     3.41     4.74\n 8      4.58 0.322 21     3.91     5.24\n\nResults are averaged over the levels of: BLOCO \nConfidence level used: 0.95 \n\n\nEm seguida, o objeto criado será argumento das funções pwpm (emmeans) e cld (multcomp), que permitem visualização da comparação de médias.\n\npwpm (medias_dfc)\n\n        1       2       3       4       5       6       7       8\n1 [10.87]  &lt;.0001  &lt;.0001  &lt;.0001  &lt;.0001  &lt;.0001  &lt;.0001  &lt;.0001\n2   4.450 [ 6.42]  0.9896  0.0249  0.0017  0.0006  0.0009  0.0107\n3   4.825   0.375 [ 6.05]  0.1329  0.0107  0.0040  0.0058  0.0628\n4   6.125   1.675   1.300 [ 4.75]  0.9202  0.7173  0.8072  0.9999\n5   6.675   2.225   1.850   0.550 [ 4.20]  0.9998  1.0000  0.9896\n6   6.875   2.425   2.050   0.750   0.200 [ 4.00]  1.0000  0.9020\n7   6.800   2.350   1.975   0.675   0.125  -0.075 [ 4.07]  0.9499\n8   6.300   1.850   1.475   0.175  -0.375  -0.575  -0.500 [ 4.57]\n\nRow and column labels: TRAT\nUpper triangle: P values   adjust = \"tukey\"\nDiagonal: [Estimates] (emmean) \nLower triangle: Comparisons (estimate)   earlier vs. later\n\n\nNa função pwpm, há três informações úteis. Na diagonal, é apresentado o valor médio estimado para cada tratamento. Acima da diagonal, são plotados os valores de probabilidade, relacionados ao teste de Tukey, referentes às comparações múltiplas entre tratamentos. Abaixo da diagonal, há a diferença de valores médios entre os tratamentos.\n\ncld (medias_dfc, Letters = LETTERS)\n\n TRAT emmean    SE df lower.CL upper.CL .group\n 6      4.00 0.322 21     3.33     4.67  A    \n 7      4.08 0.322 21     3.41     4.74  A    \n 5      4.20 0.322 21     3.53     4.87  A    \n 8      4.58 0.322 21     3.91     5.24  AB   \n 4      4.75 0.322 21     4.08     5.42  AB   \n 3      6.05 0.322 21     5.38     6.72   BC  \n 2      6.42 0.322 21     5.76     7.09    C  \n 1     10.88 0.322 21    10.21    11.54     D \n\nResults are averaged over the levels of: BLOCO \nConfidence level used: 0.95 \nP value adjustment: tukey method for comparing a family of 8 estimates \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\n\nA função cld apresenta o resultado do teste de Tukey, com as letras representando os agrupamentos.",
    "crumbs": [
      "Home",
      "Aula 08",
      "Estatística inferencial - Experimento em DBC"
    ]
  },
  {
    "objectID": "Aula 8.1.html#fer-1",
    "href": "Aula 8.1.html#fer-1",
    "title": "Aula 08 - Estatística inferencial - Experimento em DBC",
    "section": "FER",
    "text": "FER\n\nANOVA\nSimilar ao já feito para a variável DFC, será agora conduzido para a variável FER.\n\naov_fer &lt;- lm (FER ~ TRAT + BLOCO,\n               data = soja)  \nanova(aov_fer)\n\nAnalysis of Variance Table\n\nResponse: FER\n          Df Sum Sq Mean Sq F value    Pr(&gt;F)    \nTRAT       7 978.87 139.838 55.1717 4.218e-12 ***\nBLOCO      3   3.84   1.279  0.5045    0.6834    \nResiduals 21  53.23   2.535                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nPara o fator fixo TRAT, há efeito significativo, logo há algum tratamento que difere dos demais. Para o fator BLOCO, não houve efeito já que não há diferença significativa entre eles.\n\n\nPressuposições da ANOVA\n\ncheck_normality(aov_fer) \n\nWarning: Non-normality of residuals detected (p = 0.008).\n\ncheck_heteroscedasticity(aov_fer)\n\nWarning: Heteroscedasticity (non-constant error variance) detected (p &lt; .001).\n\n\nOs testes demonstram que os dados não satisfazem as pressuposições da ANOVA, logo será preciso adotar uma alternativa para análise dos dados, como por exemplo a transformação por raiz quadrada.\n\n\nTransformação - Raiz quadrada\n\naov_fer1 &lt;- lm (sqrt(FER) ~ TRAT + BLOCO,\n               data = soja)  \nanova(aov_fer1)\n\nAnalysis of Variance Table\n\nResponse: sqrt(FER)\n          Df  Sum Sq Mean Sq F value    Pr(&gt;F)    \nTRAT       7 24.5179  3.5026 56.4870 3.345e-12 ***\nBLOCO      3  0.1495  0.0498  0.8039    0.5057    \nResiduals 21  1.3021  0.0620                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nPara os dados transformados pela raiz quadrada, o fator fixo TRAT continua possuindo efeito significativo, logo há algum tratamento que difere dos demais. Para o fator BLOCO, não houve efeito já que não há diferença significativa entre eles.\n\nPressuposições da ANOVA\n\ncheck_normality(aov_fer1)\n\nOK: residuals appear as normally distributed (p = 0.104).\n\ncheck_heteroscedasticity(aov_fer1)\n\nWarning: Heteroscedasticity (non-constant error variance) detected (p &lt; .001).\n\n\nA transformação por raiz quadrada foi suficiente para normalizar os valores do resíduo, no entanto, ainda há heterocedasticidade. Assim, uma outra transformação será testada: transformação de Box-Cox.\n\n\n\nTransformação - Box-Cox\n\nb &lt;- boxcox(lm(soja$FER ~ 1))\n\n\n\n\n\n\n\nlambda &lt;- b$x [which.max(b$y)]\nlambda\n\n[1] -1.555556\n\n\n\nsoja$FER2 &lt;-(soja$FER ^ lambda - 1) / lambda\n\n\nNovo modelo - Após transformação\n\naov_fer2 &lt;- lm (FER2 ~ TRAT + BLOCO,\n               data = soja)  \nanova(aov_fer2)\n\nAnalysis of Variance Table\n\nResponse: FER2\n          Df   Sum Sq   Mean Sq F value    Pr(&gt;F)    \nTRAT       7 0.041641 0.0059488 12.9020 2.436e-06 ***\nBLOCO      3 0.005895 0.0019649  4.2616   0.01687 *  \nResiduals 21 0.009683 0.0004611                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nPara os dados transformados por Box-Cox, o fator fixo TRAT continua possuindo efeito significativo, logo há algum tratamento que difere dos demais. Para o fator BLOCO, não houve efeito já que não há diferença significativa entre eles.\n\n\nPressuposições da ANOVA\n\ncheck_normality(aov_fer2) \n\nOK: residuals appear as normally distributed (p = 0.787).\n\ncheck_heteroscedasticity(aov_fer2)\n\nOK: Error variance appears to be homoscedastic (p = 0.872).\n\n\nOs testes demonstram que a transformação de Box-Cox foi suficiente para conferir normalidade aos resíduos e homogeneidade de variância entre os grupos.\n\n\nComparação de médias\nCom os dados transformados por Box-Cox, será feita a comparação de médias como já descrito anteriormente.\n\nmedias_fer2 &lt;- emmeans(aov_fer2, ~TRAT) \nmedias_fer2\n\n TRAT emmean     SE df lower.CL upper.CL\n 1     0.637 0.0107 21    0.614    0.659\n 2     0.596 0.0107 21    0.574    0.618\n 3     0.553 0.0107 21    0.530    0.575\n 4     0.527 0.0107 21    0.505    0.550\n 5     0.539 0.0107 21    0.517    0.561\n 6     0.523 0.0107 21    0.501    0.545\n 7     0.545 0.0107 21    0.523    0.567\n 8     0.549 0.0107 21    0.527    0.572\n\nResults are averaged over the levels of: BLOCO \nConfidence level used: 0.95 \n\n\n\npwpm (medias_fer2)\n\n         1        2        3        4        5        6        7       8\n1  [0.637]   0.1857   0.0004   &lt;.0001   &lt;.0001   &lt;.0001   0.0001  0.0002\n2  0.04058  [0.596]   0.1358   0.0039   0.0208   0.0020   0.0497  0.0880\n3  0.08380  0.04322  [0.553]   0.7032   0.9807   0.5313   0.9995  1.0000\n4  0.10920  0.06862  0.02540  [0.527]   0.9938   1.0000   0.9339  0.8261\n5  0.09775  0.05717  0.01395 -0.01145  [0.539]   0.9629   0.9999  0.9964\n6  0.11349  0.07292  0.02970  0.00429  0.01575  [0.523]   0.8261  0.6703\n7  0.09154  0.05097  0.00775 -0.01766 -0.00620 -0.02195  [0.545]  1.0000\n8  0.08725  0.04667  0.00345 -0.02195 -0.01050 -0.02624 -0.00429 [0.549]\n\nRow and column labels: TRAT\nUpper triangle: P values   adjust = \"tukey\"\nDiagonal: [Estimates] (emmean) \nLower triangle: Comparisons (estimate)   earlier vs. later\n\n\n\ncld (medias_fer2, Letters = LETTERS)\n\n TRAT emmean     SE df lower.CL upper.CL .group\n 6     0.523 0.0107 21    0.501    0.545  A    \n 4     0.527 0.0107 21    0.505    0.550  A    \n 5     0.539 0.0107 21    0.517    0.561  A    \n 7     0.545 0.0107 21    0.523    0.567  A    \n 8     0.549 0.0107 21    0.527    0.572  AB   \n 3     0.553 0.0107 21    0.530    0.575  AB   \n 2     0.596 0.0107 21    0.574    0.618   BC  \n 1     0.637 0.0107 21    0.614    0.659    C  \n\nResults are averaged over the levels of: BLOCO \nConfidence level used: 0.95 \nP value adjustment: tukey method for comparing a family of 8 estimates \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\n\nPelo fato de ter sido utilizada a transformação de Box-Cox, os valores apresentados no resultado acima são da transformação e para apresentação em uma tabela seria preciso obter os originais.",
    "crumbs": [
      "Home",
      "Aula 08",
      "Estatística inferencial - Experimento em DBC"
    ]
  },
  {
    "objectID": "Aula 8.1.html#prod-1",
    "href": "Aula 8.1.html#prod-1",
    "title": "Aula 08 - Estatística inferencial - Experimento em DBC",
    "section": "PROD",
    "text": "PROD\n\nANOVA\nSimilar ao já feito para a variável DFC, será agora conduzido para a variável PROD.\n\naov_prod &lt;- lm(PROD ~ TRAT + BLOCO,\n               data = soja)\nanova(aov_prod)\n\nAnalysis of Variance Table\n\nResponse: PROD\n          Df  Sum Sq Mean Sq F value  Pr(&gt;F)  \nTRAT       7 2993906  427701  2.6367 0.04021 *\nBLOCO      3  105665   35222  0.2171 0.88340  \nResiduals 21 3406431  162211                  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nPara o fator fixo TRAT, há efeito significativo, logo há algum tratamento que difere dos demais. Para o fator BLOCO, não houve efeito já que não há diferença significativa entre eles.\n\n\n\nPressuposições da ANOVA\n\ncheck_normality(aov_prod)\n\nOK: residuals appear as normally distributed (p = 0.542).\n\ncheck_heteroscedasticity(aov_prod)\n\nOK: Error variance appears to be homoscedastic (p = 0.215).\n\n\nOs testes mostram que os resíduos são normalmente distribuídos e que há homogeneidade de variâncias entre os grupos. Assim, é possível proceder a comparação de médias.\n\n\nComparação de médias\n\nmedias_prod &lt;- emmeans(aov_prod, ~ TRAT)\nmedias_prod\n\n TRAT emmean  SE df lower.CL upper.CL\n 1      4219 201 21     3800     4638\n 2      4935 201 21     4516     5354\n 3      5110 201 21     4691     5529\n 4      5140 201 21     4721     5559\n 5      5122 201 21     4703     5541\n 6      5256 201 21     4837     5675\n 7      5128 201 21     4709     5546\n 8      5078 201 21     4659     5497\n\nResults are averaged over the levels of: BLOCO \nConfidence level used: 0.95 \n\n\n\ndf_prod_grupo &lt;- cld (medias_prod, Letters = LETTERS)\ndf_prod_grupo\n\n TRAT emmean  SE df lower.CL upper.CL .group\n 1      4219 201 21     3800     4638  A    \n 2      4935 201 21     4516     5354  AB   \n 8      5078 201 21     4659     5497  AB   \n 3      5110 201 21     4691     5529  AB   \n 5      5122 201 21     4703     5541  AB   \n 7      5128 201 21     4709     5546  AB   \n 4      5140 201 21     4721     5559  AB   \n 6      5256 201 21     4837     5675   B   \n\nResults are averaged over the levels of: BLOCO \nConfidence level used: 0.95 \nP value adjustment: tukey method for comparing a family of 8 estimates \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\n\nGráfico com médias e intervalo de confiança, uma maneira visual de apresentar os resultados.\n\ndf_prod &lt;- data.frame(medias_prod)\ndf_prod %&gt;% \n  ggplot(aes(TRAT, emmean))+\n  geom_point()+\n  ylim (3000, 6600)+\n  geom_errorbar(aes(min = lower.CL,\n                    max = upper.CL),\n                    width = 0.1)+\n  annotate(geom = \"text\", \n           x = 1.2, \n           y = 4200, \n           label = \"A\")+\n  annotate(geom = \"text\", \n           x = 2.2, \n           y = 4950, \n           label = \"AB\")+\n  annotate(geom = \"text\", \n           x = 3.2, \n           y = 5100, \n           label = \"AB\")\n\n\n\n\n\n\n\n\nA anotação das letras, deve ser feita manualmente com a função annotate.\n\n\n\nExportando os dados\nTambém é possível exportar a tabela de comparação de médias com a função write_xlsx (writexl).\n\nknitr::kable(df_prod_grupo %&gt;% \n               dplyr::select(TRAT, emmean, .group))\n\n\n\n\n\nTRAT\nemmean\n.group\n\n\n\n\n1\n1\n4219.25\nA\n\n\n2\n2\n4935.00\nAB\n\n\n8\n8\n5078.25\nAB\n\n\n3\n3\n5110.00\nAB\n\n\n5\n5\n5122.00\nAB\n\n\n7\n7\n5127.50\nAB\n\n\n4\n4\n5140.25\nAB\n\n\n6\n6\n5256.25\nB\n\n\n\n\nlibrary(writexl)\nwrite_xlsx(df_prod, \"df.xlsx\")",
    "crumbs": [
      "Home",
      "Aula 08",
      "Estatística inferencial - Experimento em DBC"
    ]
  },
  {
    "objectID": "Aula 9.1.html",
    "href": "Aula 9.1.html",
    "title": "Aula 09 - Estatística inferencial - Experimento em parcelas subdivididas",
    "section": "",
    "text": "library(gsheet)\nlibrary(tidyverse)\nlibrary(lme4)\nlibrary(car)\nlibrary(performance)\nlibrary(DHARMa)\nlibrary(emmeans)\nlibrary(multcomp)\nlibrary(multcompView)\nlibrary(patchwork)\nlibrary(r4pde)",
    "crumbs": [
      "Home",
      "Aula 09",
      "Estatística inferencial - Experimento em parcelas subdivididas"
    ]
  },
  {
    "objectID": "Aula 9.1.html#carregando-os-pacotes",
    "href": "Aula 9.1.html#carregando-os-pacotes",
    "title": "Aula 09 - Estatística inferencial - Experimento em parcelas subdivididas",
    "section": "",
    "text": "library(gsheet)\nlibrary(tidyverse)\nlibrary(lme4)\nlibrary(car)\nlibrary(performance)\nlibrary(DHARMa)\nlibrary(emmeans)\nlibrary(multcomp)\nlibrary(multcompView)\nlibrary(patchwork)\nlibrary(r4pde)",
    "crumbs": [
      "Home",
      "Aula 09",
      "Estatística inferencial - Experimento em parcelas subdivididas"
    ]
  },
  {
    "objectID": "Aula 9.1.html#análise-de-um-experimento-em-parcelas-subdivididas",
    "href": "Aula 9.1.html#análise-de-um-experimento-em-parcelas-subdivididas",
    "title": "Aula 09 - Estatística inferencial - Experimento em parcelas subdivididas",
    "section": "Análise de um experimento em parcelas subdivididas",
    "text": "Análise de um experimento em parcelas subdivididas\nExperimentos em parcelas subdivididas são utilizados quando o nível de um fator primário (ou tratamento) é aplicado a uma parcela relativamente grande e todos os níveis de um segundo fator secundário são aplicados às subparcelas desta parcela maior. Os tratamentos primários são distribuídos às parcelas de acordo com um delineamento especificado, já os tratamentos secundários são distribuídos às subparcelas de forma aleatória.",
    "crumbs": [
      "Home",
      "Aula 09",
      "Estatística inferencial - Experimento em parcelas subdivididas"
    ]
  },
  {
    "objectID": "Aula 9.1.html#importando-os-dados",
    "href": "Aula 9.1.html#importando-os-dados",
    "title": "Aula 09 - Estatística inferencial - Experimento em parcelas subdivididas",
    "section": "Importando os dados",
    "text": "Importando os dados\nPara exemplificar a análise de um experimento em parcelas subdivididas, será utilizado um conjunto de dados onde o objetivo foi avaliar o índice de doença e produtividade de híbridos de milho (fator primário) ao serem submetidos a dois métodos de inoculação (fator secundário). Um esboço desse arranjo experimental é apresentado abaixo.\n\n\n\nExperimento em parcelas subdivididas.\n\n\n\nmilho &lt;- gsheet::gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=1345524759\")\n\n\nglimpse(milho)\n\nRows: 48\nColumns: 5\n$ hybrid &lt;chr&gt; \"30F53 HX\", \"30F53 HX\", \"30F53 HX\", \"30F53 HX\", \"30F53 YH\", \"30…\n$ block  &lt;dbl&gt; 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, …\n$ method &lt;chr&gt; \"pin\", \"pin\", \"pin\", \"pin\", \"pin\", \"pin\", \"pin\", \"pin\", \"pin\", …\n$ index  &lt;dbl&gt; 21.1, 21.1, 23.3, 35.6, 21.1, 22.2, 27.3, 27.8, 20.0, 20.0, 27.…\n$ yield  &lt;dbl&gt; 12920, 9870, 8920, 13120, 12060, 7860, 7410, 10300, 11700, 1070…",
    "crumbs": [
      "Home",
      "Aula 09",
      "Estatística inferencial - Experimento em parcelas subdivididas"
    ]
  },
  {
    "objectID": "Aula 9.1.html#visualização-gráfica",
    "href": "Aula 9.1.html#visualização-gráfica",
    "title": "Aula 09 - Estatística inferencial - Experimento em parcelas subdivididas",
    "section": "Visualização gráfica",
    "text": "Visualização gráfica\n\nÍndice de doença\nPara visualização dos dados relacionados ao índice de doença e o método de inoculação será construído um gráfico de pontos (geom_jitter) acrescido do intervalo de confiança (stat_summary(fund.data = \"mean_cl_boot\"). Para gerar uma figura com os gráficos individuais de cada tratamento é utilizada a função facet_wrap.\n\nmilho %&gt;% \n  ggplot(aes(method, index))+\n  geom_jitter(color = \"darkred\", width = 0.1, alpha = 0.4)+\n  stat_summary(fund.data = \"mean_cl_boot\", color = \"black\", width = 0.5)+\n  facet_wrap (~hybrid)\n\n\n\n\n\n\n\n\n\n\nProdutividade\nPara os dados relacionados à produtividade e o método de inoculação será construído um gráfico de similar ao anterior.\n\nmilho %&gt;% \n  ggplot(aes(method, yield))+\n  geom_jitter(color = \"darkred\", width = 0.1, alpha = 0.4)+\n  stat_summary(fund.data = \"mean_cl_boot\", color = \"black\", width = 0.5)+\n  facet_wrap (~hybrid)",
    "crumbs": [
      "Home",
      "Aula 09",
      "Estatística inferencial - Experimento em parcelas subdivididas"
    ]
  },
  {
    "objectID": "Aula 9.1.html#análise-de-experimentos-em-parcelas-subdivididas",
    "href": "Aula 9.1.html#análise-de-experimentos-em-parcelas-subdivididas",
    "title": "Aula 09 - Estatística inferencial - Experimento em parcelas subdivididas",
    "section": "Análise de experimentos em parcelas subdivididas",
    "text": "Análise de experimentos em parcelas subdivididas",
    "crumbs": [
      "Home",
      "Aula 09",
      "Estatística inferencial - Experimento em parcelas subdivididas"
    ]
  },
  {
    "objectID": "Aula 9.1.html#índice-de-doença-index",
    "href": "Aula 9.1.html#índice-de-doença-index",
    "title": "Aula 09 - Estatística inferencial - Experimento em parcelas subdivididas",
    "section": "Índice de doença (index)",
    "text": "Índice de doença (index)\n\nConstrução do modelo\nAntes de definir o modelo, será preciso transformar a coluna de dados “block” para fator (funções mutate e as.factor).\n\nmilho &lt;- milho %&gt;% \n  mutate(block = as.factor(block))\n\nPara a análise dos dados, será construído um modelo linear de efeitos mistos com a função lmer (pacote lme4), onde definimos os fatores fixos e os fatores aleatórios.\n\nmix &lt;- lmer(index ~ hybrid*method + block + (1|block/hybrid),\n            data = milho)\n\n\n\nANOVA\n\nAnova(mix)\n\nAnalysis of Deviance Table (Type II Wald chisquare tests)\n\nResponse: index\n                Chisq Df Pr(&gt;Chisq)   \nhybrid        15.5971  5   0.008094 **\nmethod         4.6963  1   0.030228 * \nblock          0.2157  3   0.975023   \nhybrid:method 15.8060  5   0.007420 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nA análise de variância demonstra que há interação entre os fatores (hybrid:method). Assim seria preciso realizar os desdobramentos e comparar híbridos dentro de métodos e métodos dentro de híbridos. Mas antes, é preciso conferir se os dados atendem às pressuposições da ANOVA.\n\n\nAvaliação das premissas\n\ncheck_normality(mix)\n\nOK: residuals appear as normally distributed (p = 0.635).\n\ncheck_heteroscedasticity(mix)\n\nWarning: Heteroscedasticity (non-constant error variance) detected (p = 0.009).\n\n\n\nplot(simulateResiduals(mix))\n\n\n\n\n\n\n\n\nCom as análises acima, conclui-se que os dados seguem distribuição normal. Porém, não há homogeneidade de variância entre os grupos. Logo será preciso uma alternativa para prosseguir a análise, por exemplo a transformação dos dados com raiz quadrada.\n\n\nTransformação dos dados - Raiz quadrada\n\nmix2 &lt;- lmer(sqrt(index) ~ hybrid*method + block + (1|block/hybrid),\n            data = milho)\n\n\nANOVA - Dados transformados\n\nanova(mix2)\n\nAnalysis of Variance Table\n              npar  Sum Sq Mean Sq F value\nhybrid           5 2.14415 0.42883  3.0632\nmethod           1 0.54438 0.54438  3.8886\nblock            3 0.01004 0.00335  0.0239\nhybrid:method    5 1.87331 0.37466  2.6762\n\n\n\n\nAvaliação das premissas - Dados transformados\nCom as funções check_normality e check_heteroscedasticity (pacote Performance):\n\ncheck_normality(mix2)\n\nOK: residuals appear as normally distributed (p = 0.440).\n\ncheck_heteroscedasticity(mix2)\n\nOK: Error variance appears to be homoscedastic (p = 0.971).\n\n\nAtravés de um gráfico Q-Q (funções qqnorm e qqline):\n\nqqnorm(residuals(mix2))\nqqline(residuals(mix2))\n\n\n\n\n\n\n\n\nCom a função simulateResiduals (pacote DHARMa):\n\nplot(simulateResiduals(mix2))\n\n\n\n\n\n\n\n\nApesar da análise via DHARMa ter apresentado problemas, as demais avaliações (via Performance e QQ-Plot) se mostraram favoráveis, logo é possível prosseguir para a comparação de médias.\n\n\nComparação de médias - Dados transformados\nComo visto pela ANOVA, há efeito de interação, logo será preciso realizar desdobramentos para as comparações:\n\nHíbridos dentro de métodos:\n\nindex &lt;- emmeans(mix2, ~hybrid | method,\n                 type = \"response\")\n\ncld(index, Letters = LETTERS)\n\nmethod = pin:\n hybrid   response   SE   df lower.CL upper.CL .group\n BG7049H      19.4 10.7 6084     4.10     46.0  A    \n 30K64        20.3 10.9 6084     4.51     47.4  A    \n 30F53 YH     24.5 12.0 6084     6.61     53.7  AB   \n 30F53 HX     25.0 12.1 6084     6.84     54.4  AB   \n 30S31YH      31.7 13.7 6084    10.57     64.2  AB   \n 30S31H       37.1 14.8 6084    13.79     71.8   B   \n\nmethod = silk:\n hybrid   response   SE   df lower.CL upper.CL .group\n BG7049H      19.1 10.6 6084     3.96     45.6  A    \n 30K64        21.3 11.2 6084     5.00     48.9  A    \n 30F53 HX     24.4 12.0 6084     6.56     53.6  A    \n 30F53 YH     26.0 12.4 6084     7.42     56.0  A    \n 30S31H       26.3 12.5 6084     7.57     56.4  A    \n 30S31YH      26.4 12.5 6084     7.62     56.5  A    \n\nResults are averaged over the levels of: block \nDegrees-of-freedom method: kenward-roger \nConfidence level used: 0.95 \nIntervals are back-transformed from the sqrt scale \nNote: contrasts are still on the sqrt scale \nP value adjustment: tukey method for comparing a family of 6 estimates \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\n\n\n\nMétodos dentro de híbridos\n\nindex2 &lt;- emmeans(mix2, ~method | hybrid,\n                  type = \"response\")\n\ncld(index2, Letters = letters)\n\nhybrid = 30F53 HX:\n method response   SE   df lower.CL upper.CL .group\n silk       24.4 12.0 6084     6.56     53.6  a    \n pin        25.0 12.1 6084     6.84     54.4  a    \n\nhybrid = 30F53 YH:\n method response   SE   df lower.CL upper.CL .group\n pin        24.5 12.0 6084     6.61     53.7  a    \n silk       26.0 12.4 6084     7.42     56.0  a    \n\nhybrid = 30K64:\n method response   SE   df lower.CL upper.CL .group\n pin        20.3 10.9 6084     4.51     47.4  a    \n silk       21.3 11.2 6084     5.00     48.9  a    \n\nhybrid = 30S31H:\n method response   SE   df lower.CL upper.CL .group\n silk       26.3 12.5 6084     7.57     56.4  a    \n pin        37.1 14.8 6084    13.79     71.8   b   \n\nhybrid = 30S31YH:\n method response   SE   df lower.CL upper.CL .group\n silk       26.4 12.5 6084     7.62     56.5  a    \n pin        31.7 13.7 6084    10.57     64.2  a    \n\nhybrid = BG7049H:\n method response   SE   df lower.CL upper.CL .group\n silk       19.1 10.6 6084     3.96     45.6  a    \n pin        19.4 10.7 6084     4.10     46.0  a    \n\nResults are averaged over the levels of: block \nDegrees-of-freedom method: kenward-roger \nConfidence level used: 0.95 \nIntervals are back-transformed from the sqrt scale \nNote: contrasts are still on the sqrt scale \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same.",
    "crumbs": [
      "Home",
      "Aula 09",
      "Estatística inferencial - Experimento em parcelas subdivididas"
    ]
  },
  {
    "objectID": "Aula 9.1.html#produtividade-yield",
    "href": "Aula 9.1.html#produtividade-yield",
    "title": "Aula 09 - Estatística inferencial - Experimento em parcelas subdivididas",
    "section": "Produtividade (yield)",
    "text": "Produtividade (yield)\nSeguindo os mesmos procedimentos para o índice de doença, será conduzida avaliação da produtividade.\n\nConstrução do modelo\n\nmix3 &lt;- lmer(yield ~ hybrid*method + block + (1|block/hybrid),\n            data = milho)\n\n\n\nANOVA\n\nAnova(mix3)\n\nAnalysis of Deviance Table (Type II Wald chisquare tests)\n\nResponse: yield\n                Chisq Df Pr(&gt;Chisq)    \nhybrid        25.5991  5  0.0001067 ***\nmethod         0.1052  1  0.7456934    \nblock          2.3564  3  0.5018078    \nhybrid:method 25.9302  5  9.206e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\nAvaliação das premissas\n\ncheck_normality(mix3)\n\nOK: residuals appear as normally distributed (p = 0.211).\n\ncheck_heteroscedasticity(mix3)\n\nWarning: Heteroscedasticity (non-constant error variance) detected (p &lt; .001).\n\n\nA análise pelas funções check_normality e check_heteroscedasticity demonstram que os dados possuem normalidade na distribuição dos resíduos, no entanto, não há homogeneidade de variância entre os grupos. Portanto, também será preciso realizar transformação.\n\nTransformação dos dados - Raiz quadrada\n\nmix4 &lt;- lmer(sqrt(yield) ~ hybrid*method + block + (1|block/hybrid),\n            data = milho)\n\n\n\nANOVA - Dados transformados\n\nanova(mix4)\n\nAnalysis of Variance Table\n              npar  Sum Sq Mean Sq F value\nhybrid           5 272.298  54.460  5.1118\nmethod           1   0.554   0.554  0.0520\nblock            3  25.150   8.383  0.7869\nhybrid:method    5 260.999  52.200  4.8997\n\n\n\n\nAvaliação das premissas - Dados transformados\n\ncheck_normality(mix4)\n\nOK: residuals appear as normally distributed (p = 0.214).\n\ncheck_heteroscedasticity(mix4)\n\nOK: Error variance appears to be homoscedastic (p = 0.686).\n\n\n\n\nComparação de médias - Dados transformados\n\nHíbridos dentro de métodos:\n\nyield &lt;- emmeans(mix4, ~ hybrid | method,\n                 type = \"response\")\ncld(index, Letters = LETTERS)\n\nmethod = pin:\n hybrid   response   SE   df lower.CL upper.CL .group\n BG7049H      19.4 10.7 6084     4.10     46.0  A    \n 30K64        20.3 10.9 6084     4.51     47.4  A    \n 30F53 YH     24.5 12.0 6084     6.61     53.7  AB   \n 30F53 HX     25.0 12.1 6084     6.84     54.4  AB   \n 30S31YH      31.7 13.7 6084    10.57     64.2  AB   \n 30S31H       37.1 14.8 6084    13.79     71.8   B   \n\nmethod = silk:\n hybrid   response   SE   df lower.CL upper.CL .group\n BG7049H      19.1 10.6 6084     3.96     45.6  A    \n 30K64        21.3 11.2 6084     5.00     48.9  A    \n 30F53 HX     24.4 12.0 6084     6.56     53.6  A    \n 30F53 YH     26.0 12.4 6084     7.42     56.0  A    \n 30S31H       26.3 12.5 6084     7.57     56.4  A    \n 30S31YH      26.4 12.5 6084     7.62     56.5  A    \n\nResults are averaged over the levels of: block \nDegrees-of-freedom method: kenward-roger \nConfidence level used: 0.95 \nIntervals are back-transformed from the sqrt scale \nNote: contrasts are still on the sqrt scale \nP value adjustment: tukey method for comparing a family of 6 estimates \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\n\n\n\nMétodos dentro de híbridos\n\nyield2 &lt;- emmeans(mix4, ~ method | hybrid,\n                  type = \"response\")\ncld(index2, Letters = letters)\n\nhybrid = 30F53 HX:\n method response   SE   df lower.CL upper.CL .group\n silk       24.4 12.0 6084     6.56     53.6  a    \n pin        25.0 12.1 6084     6.84     54.4  a    \n\nhybrid = 30F53 YH:\n method response   SE   df lower.CL upper.CL .group\n pin        24.5 12.0 6084     6.61     53.7  a    \n silk       26.0 12.4 6084     7.42     56.0  a    \n\nhybrid = 30K64:\n method response   SE   df lower.CL upper.CL .group\n pin        20.3 10.9 6084     4.51     47.4  a    \n silk       21.3 11.2 6084     5.00     48.9  a    \n\nhybrid = 30S31H:\n method response   SE   df lower.CL upper.CL .group\n silk       26.3 12.5 6084     7.57     56.4  a    \n pin        37.1 14.8 6084    13.79     71.8   b   \n\nhybrid = 30S31YH:\n method response   SE   df lower.CL upper.CL .group\n silk       26.4 12.5 6084     7.62     56.5  a    \n pin        31.7 13.7 6084    10.57     64.2  a    \n\nhybrid = BG7049H:\n method response   SE   df lower.CL upper.CL .group\n silk       19.1 10.6 6084     3.96     45.6  a    \n pin        19.4 10.7 6084     4.10     46.0  a    \n\nResults are averaged over the levels of: block \nDegrees-of-freedom method: kenward-roger \nConfidence level used: 0.95 \nIntervals are back-transformed from the sqrt scale \nNote: contrasts are still on the sqrt scale \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same.",
    "crumbs": [
      "Home",
      "Aula 09",
      "Estatística inferencial - Experimento em parcelas subdivididas"
    ]
  },
  {
    "objectID": "Aula 9.3.html",
    "href": "Aula 9.3.html",
    "title": "Aula 09 - Estatística inferencial - Análise de múltiplos ensaios",
    "section": "",
    "text": "Ao trabalhar com múltiplos ensaios, é possível analisá-los individualmente para observar uma tendência geral no comportamento dos tratamentos. No entanto, existem outras alternativas, como aplicar um modelo de regressão linear global ou extrair a informação global utilizando modelos mistos. Nesse caso, os ensaios são tratados como fator aleatório, ou seja, advêm de uma distribuição (população), e o objetivo é estimar os parâmetros para essa população.\nPara exemplificar esse caso, um conjunto de dados (WhiteMoldSoybean) presente no pacote r4pde será importado, mas antes o pacote deverá ser carregado.\n\nlibrary(r4pde)\n\nwm &lt;- WhiteMoldSoybean\n\n\n\nVisualização gráfica da produtividade em função da incidência, por ensaio:\n\nwm %&gt;% \n  ggplot (aes (inc, yld))+\n  geom_point()+\n  facet_wrap(~study)\n\n\n\n\n\n\n\n\n\n\n\nGráfico para visualizar os ensaios como um todo:\n\nwm %&gt;% \n  ggplot (aes (inc, yld))+\n  geom_point()+\n  geom_smooth(method = \"lm\")\n\n\n\n\n\n\n\n\nAjuste do modelo global:\n\nmofo1 &lt;- lm(yld ~ inc,\n            data = wm)\n\nCálculo dos parâmetros para todos os ensaios\n\nsummary(mofo1)\n\n\nCall:\nlm(formula = yld ~ inc, data = wm)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1657.85  -594.50   -91.32   531.76  1693.15 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 3299.619     56.451  58.451  &lt; 2e-16 ***\ninc           -9.261      2.108  -4.393 1.45e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 745.8 on 380 degrees of freedom\nMultiple R-squared:  0.04833,   Adjusted R-squared:  0.04582 \nF-statistic:  19.3 on 1 and 380 DF,  p-value: 1.452e-05\n\nAIC(mofo1)\n\n[1] 6141.545\n\n\nPelo modelo ajustado para todos os ensaios globalmente, obtém-se um intercepto no eixo y igual a 3299.619 e o coeficiente de inclinação da reta igual a - 9.261. Para esse modelo o valor de AIC foi de 6141.54.\n\n\n\nGráfico para visualizar os ensaios individualmente:\n\nwm %&gt;% \n  ggplot (aes (inc, yld, group = factor(study)))+\n  geom_point()+\n  geom_smooth(method = \"lm\", se = F)\n\n\n\n\n\n\n\n\nCálculo dos parâmetros para cada ensaio:\n\nlibrary(broom)\nmofo2 &lt;- wm %&gt;% \n  group_by(study) %&gt;% \n  do(broom::tidy(lm(.$yld ~ .$inc), conf.int=TRUE))\n\nmofo2\n\n# A tibble: 70 × 8\n# Groups:   study [35]\n   study term        estimate std.error statistic  p.value conf.low conf.high\n   &lt;dbl&gt; &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n 1     1 (Intercept)  3329.       86.8      38.3  4.60e-13   3138.    3520.  \n 2     1 .$inc         -14.2       2.08     -6.85 2.78e- 5    -18.8     -9.64\n 3     2 (Intercept)  2682.       48.6      55.2  8.55e-15   2575.    2789.  \n 4     2 .$inc          -6.93      1.49     -4.66 6.89e- 4    -10.2     -3.66\n 5     3 (Intercept)  4017.       61.6      65.2  1.37e-15   3882.    4153.  \n 6     3 .$inc         -18.6       1.71    -10.9  3.11e- 7    -22.4    -14.9 \n 7     4 (Intercept)  2814.      151.       18.6  1.15e- 9   2481.    3147.  \n 8     4 .$inc         -43.5      16.8      -2.58 2.56e- 2    -80.5     -6.38\n 9     5 (Intercept)  3317.      234.       14.2  2.07e- 8   2802.    3832.  \n10     5 .$inc         -21.2       5.69     -3.72 3.36e- 3    -33.7     -8.67\n# ℹ 60 more rows\n\n\nApós calcular os parâmetros para cada ensaio, é possível obter as suas médias. Para isso, existem dois caminhos.\n\nOpção 1:\n\n\ndf &lt;- mofo2 %&gt;% filter(term == \".$inc\")\nmean(df$estimate)\n\n[1] -19.52932\n\n\n\ny0 &lt;- mofo2 %&gt;% filter(term == \"(Intercept)\")\nmean(y0$estimate)\n\n[1] 3482.303\n\n\n\nOpção 2:\n\n\nmofo2 |&gt; \n  filter(term == \".$inc\") |&gt;\n  ungroup() |&gt; \n  dplyr::select(estimate) |&gt; \n  summary()\n\n    estimate      \n Min.   :-43.455  \n 1st Qu.:-27.676  \n Median :-16.926  \n Mean   :-19.529  \n 3rd Qu.:-13.054  \n Max.   :  2.712  \n\n\n\nmofo2 %&gt;% \n  filter(term == \"(Intercept)\")  %&gt;% \n  ungroup() %&gt;% \n  dplyr::select(estimate) %&gt;% \n  summary()\n\n    estimate   \n Min.   :1760  \n 1st Qu.:2863  \n Median :3329  \n Mean   :3482  \n 3rd Qu.:4080  \n Max.   :4923  \n\n\nPela média dos modelos ajustados para casa ensaio, obtém-se um intercepto no eixo y igual a 3482.303 e o coeficiente de inclinação da reta igual a - 19.529.\nTambém é possível construir histogramas para cada um dos parâmetros.\n\np1 &lt;- mofo2 %&gt;% \n  filter(term == \"(Intercept)\") %&gt;% \n  ggplot(aes(x = estimate))+\n  geom_histogram(bins = 8, color = \"white\", fill = \"gray50\")+\n  theme_r4pde()+\n  labs( x = \"Intercept\",\n        y = \"Frequency\")\n\np1\n\n\n\n\n\n\n\n\n\np2 &lt;- mofo2 %&gt;% \n  filter(term == \".$inc\") %&gt;%  \n  ggplot(aes(x = estimate))+\n  geom_histogram(bins = 8, color = \"white\", fill = \"gray50\")+\n  theme_r4pde()+\n  labs(x = \"Slope\", y = \"Frequency\")\n\np2\n\n\n\n\n\n\n\n\n\nlibrary(patchwork)\n(p1+p2)\n\n\n\n\n\n\n\n\n\n\n\nConstrução do modelo:\n\nlibrary(lme4)\n\nmofo3 &lt;- lmer(yld ~ inc + (inc | study), data = wm,\n              REML = F)\n\nCálculo dos parâmetros:\n\nsummary(mofo3)\n\nLinear mixed model fit by maximum likelihood  ['lmerMod']\nFormula: yld ~ inc + (inc | study)\n   Data: wm\n\n     AIC      BIC   logLik deviance df.resid \n  5319.4   5343.1  -2653.7   5307.4      376 \n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-3.7078 -0.5991 -0.0295  0.5077  3.2364 \n\nRandom effects:\n Groups   Name        Variance  Std.Dev. Corr \n study    (Intercept) 557573.08 746.708       \n          inc             36.85   6.071  -0.29\n Residual              37228.73 192.947       \nNumber of obs: 382, groups:  study, 35\n\nFixed effects:\n            Estimate Std. Error t value\n(Intercept) 3455.432    128.063   26.98\ninc          -17.236      1.451  -11.88\n\nCorrelation of Fixed Effects:\n    (Intr)\ninc -0.300\noptimizer (nloptwrap) convergence code: 0 (OK)\nModel failed to converge with max|grad| = 0.416806 (tol = 0.002, component 1)\n\nAIC(mofo3)\n\n[1] 5319.403\n\n\nPelos resultados obtidos acima, observa-se que o intercepto no eixo y foi igual a 3455.432 e o coeficiente de inclinação da reta foi igual a - 17.236. Para o modelo linear misto, o AIC foi igual a 5319.403.\n\nCálculo dos intervalos de confiança, para o intercepto e coeficiente de inclinação da reta:\n\nconfint(mofo3, method = \"Wald\")\n\n                 2.5 %     97.5 %\n.sig01              NA         NA\n.sig02              NA         NA\n.sig03              NA         NA\n.sigma              NA         NA\n(Intercept) 3204.43403 3706.43096\ninc          -20.08046  -14.39219\n\n\n\nAo comparar os modelos gerados, nota-se que os valores dos parâmetros são bem próximos. No entanto, ao comparar os valores de AIC, o menor valor é obtido para o modelo linear misto, sugerindo que este método se ajusta melhor aos dados do exemplo.",
    "crumbs": [
      "Home",
      "Aula 09",
      "Estatística inferencial - Análise de múltiplos ensaios"
    ]
  },
  {
    "objectID": "Aula 9.3.html#análise-de-múltiplos-ensaios",
    "href": "Aula 9.3.html#análise-de-múltiplos-ensaios",
    "title": "Aula 09 - Estatística inferencial - Análise de múltiplos ensaios",
    "section": "",
    "text": "Ao trabalhar com múltiplos ensaios, é possível analisá-los individualmente para observar uma tendência geral no comportamento dos tratamentos. No entanto, existem outras alternativas, como aplicar um modelo de regressão linear global ou extrair a informação global utilizando modelos mistos. Nesse caso, os ensaios são tratados como fator aleatório, ou seja, advêm de uma distribuição (população), e o objetivo é estimar os parâmetros para essa população.\nPara exemplificar esse caso, um conjunto de dados (WhiteMoldSoybean) presente no pacote r4pde será importado, mas antes o pacote deverá ser carregado.\n\nlibrary(r4pde)\n\nwm &lt;- WhiteMoldSoybean\n\n\n\nVisualização gráfica da produtividade em função da incidência, por ensaio:\n\nwm %&gt;% \n  ggplot (aes (inc, yld))+\n  geom_point()+\n  facet_wrap(~study)\n\n\n\n\n\n\n\n\n\n\n\nGráfico para visualizar os ensaios como um todo:\n\nwm %&gt;% \n  ggplot (aes (inc, yld))+\n  geom_point()+\n  geom_smooth(method = \"lm\")\n\n\n\n\n\n\n\n\nAjuste do modelo global:\n\nmofo1 &lt;- lm(yld ~ inc,\n            data = wm)\n\nCálculo dos parâmetros para todos os ensaios\n\nsummary(mofo1)\n\n\nCall:\nlm(formula = yld ~ inc, data = wm)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1657.85  -594.50   -91.32   531.76  1693.15 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 3299.619     56.451  58.451  &lt; 2e-16 ***\ninc           -9.261      2.108  -4.393 1.45e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 745.8 on 380 degrees of freedom\nMultiple R-squared:  0.04833,   Adjusted R-squared:  0.04582 \nF-statistic:  19.3 on 1 and 380 DF,  p-value: 1.452e-05\n\nAIC(mofo1)\n\n[1] 6141.545\n\n\nPelo modelo ajustado para todos os ensaios globalmente, obtém-se um intercepto no eixo y igual a 3299.619 e o coeficiente de inclinação da reta igual a - 9.261. Para esse modelo o valor de AIC foi de 6141.54.\n\n\n\nGráfico para visualizar os ensaios individualmente:\n\nwm %&gt;% \n  ggplot (aes (inc, yld, group = factor(study)))+\n  geom_point()+\n  geom_smooth(method = \"lm\", se = F)\n\n\n\n\n\n\n\n\nCálculo dos parâmetros para cada ensaio:\n\nlibrary(broom)\nmofo2 &lt;- wm %&gt;% \n  group_by(study) %&gt;% \n  do(broom::tidy(lm(.$yld ~ .$inc), conf.int=TRUE))\n\nmofo2\n\n# A tibble: 70 × 8\n# Groups:   study [35]\n   study term        estimate std.error statistic  p.value conf.low conf.high\n   &lt;dbl&gt; &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n 1     1 (Intercept)  3329.       86.8      38.3  4.60e-13   3138.    3520.  \n 2     1 .$inc         -14.2       2.08     -6.85 2.78e- 5    -18.8     -9.64\n 3     2 (Intercept)  2682.       48.6      55.2  8.55e-15   2575.    2789.  \n 4     2 .$inc          -6.93      1.49     -4.66 6.89e- 4    -10.2     -3.66\n 5     3 (Intercept)  4017.       61.6      65.2  1.37e-15   3882.    4153.  \n 6     3 .$inc         -18.6       1.71    -10.9  3.11e- 7    -22.4    -14.9 \n 7     4 (Intercept)  2814.      151.       18.6  1.15e- 9   2481.    3147.  \n 8     4 .$inc         -43.5      16.8      -2.58 2.56e- 2    -80.5     -6.38\n 9     5 (Intercept)  3317.      234.       14.2  2.07e- 8   2802.    3832.  \n10     5 .$inc         -21.2       5.69     -3.72 3.36e- 3    -33.7     -8.67\n# ℹ 60 more rows\n\n\nApós calcular os parâmetros para cada ensaio, é possível obter as suas médias. Para isso, existem dois caminhos.\n\nOpção 1:\n\n\ndf &lt;- mofo2 %&gt;% filter(term == \".$inc\")\nmean(df$estimate)\n\n[1] -19.52932\n\n\n\ny0 &lt;- mofo2 %&gt;% filter(term == \"(Intercept)\")\nmean(y0$estimate)\n\n[1] 3482.303\n\n\n\nOpção 2:\n\n\nmofo2 |&gt; \n  filter(term == \".$inc\") |&gt;\n  ungroup() |&gt; \n  dplyr::select(estimate) |&gt; \n  summary()\n\n    estimate      \n Min.   :-43.455  \n 1st Qu.:-27.676  \n Median :-16.926  \n Mean   :-19.529  \n 3rd Qu.:-13.054  \n Max.   :  2.712  \n\n\n\nmofo2 %&gt;% \n  filter(term == \"(Intercept)\")  %&gt;% \n  ungroup() %&gt;% \n  dplyr::select(estimate) %&gt;% \n  summary()\n\n    estimate   \n Min.   :1760  \n 1st Qu.:2863  \n Median :3329  \n Mean   :3482  \n 3rd Qu.:4080  \n Max.   :4923  \n\n\nPela média dos modelos ajustados para casa ensaio, obtém-se um intercepto no eixo y igual a 3482.303 e o coeficiente de inclinação da reta igual a - 19.529.\nTambém é possível construir histogramas para cada um dos parâmetros.\n\np1 &lt;- mofo2 %&gt;% \n  filter(term == \"(Intercept)\") %&gt;% \n  ggplot(aes(x = estimate))+\n  geom_histogram(bins = 8, color = \"white\", fill = \"gray50\")+\n  theme_r4pde()+\n  labs( x = \"Intercept\",\n        y = \"Frequency\")\n\np1\n\n\n\n\n\n\n\n\n\np2 &lt;- mofo2 %&gt;% \n  filter(term == \".$inc\") %&gt;%  \n  ggplot(aes(x = estimate))+\n  geom_histogram(bins = 8, color = \"white\", fill = \"gray50\")+\n  theme_r4pde()+\n  labs(x = \"Slope\", y = \"Frequency\")\n\np2\n\n\n\n\n\n\n\n\n\nlibrary(patchwork)\n(p1+p2)\n\n\n\n\n\n\n\n\n\n\n\nConstrução do modelo:\n\nlibrary(lme4)\n\nmofo3 &lt;- lmer(yld ~ inc + (inc | study), data = wm,\n              REML = F)\n\nCálculo dos parâmetros:\n\nsummary(mofo3)\n\nLinear mixed model fit by maximum likelihood  ['lmerMod']\nFormula: yld ~ inc + (inc | study)\n   Data: wm\n\n     AIC      BIC   logLik deviance df.resid \n  5319.4   5343.1  -2653.7   5307.4      376 \n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-3.7078 -0.5991 -0.0295  0.5077  3.2364 \n\nRandom effects:\n Groups   Name        Variance  Std.Dev. Corr \n study    (Intercept) 557573.08 746.708       \n          inc             36.85   6.071  -0.29\n Residual              37228.73 192.947       \nNumber of obs: 382, groups:  study, 35\n\nFixed effects:\n            Estimate Std. Error t value\n(Intercept) 3455.432    128.063   26.98\ninc          -17.236      1.451  -11.88\n\nCorrelation of Fixed Effects:\n    (Intr)\ninc -0.300\noptimizer (nloptwrap) convergence code: 0 (OK)\nModel failed to converge with max|grad| = 0.416806 (tol = 0.002, component 1)\n\nAIC(mofo3)\n\n[1] 5319.403\n\n\nPelos resultados obtidos acima, observa-se que o intercepto no eixo y foi igual a 3455.432 e o coeficiente de inclinação da reta foi igual a - 17.236. Para o modelo linear misto, o AIC foi igual a 5319.403.\n\nCálculo dos intervalos de confiança, para o intercepto e coeficiente de inclinação da reta:\n\nconfint(mofo3, method = \"Wald\")\n\n                 2.5 %     97.5 %\n.sig01              NA         NA\n.sig02              NA         NA\n.sig03              NA         NA\n.sigma              NA         NA\n(Intercept) 3204.43403 3706.43096\ninc          -20.08046  -14.39219\n\n\n\nAo comparar os modelos gerados, nota-se que os valores dos parâmetros são bem próximos. No entanto, ao comparar os valores de AIC, o menor valor é obtido para o modelo linear misto, sugerindo que este método se ajusta melhor aos dados do exemplo.",
    "crumbs": [
      "Home",
      "Aula 09",
      "Estatística inferencial - Análise de múltiplos ensaios"
    ]
  }
]