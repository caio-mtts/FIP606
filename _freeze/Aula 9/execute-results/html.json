{
  "hash": "6c37fd5351da5f742c7ea893953d06b3",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Aula 9\"\nauthor: \"Caio\"\nformat: html\neditor: visual\nexecute: \n  error: false\n  warning: false\n---\n\n\n# Aula 9\n\n## Carregando pacotes\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(gsheet)\nlibrary(tidyverse)\nlibrary(lme4)\nlibrary(car)\nlibrary(performance)\nlibrary(DHARMa)\nlibrary(emmeans)\nlibrary(multcomp)\nlibrary(multcompView)\nlibrary(patchwork)\nlibrary(r4pde)\n```\n:::\n\n\n## Análise de um experimento em parcelas subdivididas\n\nExperimentos em parcelas subdivididas são utilizados quando o nível de um fator primário (ou tratamento) é aplicado a uma parcela relativamente grande e todos os níveis de um segundo fator secundário são aplicados às subparcelas desta parcela maior. Os tratamentos primários são distribuídos às parcelas de acordo com um delineamento especificado, já os tratamentos secundários são distribuídos às subparcelas de forma aleatória.\\\n\n## Importando os dados\n\nPara exemplificar a análise de um experimento em parcelas subdivididas, será utilizado um conjunto de dados onde o objetivo foi avaliar o índice de doença e produtividade de híbridos de milho (fator primário) ao serem submetidos a dois métodos de inoculação (fator secundário). Um esboço desse arranjo experimental é apresentado abaixo.\n\n![Experimento em parcelas subdivididas.](Imagem1.png){width=\"1650\"}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmilho <- gsheet::gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=1345524759\")\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nglimpse(milho)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 48\nColumns: 5\n$ hybrid <chr> \"30F53 HX\", \"30F53 HX\", \"30F53 HX\", \"30F53 HX\", \"30F53 YH\", \"30…\n$ block  <dbl> 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, …\n$ method <chr> \"pin\", \"pin\", \"pin\", \"pin\", \"pin\", \"pin\", \"pin\", \"pin\", \"pin\", …\n$ index  <dbl> 21.1, 21.1, 23.3, 35.6, 21.1, 22.2, 27.3, 27.8, 20.0, 20.0, 27.…\n$ yield  <dbl> 12920, 9870, 8920, 13120, 12060, 7860, 7410, 10300, 11700, 1070…\n```\n\n\n:::\n:::\n\n\n## Visualização gráfica\n\n### Índice de doença\n\nPara visualização dos dados relacionados ao índice de doença e o método de inoculação será construído um gráfico de pontos (`geom_jitter`) acrescido do intervalo de confiança (`stat_summary(fund.data = \"mean_cl_boot\"`). Para gerar uma figura com os gráficos individuais de cada tratamento é utilizada a função `facet_wrap`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmilho %>% \n  ggplot(aes(method, index))+\n  geom_jitter(color = \"darkred\", width = 0.1, alpha = 0.4)+\n  stat_summary(fund.data = \"mean_cl_boot\", color = \"black\", width = 0.5)+\n  facet_wrap (~hybrid)\n```\n\n::: {.cell-output-display}\n![](Aula-9_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n:::\n\n\n### Produtividade\n\nPara os dados relacionados à produtividade e o método de inoculação será construído um gráfico de similar ao anterior.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmilho %>% \n  ggplot(aes(method, yield))+\n  geom_jitter(color = \"darkred\", width = 0.1, alpha = 0.4)+\n  stat_summary(fund.data = \"mean_cl_boot\", color = \"black\", width = 0.5)+\n  facet_wrap (~hybrid)\n```\n\n::: {.cell-output-display}\n![](Aula-9_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n:::\n\n\n## Análise em parcelas subdivididas\n\n## Índice de doença (index)\n\n### Construção do modelo\n\nAntes de definir o modelo, será preciso transformar a coluna de dados \"block\" para fator (funções `mutate` e `as.factor`).\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmilho <- milho %>% \n  mutate(block = as.factor(block))\n```\n:::\n\n\nPara a análise dos dados, será construído um modelo linear de efeitos mistos com a função `lmer` (pacote **`lme4`**), onde definimos os fatores fixos e os fatores aleatórios.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmix <- lmer(index ~ hybrid*method + block + (1|block/hybrid),\n            data = milho)\n```\n:::\n\n\n### ANOVA\n\n\n::: {.cell}\n\n```{.r .cell-code}\nAnova(mix)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nAnalysis of Deviance Table (Type II Wald chisquare tests)\n\nResponse: index\n                Chisq Df Pr(>Chisq)   \nhybrid        15.5971  5   0.008094 **\nmethod         4.6963  1   0.030228 * \nblock          0.2157  3   0.975023   \nhybrid:method 15.8060  5   0.007420 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n:::\n\n\nA análise de variância demonstra que há interação entre os fatores (hybrid:method). Assim seria preciso realizar os desdobramentos e comparar híbridos dentro de métodos e métodos dentro de híbridos. Mas antes, é preciso conferir se os dados atendem às pressuposições da ANOVA.\n\n### Avaliação das premissas\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncheck_normality(mix)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nOK: residuals appear as normally distributed (p = 0.635).\n```\n\n\n:::\n\n```{.r .cell-code}\ncheck_heteroscedasticity(mix)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nWarning: Heteroscedasticity (non-constant error variance) detected (p = 0.009).\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(simulateResiduals(mix))\n```\n\n::: {.cell-output-display}\n![](Aula-9_files/figure-html/unnamed-chunk-10-1.png){width=672}\n:::\n:::\n\n\nCom as análises acima, conclui-se que os dados seguem distribuição normal. Porém, não há homogeneidade de variância entre os grupos. Logo será preciso uma alternativa para prosseguir a análise, por exemplo a transformação dos dados com raiz quadrada.\n\n### Transformação dos dados - Raiz quadrada\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmix2 <- lmer(sqrt(index) ~ hybrid*method + block + (1|block/hybrid),\n            data = milho)\n```\n:::\n\n\n#### ANOVA - Dados transformados\n\n\n::: {.cell}\n\n```{.r .cell-code}\nanova(mix2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nAnalysis of Variance Table\n              npar  Sum Sq Mean Sq F value\nhybrid           5 2.14415 0.42883  3.0632\nmethod           1 0.54438 0.54438  3.8886\nblock            3 0.01004 0.00335  0.0239\nhybrid:method    5 1.87331 0.37466  2.6762\n```\n\n\n:::\n:::\n\n\n#### Avaliação das premissas - Dados transformados\n\nCom as funções `check_normality` e `check_heteroscedasticity` (pacote **`Performance`**):\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncheck_normality(mix2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nOK: residuals appear as normally distributed (p = 0.440).\n```\n\n\n:::\n\n```{.r .cell-code}\ncheck_heteroscedasticity(mix2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nOK: Error variance appears to be homoscedastic (p = 0.971).\n```\n\n\n:::\n:::\n\n\nAtravés de um gráfico Q-Q (funções `qqnorm` e `qqline`):\n\n\n::: {.cell}\n\n```{.r .cell-code}\nqqnorm(residuals(mix2))\nqqline(residuals(mix2))\n```\n\n::: {.cell-output-display}\n![](Aula-9_files/figure-html/unnamed-chunk-14-1.png){width=672}\n:::\n:::\n\n\nCom a função `simulateResiduals` (pacote **`DHARMa`**):\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(simulateResiduals(mix2))\n```\n\n::: {.cell-output-display}\n![](Aula-9_files/figure-html/unnamed-chunk-15-1.png){width=672}\n:::\n:::\n\n\nApesar da análise via **`DHARMa`** ter apresentado problemas, as demais avaliações (via **`Performance`** e QQ-Plot) se mostraram favoráveis, logo é possível prosseguir para a comparação de médias.\n\n#### Comparação de médias - Dados transformados\n\nComo visto pela ANOVA, há efeito de interação, logo será preciso realizar desdobramentos para as comparações:\n\n##### Híbridos dentro de métodos:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nindex <- emmeans(mix2, ~hybrid | method,\n                 type = \"response\")\n\ncld(index, Letters = LETTERS)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nmethod = pin:\n hybrid   response   SE   df lower.CL upper.CL .group\n BG7049H      19.4 10.7 6084     4.10     46.0  A    \n 30K64        20.3 10.9 6084     4.51     47.4  A    \n 30F53 YH     24.5 12.0 6084     6.61     53.7  AB   \n 30F53 HX     25.0 12.1 6084     6.84     54.4  AB   \n 30S31YH      31.7 13.7 6084    10.57     64.2  AB   \n 30S31H       37.1 14.8 6084    13.79     71.8   B   \n\nmethod = silk:\n hybrid   response   SE   df lower.CL upper.CL .group\n BG7049H      19.1 10.6 6084     3.96     45.6  A    \n 30K64        21.3 11.2 6084     5.00     48.9  A    \n 30F53 HX     24.4 12.0 6084     6.56     53.6  A    \n 30F53 YH     26.0 12.4 6084     7.42     56.0  A    \n 30S31H       26.3 12.5 6084     7.57     56.4  A    \n 30S31YH      26.4 12.5 6084     7.62     56.5  A    \n\nResults are averaged over the levels of: block \nDegrees-of-freedom method: kenward-roger \nConfidence level used: 0.95 \nIntervals are back-transformed from the sqrt scale \nNote: contrasts are still on the sqrt scale \nP value adjustment: tukey method for comparing a family of 6 estimates \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n```\n\n\n:::\n:::\n\n\n##### Métodos dentro de híbridos\n\n\n::: {.cell}\n\n```{.r .cell-code}\nindex2 <- emmeans(mix2, ~method | hybrid,\n                  type = \"response\")\n\ncld(index2, Letters = letters)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nhybrid = 30F53 HX:\n method response   SE   df lower.CL upper.CL .group\n silk       24.4 12.0 6084     6.56     53.6  a    \n pin        25.0 12.1 6084     6.84     54.4  a    \n\nhybrid = 30F53 YH:\n method response   SE   df lower.CL upper.CL .group\n pin        24.5 12.0 6084     6.61     53.7  a    \n silk       26.0 12.4 6084     7.42     56.0  a    \n\nhybrid = 30K64:\n method response   SE   df lower.CL upper.CL .group\n pin        20.3 10.9 6084     4.51     47.4  a    \n silk       21.3 11.2 6084     5.00     48.9  a    \n\nhybrid = 30S31H:\n method response   SE   df lower.CL upper.CL .group\n silk       26.3 12.5 6084     7.57     56.4  a    \n pin        37.1 14.8 6084    13.79     71.8   b   \n\nhybrid = 30S31YH:\n method response   SE   df lower.CL upper.CL .group\n silk       26.4 12.5 6084     7.62     56.5  a    \n pin        31.7 13.7 6084    10.57     64.2  a    \n\nhybrid = BG7049H:\n method response   SE   df lower.CL upper.CL .group\n silk       19.1 10.6 6084     3.96     45.6  a    \n pin        19.4 10.7 6084     4.10     46.0  a    \n\nResults are averaged over the levels of: block \nDegrees-of-freedom method: kenward-roger \nConfidence level used: 0.95 \nIntervals are back-transformed from the sqrt scale \nNote: contrasts are still on the sqrt scale \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n```\n\n\n:::\n:::\n\n\n## Produtividade (yield)\n\nSeguindo os mesmos procedimentos para o índice de doença, será conduzida avaliação da produtividade.\n\n### Construção do modelo\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmix3 <- lmer(yield ~ hybrid*method + block + (1|block/hybrid),\n            data = milho)\n```\n:::\n\n\n### ANOVA\n\n\n::: {.cell}\n\n```{.r .cell-code}\nAnova(mix3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nAnalysis of Deviance Table (Type II Wald chisquare tests)\n\nResponse: yield\n                Chisq Df Pr(>Chisq)    \nhybrid        25.5991  5  0.0001067 ***\nmethod         0.1052  1  0.7456934    \nblock          2.3564  3  0.5018078    \nhybrid:method 25.9302  5  9.206e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n:::\n\n\n### Avaliação das premissas\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncheck_normality(mix3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nOK: residuals appear as normally distributed (p = 0.211).\n```\n\n\n:::\n\n```{.r .cell-code}\ncheck_heteroscedasticity(mix3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nWarning: Heteroscedasticity (non-constant error variance) detected (p < .001).\n```\n\n\n:::\n:::\n\n\nA análise pelas funções check_normality e check_heteroscedasticity demonstram que os dados possuem normalidade na distribuição dos resíduos, no entanto, não há homogeneidade de variância entre os grupos. Portanto, também será preciso realizar transformação.\n\n#### Transformação dos dados - Raiz quadrada\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmix4 <- lmer(sqrt(yield) ~ hybrid*method + block + (1|block/hybrid),\n            data = milho)\n```\n:::\n\n\n#### ANOVA - Dados transformados\n\n\n::: {.cell}\n\n```{.r .cell-code}\nanova(mix4)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nAnalysis of Variance Table\n              npar  Sum Sq Mean Sq F value\nhybrid           5 272.298  54.460  5.1118\nmethod           1   0.554   0.554  0.0520\nblock            3  25.150   8.383  0.7869\nhybrid:method    5 260.999  52.200  4.8997\n```\n\n\n:::\n:::\n\n\n#### Avaliação das premissas - Dados transformados\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncheck_normality(mix4)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nOK: residuals appear as normally distributed (p = 0.214).\n```\n\n\n:::\n\n```{.r .cell-code}\ncheck_heteroscedasticity(mix4)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nOK: Error variance appears to be homoscedastic (p = 0.686).\n```\n\n\n:::\n:::\n\n\n#### Comparação de médias - Dados transformados\n\n##### Híbridos dentro de métodos:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nyield <- emmeans(mix4, ~ hybrid | method,\n                 type = \"response\")\ncld(index, Letters = LETTERS)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nmethod = pin:\n hybrid   response   SE   df lower.CL upper.CL .group\n BG7049H      19.4 10.7 6084     4.10     46.0  A    \n 30K64        20.3 10.9 6084     4.51     47.4  A    \n 30F53 YH     24.5 12.0 6084     6.61     53.7  AB   \n 30F53 HX     25.0 12.1 6084     6.84     54.4  AB   \n 30S31YH      31.7 13.7 6084    10.57     64.2  AB   \n 30S31H       37.1 14.8 6084    13.79     71.8   B   \n\nmethod = silk:\n hybrid   response   SE   df lower.CL upper.CL .group\n BG7049H      19.1 10.6 6084     3.96     45.6  A    \n 30K64        21.3 11.2 6084     5.00     48.9  A    \n 30F53 HX     24.4 12.0 6084     6.56     53.6  A    \n 30F53 YH     26.0 12.4 6084     7.42     56.0  A    \n 30S31H       26.3 12.5 6084     7.57     56.4  A    \n 30S31YH      26.4 12.5 6084     7.62     56.5  A    \n\nResults are averaged over the levels of: block \nDegrees-of-freedom method: kenward-roger \nConfidence level used: 0.95 \nIntervals are back-transformed from the sqrt scale \nNote: contrasts are still on the sqrt scale \nP value adjustment: tukey method for comparing a family of 6 estimates \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n```\n\n\n:::\n:::\n\n\n##### Métodos dentro de híbridos\n\n\n::: {.cell}\n\n```{.r .cell-code}\nyield2 <- emmeans(mix4, ~ method | hybrid,\n                  type = \"response\")\ncld(index2, Letters = letters)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nhybrid = 30F53 HX:\n method response   SE   df lower.CL upper.CL .group\n silk       24.4 12.0 6084     6.56     53.6  a    \n pin        25.0 12.1 6084     6.84     54.4  a    \n\nhybrid = 30F53 YH:\n method response   SE   df lower.CL upper.CL .group\n pin        24.5 12.0 6084     6.61     53.7  a    \n silk       26.0 12.4 6084     7.42     56.0  a    \n\nhybrid = 30K64:\n method response   SE   df lower.CL upper.CL .group\n pin        20.3 10.9 6084     4.51     47.4  a    \n silk       21.3 11.2 6084     5.00     48.9  a    \n\nhybrid = 30S31H:\n method response   SE   df lower.CL upper.CL .group\n silk       26.3 12.5 6084     7.57     56.4  a    \n pin        37.1 14.8 6084    13.79     71.8   b   \n\nhybrid = 30S31YH:\n method response   SE   df lower.CL upper.CL .group\n silk       26.4 12.5 6084     7.62     56.5  a    \n pin        31.7 13.7 6084    10.57     64.2  a    \n\nhybrid = BG7049H:\n method response   SE   df lower.CL upper.CL .group\n silk       19.1 10.6 6084     3.96     45.6  a    \n pin        19.4 10.7 6084     4.10     46.0  a    \n\nResults are averaged over the levels of: block \nDegrees-of-freedom method: kenward-roger \nConfidence level used: 0.95 \nIntervals are back-transformed from the sqrt scale \nNote: contrasts are still on the sqrt scale \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n```\n\n\n:::\n:::\n\n\n## Análise de Regressão Linear\n\n\n::: {.cell}\n\n```{.r .cell-code}\nestande <- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=401662555\")\n\nestande <- estande %>% \n  mutate(bloco = as.factor(bloco))\n```\n:::\n\n\n### Visualização gráfica\n\n\n::: {.cell}\n\n```{.r .cell-code}\nestande %>% \n  ggplot(aes(trat, nplants))+\n  geom_jitter(width = 0.2, alpha = 0.2, color = \"darkred\")+\n  stat_summary(fun.data = \"mean_cl_boot\")+\n  geom_smooth(method = \"lm\", se = FALSE)+\n  facet_wrap(~exp)\n```\n\n::: {.cell-output-display}\n![](Aula-9_files/figure-html/unnamed-chunk-27-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nestande %>% \n  ggplot(aes(trat, nplants))+\n  geom_jitter(width = 0.2, alpha = 0.2, color = \"darkred\")+\n  stat_summary(fun.data = \"mean_cl_boot\")+\n  geom_smooth(method = \"lm\", se = FALSE)\n```\n\n::: {.cell-output-display}\n![](Aula-9_files/figure-html/unnamed-chunk-28-1.png){width=672}\n:::\n:::\n\n\n### Comparação por experimentos\n\n#### Exp. 1\n\n\n::: {.cell}\n\n```{.r .cell-code}\nexp1 <- estande %>% \n  filter(exp == 1)\n\nexp1 %>% \n  ggplot(aes(trat, nplants))+\n  geom_point()+\n  ylim (0,100)+\n  geom_smooth(method = \"lm\", se = FALSE)\n```\n\n::: {.cell-output-display}\n![](Aula-9_files/figure-html/unnamed-chunk-29-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nlm1 <- lm (nplants ~ trat,\n           data = exp1)\nsummary(lm1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = nplants ~ trat, data = exp1)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-25.500  -6.532   1.758   8.573  27.226 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  52.5000     4.2044  12.487 1.84e-11 ***\ntrat         -0.2419     0.1859  -1.301    0.207    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 15 on 22 degrees of freedom\nMultiple R-squared:  0.07148,\tAdjusted R-squared:  0.02928 \nF-statistic: 1.694 on 1 and 22 DF,  p-value: 0.2066\n```\n\n\n:::\n:::\n\n\n#### Exp. 2\n\n\n::: {.cell}\n\n```{.r .cell-code}\nexp2 <- estande %>% \n  filter(exp == 2)\n\nexp2 %>% \n  ggplot(aes(trat, nplants))+\n  geom_point()+\n  ylim (0,100)+\n  geom_smooth (se = FALSE)+\n  geom_smooth(method = \"lm\", se = FALSE, color = \"red\")\n```\n\n::: {.cell-output-display}\n![](Aula-9_files/figure-html/unnamed-chunk-31-1.png){width=672}\n:::\n:::\n\n\nUma opção para linearizar a curva seria aplicar log no tratamento (log(trat)).\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlm2 <- lm (nplants ~ trat,\n           data = exp2)\nsummary(lm2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = nplants ~ trat, data = exp2)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-25.7816  -7.7150   0.5653   8.1929  19.2184 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  60.9857     3.6304  16.798 4.93e-14 ***\ntrat         -0.7007     0.1605  -4.365 0.000247 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 12.95 on 22 degrees of freedom\nMultiple R-squared:  0.4641,\tAdjusted R-squared:  0.4398 \nF-statistic: 19.05 on 1 and 22 DF,  p-value: 0.0002473\n```\n\n\n:::\n:::\n\n\n#### Exp. 3\n\n\n::: {.cell}\n\n```{.r .cell-code}\nexp3 <- estande %>% \n  filter(exp == 3)\n\nexp1 %>% \n  ggplot(aes(trat, nplants))+\n  geom_point()+\n  ylim (0,100)+\n  geom_smooth(method = \"lm\", se = FALSE)\n```\n\n::: {.cell-output-display}\n![](Aula-9_files/figure-html/unnamed-chunk-33-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nlm3 <- lm (nplants ~ trat,\n           data = exp3)\nsummary(lm3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = nplants ~ trat, data = exp3)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-26.5887  -3.9597   0.7177   5.5806  19.8952 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  95.7500     2.9529  32.425  < 2e-16 ***\ntrat         -0.7634     0.1306  -5.847 6.97e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 10.53 on 22 degrees of freedom\nMultiple R-squared:  0.6085,\tAdjusted R-squared:  0.5907 \nF-statistic: 34.19 on 1 and 22 DF,  p-value: 6.968e-06\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nglm1 <- glm(nplants ~ trat,\n            family = \"gaussian\",\n            data = exp1)\n\nsummary(glm1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nglm(formula = nplants ~ trat, family = \"gaussian\", data = exp1)\n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  52.5000     4.2044  12.487 1.84e-11 ***\ntrat         -0.2419     0.1859  -1.301    0.207    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for gaussian family taken to be 224.9751)\n\n    Null deviance: 5330.5  on 23  degrees of freedom\nResidual deviance: 4949.5  on 22  degrees of freedom\nAIC: 202\n\nNumber of Fisher Scoring iterations: 2\n```\n\n\n:::\n\n```{.r .cell-code}\nAIC(glm1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 202.0045\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nglm2a <- glm(nplants ~ trat,\n            family = \"gaussian\",\n            data = exp2)\n\nsummary(glm2a)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nglm(formula = nplants ~ trat, family = \"gaussian\", data = exp2)\n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  60.9857     3.6304  16.798 4.93e-14 ***\ntrat         -0.7007     0.1605  -4.365 0.000247 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for gaussian family taken to be 167.7464)\n\n    Null deviance: 6886.6  on 23  degrees of freedom\nResidual deviance: 3690.4  on 22  degrees of freedom\nAIC: 194.96\n\nNumber of Fisher Scoring iterations: 2\n```\n\n\n:::\n\n```{.r .cell-code}\nAIC(glm2a)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 194.9597\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nglm2b <- glm(nplants ~ trat,\n            family = poisson(link = \"log\"),\n            data = exp2)\n\nsummary(glm2b)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nglm(formula = nplants ~ trat, family = poisson(link = \"log\"), \n    data = exp2)\n\nCoefficients:\n             Estimate Std. Error z value Pr(>|z|)    \n(Intercept)  4.134189   0.037583 110.003  < 2e-16 ***\ntrat        -0.016270   0.002059  -7.901 2.76e-15 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 139.783  on 23  degrees of freedom\nResidual deviance:  69.578  on 22  degrees of freedom\nAIC: 210.24\n\nNumber of Fisher Scoring iterations: 4\n```\n\n\n:::\n\n```{.r .cell-code}\nAIC(glm2b)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 210.2353\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nglm3 <- glm(nplants ~ trat,\n            family = \"gaussian\",\n            data = exp3)\n\nsummary(glm3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nglm(formula = nplants ~ trat, family = \"gaussian\", data = exp3)\n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  95.7500     2.9529  32.425  < 2e-16 ***\ntrat         -0.7634     0.1306  -5.847 6.97e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for gaussian family taken to be 110.9787)\n\n    Null deviance: 6235.8  on 23  degrees of freedom\nResidual deviance: 2441.5  on 22  degrees of freedom\nAIC: 185.04\n\nNumber of Fisher Scoring iterations: 2\n```\n\n\n:::\n\n```{.r .cell-code}\nAIC(glm3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 185.0449\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nglm3b <- glm(nplants ~ trat,\n            family = poisson(link = \"log\"),\n            data = exp3)\n\nsummary(glm3b)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nglm(formula = nplants ~ trat, family = poisson(link = \"log\"), \n    data = exp3)\n\nCoefficients:\n             Estimate Std. Error z value Pr(>|z|)    \n(Intercept)  4.571590   0.029539 154.762  < 2e-16 ***\ntrat        -0.009965   0.001488  -6.697 2.13e-11 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 77.906  on 23  degrees of freedom\nResidual deviance: 29.952  on 22  degrees of freedom\nAIC: 183.93\n\nNumber of Fisher Scoring iterations: 4\n```\n\n\n:::\n\n```{.r .cell-code}\nAIC(glm3b)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 183.9324\n```\n\n\n:::\n:::\n\n\nAnálise dos experimento como um conjuto\n\n\n::: {.cell}\n\n```{.r .cell-code}\nglm_exp <- glmer(nplants ~ trat + (trat | exp),\n            family = \"gaussian\",\n            data = estande)\n\nsummary(glm_exp)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nLinear mixed model fit by REML ['lmerMod']\nFormula: nplants ~ trat + (trat | exp)\n   Data: estande\n\nREML criterion at convergence: 580.8\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-2.0988 -0.6091  0.1722  0.6360  1.9963 \n\nRandom effects:\n Groups   Name        Variance  Std.Dev. Corr \n exp      (Intercept) 510.68405 22.5983       \n          trat          0.05516  0.2349  -0.82\n Residual             167.91303 12.9581       \nNumber of obs: 72, groups:  exp, 3\n\nFixed effects:\n            Estimate Std. Error t value\n(Intercept)  69.7452    13.2146   5.278\ntrat         -0.5687     0.1643  -3.462\n\nCorrelation of Fixed Effects:\n     (Intr)\ntrat -0.731\noptimizer (nloptwrap) convergence code: 0 (OK)\nModel failed to converge with max|grad| = 0.00274249 (tol = 0.002, component 1)\n```\n\n\n:::\n\n```{.r .cell-code}\nAIC(glm_exp)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 592.8402\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nglm_exp_2 <- glmer(nplants ~ trat + (trat | exp),\n            family = poisson(link = \"log\"),\n            data = estande)\n\nsummary(glm_exp_2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nGeneralized linear mixed model fit by maximum likelihood (Laplace\n  Approximation) [glmerMod]\n Family: poisson  ( log )\nFormula: nplants ~ trat + (trat | exp)\n   Data: estande\n\n     AIC      BIC   logLik deviance df.resid \n   660.7    672.1   -325.4    650.7       67 \n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-3.6247 -0.8083  0.1042  0.9601  3.6511 \n\nRandom effects:\n Groups Name        Variance  Std.Dev. Corr \n exp    (Intercept) 6.425e-02 0.253478      \n        trat        1.602e-05 0.004003 -0.17\nNumber of obs: 72, groups:  exp, 3\n\nFixed effects:\n             Estimate Std. Error z value Pr(>|z|)    \n(Intercept)  4.223397   0.147793  28.577  < 2e-16 ***\ntrat        -0.010434   0.002538  -4.111 3.93e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n     (Intr)\ntrat -0.192\n```\n\n\n:::\n\n```{.r .cell-code}\nAIC(glm_exp_2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 660.7282\n```\n\n\n:::\n:::\n\n\n\\_\\_\\_\n\n\n::: {.cell}\n\n```{.r .cell-code}\ninstall.packages(\"pak\")\npak::pkg_install(\"Icens\")\npak::pkg_install(\"emdelponte/r4pde\")\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nremotes::install_github(\"emdelponte/r4pde\")\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(r4pde)\nwm <- WhiteMoldSoybean\n\nwm %>% \n  ggplot (aes (inc, yld))+\n  geom_point()+\n  facet_wrap(~study)\n```\n\n::: {.cell-output-display}\n![](Aula-9_files/figure-html/unnamed-chunk-44-1.png){width=672}\n:::\n:::\n\n\nCálculo de coeficiente angular para todos os ensaios\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwm %>% \n  ggplot (aes (inc, yld))+\n  geom_point()+\n  geom_smooth(method = \"lm\")\n```\n\n::: {.cell-output-display}\n![](Aula-9_files/figure-html/unnamed-chunk-45-1.png){width=672}\n:::\n\n```{.r .cell-code}\nmofo1 <- lm(yld ~ inc,\n            data = wm)\nsummary(mofo1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = yld ~ inc, data = wm)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1657.85  -594.50   -91.32   531.76  1693.15 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 3299.619     56.451  58.451  < 2e-16 ***\ninc           -9.261      2.108  -4.393 1.45e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 745.8 on 380 degrees of freedom\nMultiple R-squared:  0.04833,\tAdjusted R-squared:  0.04582 \nF-statistic:  19.3 on 1 and 380 DF,  p-value: 1.452e-05\n```\n\n\n:::\n:::\n\n\nCálculo de coeficiente angular para os ensaios individualmente\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwm %>% \n  ggplot (aes (inc, yld, group = factor(study)))+\n  geom_point()+\n  geom_smooth(method = \"lm\", se = F)\n```\n\n::: {.cell-output-display}\n![](Aula-9_files/figure-html/unnamed-chunk-46-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(broom)\nmofo2 <- wm %>% \n  group_by(study) %>% \n  do(tidy(lm(.$study ~ .$inc), conf.int = TRUE))\n\nmofo2\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 70 × 8\n# Groups:   study [35]\n   study term        estimate std.error statistic     p.value conf.low conf.high\n   <dbl> <chr>          <dbl>     <dbl>     <dbl>       <dbl>    <dbl>     <dbl>\n 1     1 (Intercept) 1   e+ 0  0        Inf         0         1   e+ 0  1   e+ 0\n 2     1 .$inc       0         0        NaN       NaN         0         0       \n 3     2 (Intercept) 2   e+ 0  0        Inf         0         2   e+ 0  2   e+ 0\n 4     2 .$inc       0         0        NaN       NaN         0         0       \n 5     3 (Intercept) 3   e+ 0  0        Inf         0         3   e+ 0  3   e+ 0\n 6     3 .$inc       0         0        NaN       NaN         0         0       \n 7     4 (Intercept) 4   e+ 0  0        Inf         0         4   e+ 0  4   e+ 0\n 8     4 .$inc       0         0        NaN       NaN         0         0       \n 9     5 (Intercept) 5.00e+ 0  1.16e-15   4.29e15   1.37e-167 5.00e+ 0  5   e+ 0\n10     5 .$inc       1.40e-16  2.83e-17   4.93e 0   4.50e-  4 7.73e-17  2.02e-16\n# ℹ 60 more rows\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ndf <- mofo2 %>% filter(term == \".$inc\")\nmean(df$estimate)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 5.99393e-17\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\np1 <- mofo2 %>% \n  filter(term == \"(Intercept)\") %>% \n  ggplot(aes(x = estimate))+\n  geom_histogram(bins = 8, color = \"white\", fill = \"gray50\")+\n  theme_r4pde()+\n  labs( x = \"Intercept\",\n        y = \"Frequency\")\n\np1\n```\n\n::: {.cell-output-display}\n![](Aula-9_files/figure-html/unnamed-chunk-49-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\np2 <- mofo2 %>% \n  filter(term == \".$inc\") %>%  \n  ggplot(aes(x = estimate))+\n  geom_histogram(bins = 8, color = \"white\", fill = \"gray50\")+\n  theme_r4pde()+\n  labs(x = \"Slope\", y = \"Frequency\")\n\np2\n```\n\n::: {.cell-output-display}\n![](Aula-9_files/figure-html/unnamed-chunk-50-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(patchwork)\n(p1+p2)\n```\n\n::: {.cell-output-display}\n![](Aula-9_files/figure-html/unnamed-chunk-51-1.png){width=672}\n:::\n:::\n\n\nModelo misto\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmofo3 <- lmer(yld ~ inc + (inc | study), data = wm,\n              REML = F)\nsummary(mofo3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nLinear mixed model fit by maximum likelihood  ['lmerMod']\nFormula: yld ~ inc + (inc | study)\n   Data: wm\n\n     AIC      BIC   logLik deviance df.resid \n  5319.4   5343.1  -2653.7   5307.4      376 \n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-3.7078 -0.5991 -0.0295  0.5077  3.2364 \n\nRandom effects:\n Groups   Name        Variance  Std.Dev. Corr \n study    (Intercept) 557573.08 746.708       \n          inc             36.85   6.071  -0.29\n Residual              37228.73 192.947       \nNumber of obs: 382, groups:  study, 35\n\nFixed effects:\n            Estimate Std. Error t value\n(Intercept) 3455.432    128.063   26.98\ninc          -17.236      1.451  -11.88\n\nCorrelation of Fixed Effects:\n    (Intr)\ninc -0.300\noptimizer (nloptwrap) convergence code: 0 (OK)\nModel failed to converge with max|grad| = 0.416806 (tol = 0.002, component 1)\n```\n\n\n:::\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}