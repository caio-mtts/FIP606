---
title: "Aula 09 - Estatística inferencial - Regressão linear"
format: html
editor: visual
execute: 
  error: false
  warning: false
---

```{r}
#| include: false
#| echo: false

library(gsheet)
library(tidyverse)
library(lme4)
library(car)
library(performance)
library(DHARMa)
library(emmeans)
library(multcomp)
library(multcompView)
library(patchwork)
library(r4pde)
```

## Análise de Regressão Linear

```{r}
estande <- gsheet2tbl("https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=401662555")

estande <- estande %>% 
  mutate(bloco = as.factor(bloco))
```

### Visualização gráfica

```{r}
estande %>% 
  ggplot(aes(trat, nplants))+
  geom_jitter(width = 0.2, alpha = 0.2, color = "darkred")+
  stat_summary(fun.data = "mean_cl_boot")+
  geom_smooth(method = "lm", se = FALSE)+
  facet_wrap(~exp)
```

```{r}
estande %>% 
  ggplot(aes(trat, nplants))+
  geom_jitter(width = 0.2, alpha = 0.2, color = "darkred")+
  stat_summary(fun.data = "mean_cl_boot")+
  geom_smooth(method = "lm", se = FALSE)
```

### Comparação por experimentos

#### Exp. 1

```{r}
exp1 <- estande %>% 
  filter(exp == 1)

exp1 %>% 
  ggplot(aes(trat, nplants))+
  geom_point()+
  ylim (0,100)+
  geom_smooth(method = "lm", se = FALSE)
```

```{r}
lm1 <- lm (nplants ~ trat,
           data = exp1)
summary(lm1)
```

#### Exp. 2

```{r}
exp2 <- estande %>% 
  filter(exp == 2)

exp2 %>% 
  ggplot(aes(trat, nplants))+
  geom_point()+
  ylim (0,100)+
  geom_smooth (se = FALSE)+
  geom_smooth(method = "lm", se = FALSE, color = "red")
```

Uma alternativa para linearizar a curva seria aplicar função logarítmica no tratameto.

```{r}
lm2 <- lm (nplants ~ trat,
           data = exp2)
summary(lm2)
```

#### Exp. 3

```{r}
exp3 <- estande %>% 
  filter(exp == 3)

exp1 %>% 
  ggplot(aes(trat, nplants))+
  geom_point()+
  ylim (0,100)+
  geom_smooth(method = "lm", se = FALSE)
```

```{r}
lm3 <- lm (nplants ~ trat,
           data = exp3)
summary(lm3)
```

### Modelos lineares generalizados para comparação do ajuste por experimentos

```{r}
glm1 <- glm(nplants ~ trat,
            family = "gaussian",
            data = exp1)

summary(glm1)
AIC(glm1)
```

```{r}
glm2a <- glm(nplants ~ trat,
            family = "gaussian",
            data = exp2)

summary(glm2a)
AIC(glm2a)
```

```{r}
glm2b <- glm(nplants ~ trat,
            family = poisson(link = "log"),
            data = exp2)

summary(glm2b)
AIC(glm2b)
```

```{r}
glm3 <- glm(nplants ~ trat,
            family = "gaussian",
            data = exp3)

summary(glm3)
AIC(glm3)
```

```{r}
glm3b <- glm(nplants ~ trat,
            family = poisson(link = "log"),
            data = exp3)

summary(glm3b)
AIC(glm3b)
```

A função `AIC` é útil para auxiliar na escolha do melhor modelo para cada situação. Nesse caso, utilizamos o critério de informação de Akaike (do inglês, Akaike's Information Criterion - AIC). Os melhores modelos, ou seja, aqueles que melhor se ajustam aos dados, serão aqueles que apresentarem os menores valores para essa função.

### Análise dos experimento como um conjuto

```{r}
glm_exp <- glmer(nplants ~ trat + (trat | exp),
            family = "gaussian",
            data = estande)

summary(glm_exp)
AIC(glm_exp)
```

```{r}
glm_exp_2 <- glmer(nplants ~ trat + (trat | exp),
            family = poisson(link = "log"),
            data = estande)

summary(glm_exp_2)
AIC(glm_exp_2)
```
